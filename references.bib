
@article{krafczyk_learning_2021,
	title = {Learning from reproducing computational results: introducing three principles and the {Reproduction} {Package}},
	volume = {379},
	shorttitle = {Learning from reproducing computational results},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0069},
	doi = {10.1098/rsta.2020.0069},
	abstract = {We carry out efforts to reproduce computational results for seven published articles and identify barriers to computational reproducibility. We then derive three principles to guide the practice and dissemination of reproducible computational research: (i) Provide transparency regarding how computational results are produced; (ii) When writing and releasing research software, aim for ease of (re-)executability; (iii) Make any code upon which the results rely as deterministic as possible. We then exemplify these three principles with 12 specific guidelines for their implementation in practice. We illustrate the three principles of reproducible research with a series of vignettes from our experimental reproducibility work. We define a novel Reproduction Package, a formalism that specifies a structured way to share computational research artifacts that implements the guidelines generated from our reproduction efforts to allow others to build, reproduce and extend computational science. We make our reproduction efforts in this paper publicly available as exemplar Reproduction Packages.

This article is part of the theme issue ‘Reliability and reproducibility in computational science: implementing verification, validation and uncertainty quantification in silico’.},
	number = {2197},
	urldate = {2024-05-10},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Krafczyk, M. S. and Shi, A. and Bhaskar, A. and Marinov, D. and Stodden, V.},
	month = mar,
	year = {2021},
	note = {Publisher: Royal Society},
	keywords = {reproducibility, code packaging, open code, open data, software testing, verification},
	pages = {20200069},
	file = {Full Text PDF:/home/amy/Zotero/storage/J8BX7DB9/Krafczyk et al. - 2021 - Learning from reproducing computational results i.pdf:application/pdf},
}

@article{wood_replication_2018,
	title = {Replication {Protocol} for {Push} {Button} {Replication} ({PBR})},
	url = {https://osf.io/yfbr8/},
	doi = {https://doi.org/10.17605/OSF.IO/YFBR8},
	abstract = {3ie’s Replication Programme is conducting a PBRproject.PBR studies test the ability for another researcher to use data and code to reproduce the originally published results.PBR researchersare not tasked with evaluating the quality of the original research or testing the robustness of the original results to any type of sensitivity analysis. They are also not expected to explore any original coding decisions. When conducting PBRstudies, 3ie requires researchers to follow a set protocol. The steps of the protocol are listed sequentially and outlined below.Each paper subject to replication will have a unique component in the Open Science Framework (OSF)platform.},
	language = {en-us},
	urldate = {2024-05-10},
	journal = {OSF},
	author = {Wood, Benjamin and Brown, Annette and Djimeu, Eric and Vasquez, Maria and Yoon, Semi and Burke, Jane},
	month = jan,
	year = {2018},
	note = {Publisher: Open Science Framework},
	file = {Wood - 2018 - Replication Protocol for Push Button Replication (.pdf:/home/amy/Zotero/storage/ITZP3QMT/Wood - 2018 - Replication Protocol for Push Button Replication (.pdf:application/pdf},
}

@misc{haroz_comparison_2022,
	title = {Comparison of {Preregistration} {Platforms}},
	url = {https://osf.io/preprints/metaarxiv/zry2u},
	doi = {https://doi.org/10.31222/osf.io/zry2u},
	abstract = {Preregistration can force researchers to front-load a lot of decision-making to an early stage of a project. Choosing which preregistration platform to use must be therefore be one of those early decisions, and because a preregistration cannot be moved, that choice is permanent. This article aims to help researchers who are already interested in preregistration choose a platform by clarifying differences between them. Preregistration criteria and features are explained and analyzed for sites that cater to a broad range of research fields, including: GitHub, AsPredicted, Zenodo, the Open Science Framework (OSF), and an “open-ended” variant of OSF. While a private prespecification document can help mitigate self-deception, this guide considers publicly shared preregistrations that aim to improve credibility. It therefore defines three of the criteria (a timestamp, a registry, and persistence) as a bare minimum for a valid and reliable preregistration. GitHub and AsPredicted fail to meet all three. Zenodo and OSF meet the basic criteria and vary in which additional features they offer.},
	urldate = {2024-05-10},
	publisher = {MetaArXiv},
	author = {Haroz, Steve},
	month = feb,
	year = {2022},
	file = {Haroz - Comparison of Preregistration Platforms.pdf:/home/amy/Zotero/storage/W7GW7B4K/Haroz - Comparison of Preregistration Platforms.pdf:application/pdf},
}

@article{wood_push_2018,
	title = {Push button replication: {Is} impact evaluation evidence for international development verifiable?},
	volume = {13},
	issn = {1932-6203},
	shorttitle = {Push button replication},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0209416},
	doi = {10.1371/journal.pone.0209416},
	abstract = {Objective Empirical research that cannot be reproduced using the original dataset and software code (replication files) creates a credibility challenge, as it means those published findings are not verifiable. This study reports the results of a research audit exercise, known as the push button replication project, that tested a sample of studies that use similar empirical methods but span a variety of academic fields. Methods We developed and piloted a detailed protocol for conducting push button replication and determining the level of comparability of these replication findings to original findings. We drew a sample of articles from the ten journals that published the most impact evaluations from low- and middle-income countries from 2010 through 2012. This set includes health, economics, and development journals. We then selected all articles in these journals published in 2014 that meet the same inclusion criteria and implemented the protocol on the sample. Results Of the 109 articles in our sample, only 27 are push button replicable, meaning the provided code run on the provided dataset produces comparable findings for the key results in the published article. The authors of 59 of the articles refused to provide replication files. Thirty of these 59 articles were published in journals that had replication file requirements in 2014, meaning these articles are non-compliant with their journal requirements. For the remaining 23 of the 109 articles, we confirmed that three had proprietary data, we received incomplete replication files for 15, and we found minor differences in the replication results for five. Conclusion The findings presented here reveal that many economics, development, and public health researchers are a long way from adopting the norm of open research. Journals do not appear to be playing a strong role in ensuring the availability of replication files.},
	language = {en},
	number = {12},
	urldate = {2024-05-10},
	journal = {PLOS ONE},
	author = {Wood, Benjamin D. K. and Müller, Rui and Brown, Annette N.},
	month = dec,
	year = {2018},
	note = {Publisher: Public Library of Science},
	keywords = {Health economics, Development economics, Economic development, Medical journals, Open data, Public and occupational health, Replication studies, Scientific publishing},
	pages = {e0209416},
	file = {Full Text PDF:/home/amy/Zotero/storage/UFWQJ7I8/Wood et al. - 2018 - Push button replication Is impact evaluation evid.pdf:application/pdf},
}

@article{monks_computer_2023,
	title = {Computer model and code sharing practices in healthcare discrete-event simulation: a systematic scoping review},
	volume = {0},
	issn = {1747-7778},
	shorttitle = {Computer model and code sharing practices in healthcare discrete-event simulation},
	url = {https://doi.org/10.1080/17477778.2023.2260772},
	doi = {10.1080/17477778.2023.2260772},
	abstract = {Discrete-event simulation (DES) is a widely used computational method in health services and health economic studies. This scoping review investigates to what extent authors share DES models and audits if sharing adheres to best practice. The Web of Science, Scopus, PubMed, and ACM Digital Library databases were searched between January 1 2019 till December 31 2022. Cost-effectiveness, health service research and methodology studies in a health context were included. Data extraction and audit were performed by two reviewers. We measured the proportion of literature that shared models; we report analyses by publication type, year of publication, COVID-19 application; and free and open source versus commercial software. Out of the 564 studies included, 47 (8.3\%) cited a published computer model, rising to 9.0\% in 2022. Studies were more likely to share models if they had been developed using free and open source tools. Studies rarely followed best practice when sharing computer models. Although still in the minority, healthcare DES authors are increasingly sharing their computer model artefacts. Although commercial software dominates the DES literature, free and open source software plays a crucial role in sharing. The DES community can adopt simple best practices to improve the quality of sharing.},
	number = {0},
	urldate = {2024-05-10},
	journal = {Journal of Simulation},
	author = {Monks, Thomas and Harper, Alison},
	year = {2023},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/17477778.2023.2260772},
	keywords = {open science, reproducibility, review, healthcare, Discrete-event simulation, sharing},
	pages = {1--16},
	file = {Full Text PDF:/home/amy/Zotero/storage/KDBG4H9R/Monks and Harper - 2023 - Computer model and code sharing practices in healt.pdf:application/pdf},
}

@article{monks_towards_2024,
	title = {Towards sharing tools and artefacts for reusable simulations in healthcare},
	volume = {0},
	issn = {1747-7778},
	url = {https://doi.org/10.1080/17477778.2024.2347882},
	doi = {10.1080/17477778.2024.2347882},
	abstract = {Discrete-event simulation (DES) is a widely used computational method in health services and health economic studies. Despite increasing recognition of the advantages of open, reusable DES models for both healthcare practitioners and simulation researchers, in practice very few authors share their model code alongside a published paper. In the context of Free and Open Source Software (FOSS), this paper presents a pilot framework called STARS: Sharing Tools and Artefacts for Reusable Simulations to begin to address the challenges and leverage the opportunities of sharing DES models in healthcare. STARS aligns with existing guidelines and documentation, including reproducibility initiatives, and enables computer models to be shared with users of differing technical abilities. We demonstrate the feasibility and applicability of STARS with three applied DES examples using Python. Our framework supports the development of open, reusable DES models which can enable partner healthcare organisations to preview, validate, and use models. Academic research teams can benefit from knowledge exchange, enhanced recognition and scrutiny of their work, and long-term archiving of models.},
	number = {0},
	urldate = {2024-05-13},
	journal = {Journal of Simulation},
	author = {Monks, Thomas and Harper, Alison and Mustafee, Navonil},
	year = {2024},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/17477778.2024.2347882},
	keywords = {open science, healthcare, Discrete-event simulation, reusable models},
	pages = {1--20},
	file = {Full Text PDF:/home/amy/Zotero/storage/V3EYVUHB/Monks et al. - 2024 - Towards sharing tools and artefacts for reusable s.pdf:application/pdf},
}

@article{ayllon_keeping_2021,
	title = {Keeping modelling notebooks with {TRACE}: {Good} for you and good for environmental research and management support},
	volume = {136},
	issn = {1364-8152},
	shorttitle = {Keeping modelling notebooks with {TRACE}},
	url = {https://www.sciencedirect.com/science/article/pii/S1364815220309890},
	doi = {10.1016/j.envsoft.2020.104932},
	abstract = {The acceptance and usefulness of simulation models are often limited by the efficiency, transparency, reproducibility, and reliability of the modelling process. We address these issues by suggesting that modellers (1) “trace” the iterative modelling process by keeping a modelling notebook corresponding to the laboratory notebooks used by empirical researchers, (2) use a standardized notebook structure and terminology based on the existing TRACE documentation framework, and (3) use their notebooks to compile TRACE documents that supplement publications and reports. These practices have benefits for model developers, users, and stakeholders: improved and efficient model design, analysis, testing, and application; increased model acceptance and reuse; and replicability and reproducibility of the model and the simulation experiments. Using TRACE terminology and structure in modelling notebooks facilitates production of TRACE documents. We explain the rationale of TRACE, provide example TRACE documents, and suggest strategies for keeping “TRACE Modelling Notebooks.”},
	urldate = {2024-05-13},
	journal = {Environmental Modelling \& Software},
	author = {Ayllón, Daniel and Railsback, Steven F. and Gallagher, Cara and Augusiak, Jacqueline and Baveco, Hans and Berger, Uta and Charles, Sandrine and Martin, Romina and Focks, Andreas and Galic, Nika and Liu, Chun and van Loon, E. Emiel and Nabe-Nielsen, Jacob and Piou, Cyril and Polhill, J. Gareth and Preuss, Thomas G. and Radchuk, Viktoriia and Schmolke, Amelie and Stadnicka-Michalak, Julita and Thorbek, Pernille and Grimm, Volker},
	month = feb,
	year = {2021},
	keywords = {Environmental modelling, Model documentation, Modelling cycle, Reproducible research, Scientific communication, Standards},
	pages = {104932},
	file = {Full Text:/home/amy/Zotero/storage/PF4JAKCY/Ayllón et al. - 2021 - Keeping modelling notebooks with TRACE Good for y.pdf:application/pdf;ScienceDirect Snapshot:/home/amy/Zotero/storage/FKPZRHYH/S1364815220309890.html:text/html},
}

@inproceedings{winter_retrospective_2022,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} 2022},
	title = {A retrospective study of one decade of artifact evaluations},
	isbn = {978-1-4503-9413-0},
	url = {https://dl.acm.org/doi/10.1145/3540250.3549172},
	doi = {10.1145/3540250.3549172},
	abstract = {Most software engineering research involves the development of a prototype, a proof of concept, or a measurement apparatus. Together with the data collected in the research process, they are collectively referred to as research artifacts and are subject to artifact evaluation (AE) at scientific conferences. Since its initiation in the SE community at ESEC/FSE 2011, both the goals and the process of AE have evolved and today expectations towards AE are strongly linked with reproducible research results and reusable tools that other researchers can build their work on. However, to date little evidence has been provided that artifacts which have passed AE actually live up to these high expectations, i.e., to which degree AE processes contribute to AE's goals and whether the overhead they impose is justified. We aim to fill this gap by providing an in-depth analysis of research artifacts from a decade of software engineering (SE) and programming languages (PL) conferences, based on which we reflect on the goals and mechanisms of AE in our community. In summary, our analyses (1) suggest that articles with artifacts do not generally have better visibility in the community, (2) provide evidence how evaluated and not evaluated artifacts differ with respect to different quality criteria, and (3) highlight opportunities for further improving AE processes.},
	urldate = {2024-05-13},
	booktitle = {Proceedings of the 30th {ACM} {Joint} {European} {Software} {Engineering} {Conference} and {Symposium} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Winter, Stefan and Timperley, Christopher S. and Hermann, Ben and Cito, Jürgen and Bell, Jonathan and Hilton, Michael and Beyer, Dirk},
	month = nov,
	year = {2022},
	keywords = {Reuse, Artifact evaluation, Open science, Reproduction, Research artifacts},
	pages = {145--156},
	file = {Full Text PDF:/home/amy/Zotero/storage/UEFCFZWX/Winter et al. - 2022 - A retrospective study of one decade of artifact ev.pdf:application/pdf},
}

@misc{niso_reproducibility_badging_and_definitions_working_group_reproducibility_2021,
	title = {Reproducibility {Badging} and {Definitions}},
	url = {https://www.niso.org/publications/rp-31-2021-badging},
	doi = {10.3789/niso-rp-31-2021},
	language = {en},
	author = {{NISO Reproducibility Badging and Definitions Working Group}},
	month = jan,
	year = {2021},
	file = {NISO Taxonomy, Definitions, and Recognition Badging Scheme Working Group - Reproducibility Badging and Definitions.pdf:/home/amy/Zotero/storage/K5P79CPD/NISO Taxonomy, Definitions, and Recognition Badging Scheme Working Group - Reproducibility Badging and Definitions.pdf:application/pdf},
}

@misc{berkeley_initiative_for_transparency_in_the_social_sciences_guide_2022,
	title = {Guide for {Advancing} {Computational} {Reproducibility} in the {Social} {Sciences}},
	url = {https://bitss.github.io/ACRE/},
	urldate = {2024-05-15},
	author = {{Berkeley Initiative for Transparency in the Social Sciences}},
	month = sep,
	year = {2022},
}

@article{henderson_reproducibility_2024,
	title = {Reproducibility of {COVID}-era infectious disease models},
	volume = {46},
	issn = {1755-4365},
	url = {https://www.sciencedirect.com/science/article/pii/S1755436524000045},
	doi = {10.1016/j.epidem.2024.100743},
	abstract = {Infectious disease modelling has been prominent throughout the COVID-19 pandemic, helping to understand the virus’ transmission dynamics and inform response policies. Given their potential importance and translational impact, we evaluated the computational reproducibility of infectious disease modelling articles from the COVID era. We found that four out of 100 randomly sampled studies released between January 2020 and August 2022 could be completely computationally reproduced using the resources provided (e.g., code, data, instructions) whilst a further eight were partially reproducible. For the 100 most highly cited articles from the same period we found that 11 were completely reproducible with a further 22 partially reproducible. Reflecting on our experience, we discuss common issues affecting computational reproducibility and how these might be addressed.},
	urldate = {2024-05-15},
	journal = {Epidemics},
	author = {Henderson, Alec S. and Hickson, Roslyn I. and Furlong, Morgan and McBryde, Emma S. and Meehan, Michael T.},
	month = mar,
	year = {2024},
	keywords = {COVID-19, Open science, Infectious disease modelling, Reproducibility},
	pages = {100743},
	file = {Submitted Version:/home/amy/Zotero/storage/AUVVJ75B/Henderson et al. - 2024 - Reproducibility of COVID-era infectious disease mo.pdf:application/pdf},
}

@article{laurinavichyute_share_2022,
	title = {Share the code, not just the data: {A} case study of the reproducibility of articles published in the {Journal} of {Memory} and {Language} under the open data policy},
	volume = {125},
	issn = {0749-596X},
	shorttitle = {Share the code, not just the data},
	url = {https://www.sciencedirect.com/science/article/pii/S0749596X22000195},
	doi = {10.1016/j.jml.2022.104332},
	abstract = {In 2019 the Journal of Memory and Language instituted an open data and code policy; this policy requires that, as a rule, code and data be released at the latest upon publication. How effective is this policy? We compared 59 papers published before, and 59 papers published after, the policy took effect. After the policy was in place, the rate of data sharing increased by more than 50\%. We further looked at whether papers published under the open data policy were reproducible, in the sense that the published results should be possible to regenerate given the data, and given the code, when code was provided. For 8 out of the 59 papers, data sets were inaccessible. The reproducibility rate ranged from 34\% to 56\%, depending on the reproducibility criteria. The strongest predictor of whether an attempt to reproduce would be successful is the presence of the analysis code: it increases the probability of reproducing reported results by almost 40\%. We propose two simple steps that can increase the reproducibility of published papers: share the analysis code, and attempt to reproduce one’s own analysis using only the shared materials.},
	urldate = {2024-05-15},
	journal = {Journal of Memory and Language},
	author = {Laurinavichyute, Anna and Yadav, Himanshu and Vasishth, Shravan},
	month = aug,
	year = {2022},
	keywords = {Open data, Open science, Reproducibility, Journal policy, Meta-research, Reproducible statistical analyses},
	pages = {104332},
	file = {ScienceDirect Snapshot:/home/amy/Zotero/storage/W9KMXNC2/S0749596X22000195.html:text/html;Submitted Version:/home/amy/Zotero/storage/HLXDKBEY/Laurinavichyute et al. - 2022 - Share the code, not just the data A case study of.pdf:application/pdf},
}

@misc{the_turing_way_community_turing_2022,
	title = {The {Turing} {Way}: {A} handbook for reproducible, ethical and collaborative research (1.0.2)},
	url = {https://doi.org/10.5281/zenodo.7625728},
	urldate = {2024-05-15},
	journal = {Zenodo},
	author = {{The Turing Way Community}},
	year = {2022},
}

@article{konkol_computational_2019,
	title = {Computational reproducibility in geoscientific papers: {Insights} from a series of studies with geoscientists and a reproduction study},
	volume = {33},
	issn = {1365-8816},
	shorttitle = {Computational reproducibility in geoscientific papers},
	url = {https://doi.org/10.1080/13658816.2018.1508687},
	doi = {10.1080/13658816.2018.1508687},
	abstract = {Reproducibility is a cornerstone of science and thus for geographic research as well. However, studies in other disciplines such as biology have shown that published work is rarely reproducible. To assess the state of reproducibility, specifically computational reproducibility (i.e. rerunning the analysis of a paper using the original code), in geographic research, we asked geoscientists about this topic using three methods: a survey (n = 146), interviews (n = 9), and a focus group (n = 5). We asked participants about their understanding of open reproducible research (ORR), how much it is practiced, and what obstacles hinder ORR. We found that participants had different understandings of ORR and that there are several obstacles for authors and readers (e.g. effort, lack of openness). Then, in order to complement the subjective feedback from the participants, we tried to reproduce the results of papers that use spatial statistics to address problems in the geosciences. We selected 41 open access papers from Copernicus and Journal of Statistical Software and executed the R code. In doing so, we identified several technical issues and specific issues with the reproduced figures depicting the results. Based on these findings, we propose guidelines for authors to overcome the issues around reproducibility in the computational geosciences.},
	number = {2},
	urldate = {2024-05-15},
	journal = {International Journal of Geographical Information Science},
	author = {Konkol, Markus and Kray, Christian and Pfeiffer, Max},
	month = feb,
	year = {2019},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/13658816.2018.1508687},
	keywords = {computational research, Open reproducible research, spatial statistics},
	pages = {408--429},
	file = {Full Text PDF:/home/amy/Zotero/storage/X5TEHBQR/Konkol et al. - 2019 - Computational reproducibility in geoscientific pap.pdf:application/pdf},
}

@article{mcmanus_can_2019,
	title = {Can {You} {Repeat} {That}? {Exploring} the {Definition} of a {Successful} {Model} {Replication} in {Health} {Economics}},
	volume = {37},
	issn = {1179-2027},
	shorttitle = {Can {You} {Repeat} {That}?},
	url = {https://doi.org/10.1007/s40273-019-00836-y},
	doi = {10.1007/s40273-019-00836-y},
	abstract = {The International Society for Pharmacoeconomics and Outcomes Research (ISPOR) modelling taskforce suggests decision models should be thoroughly reported and transparent. However, the level of transparency and indeed how transparency should be assessed are yet to be defined. One way may be to attempt to replicate the model and its outputs. The ability to replicate a decision model could demonstrate adequate reporting transparency. This review aims to explore published definitions of replication success across all scientific disciplines and to consider how such a definition should be tailored for use in health economic models. A literature review was conducted to identify published definitions of a ‘successful replication’. Using these as a foundation, several definitions of replication success were constructed, to be applicable to replications of economic decision models, with the associated strengths and weaknesses of such definitions discussed. A substantial body of literature discussing replicability was found; however, relatively few studies, ten, explicitly defined a successful replication. These definitions varied from subjective assessments to expecting exactly the same results to be reproduced. Whilst the definitions that have been found may help to construct a definition specific to health economics, no definition was found that completely encompassed the unique requirements for decision models. Replication is widely discussed in other scientific disciplines; however, as of yet, there is no consensus on how replicable models should be within health economics or what constitutes a successful replication. Replication studies can demonstrate how transparently a model is reported, identify potential calculation errors and inform future reporting practices. It may therefore be a useful adjunct to other transparency or quality measures.},
	language = {en},
	number = {11},
	urldate = {2024-05-15},
	journal = {PharmacoEconomics},
	author = {McManus, Emma and Turner, David and Sach, Tracey},
	month = nov,
	year = {2019},
	pages = {1371--1381},
	file = {Full Text PDF:/home/amy/Zotero/storage/BKKYMFPI/McManus et al. - 2019 - Can You Repeat That Exploring the Definition of a.pdf:application/pdf},
}

@article{schwander_replication_2021,
	title = {Replication of {Published} {Health} {Economic} {Obesity} {Models}: {Assessment} of {Facilitators}, {Hurdles} and {Reproduction} {Success}},
	volume = {39},
	issn = {1170-7690},
	shorttitle = {Replication of {Published} {Health} {Economic} {Obesity} {Models}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8009773/},
	doi = {10.1007/s40273-021-01008-7},
	abstract = {Objectives
This research aims to (1) replicate published health economic models, (2) compare reproduced results with original results, (3) identify facilitators and hurdles to model replicability and determine reproduction success, and (4) suggest model replication reporting standards to enhance model reproducibility, in the context of health economic obesity models.

Methods
Four health economic obesity models simulating an adult UK population were identified, selected for replication, and evaluated using the Consolidated Health Economic Evaluation Reporting Standards (CHEERS) checklist. Reproduction results were compared to original results, focusing on cost-effectiveness outcomes, and the resulting reproduction success was assessed by published criteria. Replication facilitators and hurdles were identified and transferred into related reporting standards.

Results
All four case studies were state-transition models simulating costs and quality-adjusted life-years (QALYs). Comparing original versus reproduction outcomes, the following deviation ranges were observed: costs − 3.9 to 16.1\% (mean over all model simulations 3.78\%), QALYs − 3.7 to 2.1\% (mean − 0.11\%), and average cost-utility ratios − 3.0 to 17.9\% (mean 4.28\%). Applying different published criteria, an overall reproduction success was observed for three of four models. Key replication facilitators were input data tables and model diagrams, while missing standard deviations and missing formulas for equations were considered as key hurdles.

Conclusions
This study confirms the feasibility of rebuilding health economic obesity models, but minor to major assumptions were needed to fill reporting gaps. Model replications can help to assess the quality of health economic model documentation and can be used to validate current model reporting practices. Simple changes to actual CHEERS reporting criteria may solve identified replication hurdles.

Supplementary Information
The online version contains supplementary material available at 10.1007/s40273-021-01008-7.},
	number = {4},
	urldate = {2024-05-15},
	journal = {Pharmacoeconomics},
	author = {Schwander, Björn and Nuijten, Mark and Evers, Silvia and Hiligsmann, Mickaël},
	year = {2021},
	pmid = {33751452},
	pmcid = {PMC8009773},
	pages = {433--446},
	file = {PubMed Central Full Text PDF:/home/amy/Zotero/storage/F5GE7A6I/Schwander et al. - 2021 - Replication of Published Health Economic Obesity M.pdf:application/pdf},
}

@article{hardwicke_analytic_2021,
	title = {Analytic reproducibility in articles receiving open data badges at the journal {Psychological} {Science}: an observational study},
	volume = {8},
	shorttitle = {Analytic reproducibility in articles receiving open data badges at the journal {Psychological} {Science}},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.201494},
	doi = {10.1098/rsos.201494},
	abstract = {For any scientific report, repeating the original analyses upon the original data should yield the original outcomes. We evaluated analytic reproducibility in 25 Psychological Science articles awarded open data badges between 2014 and 2015. Initially, 16 (64\%, 95\% confidence interval [43,81]) articles contained at least one ‘major numerical discrepancy' ({\textgreater}10\% difference) prompting us to request input from original authors. Ultimately, target values were reproducible without author involvement for 9 (36\% [20,59]) articles; reproducible with author involvement for 6 (24\% [8,47]) articles; not fully reproducible with no substantive author response for 3 (12\% [0,35]) articles; and not fully reproducible despite author involvement for 7 (28\% [12,51]) articles. Overall, 37 major numerical discrepancies remained out of 789 checked values (5\% [3,6]), but original conclusions did not appear affected. Non-reproducibility was primarily caused by unclear reporting of analytic procedures. These results highlight that open data alone is not sufficient to ensure analytic reproducibility.},
	number = {1},
	urldate = {2024-05-15},
	journal = {Royal Society Open Science},
	author = {Hardwicke, Tom E. and Bohn, Manuel and MacDonald, Kyle and Hembacher, Emily and Nuijten, Michèle B. and Peloquin, Benjamin N. and deMayo, Benjamin E. and Long, Bria and Yoon, Erica J. and Frank, Michael C.},
	month = jan,
	year = {2021},
	note = {Publisher: Royal Society},
	keywords = {open science, reproducibility, open data, journal policy, meta-research, open badges},
	pages = {201494},
	file = {Full Text PDF:/home/amy/Zotero/storage/ISCJEP9X/Hardwicke et al. - 2021 - Analytic reproducibility in articles receiving ope.pdf:application/pdf},
}

@article{hardwicke_pre-registered_2017,
	title = {Pre-registered study protocol},
	url = {https://osf.io/2cnkq},
	doi = {10.17605/OSF.IO/T5X7F},
	urldate = {2024-05-15},
	journal = {Open Science Framework},
	author = {Hardwicke, Tom E and Frank, Michael C.},
	month = oct,
	year = {2017},
	note = {Publisher: [object Object]},
	file = {Hardwicke and Frank - 2017 - Pre-registered study protocol.pdf:/home/amy/Zotero/storage/8BICRTSJ/Hardwicke and Frank - 2017 - Pre-registered study protocol.pdf:application/pdf},
}

@article{baykova_ensuring_2024,
	title = {Ensuring the computational reproducibility of to-be-submitted psychology papers},
	url = {https://osf.io/kba9q},
	doi = {https://doi.org/10.17605/OSF.IO/DR35V},
	urldate = {2024-05-16},
	author = {Baykova, Reny and Dienes, Zoltan and Colling, Lincoln},
	month = apr,
	year = {2024},
	file = {Baykova et al. - 2024 - Ensuring the computational reproducibility of to-b.pdf:/home/amy/Zotero/storage/YJPK4LS4/Baykova et al. - 2024 - Ensuring the computational reproducibility of to-b.pdf:application/pdf},
}

@article{obels_analysis_2020,
	title = {Analysis of {Open} {Data} and {Computational} {Reproducibility} in {Registered} {Reports} in {Psychology}},
	volume = {3},
	issn = {2515-2459},
	url = {https://doi.org/10.1177/2515245920918872},
	doi = {10.1177/2515245920918872},
	abstract = {Ongoing technological developments have made it easier than ever before for scientists to share their data, materials, and analysis code. Sharing data and analysis code makes it easier for other researchers to reuse or check published research. However, these benefits will emerge only if researchers can reproduce the analyses reported in published articles and if data are annotated well enough so that it is clear what all variable and value labels mean. Because most researchers are not trained in computational reproducibility, it is important to evaluate current practices to identify those that can be improved. We examined data and code sharing for Registered Reports published in the psychological literature from 2014 to 2018 and attempted to independently computationally reproduce the main results in each article. Of the 62 articles that met our inclusion criteria, 41 had data available, and 37 had analysis scripts available. Both data and code for 36 of the articles were shared. We could run the scripts for 31 analyses, and we reproduced the main results for 21 articles. Although the percentage of articles for which both data and code were shared (36 out of 62, or 58\%) and the percentage of articles for which main results could be computationally reproduced (21 out of 36, or 58\%) were relatively high compared with the percentages found in other studies, there is clear room for improvement. We provide practical recommendations based on our observations and cite examples of good research practices in the studies whose main results we reproduced.},
	language = {en},
	number = {2},
	urldate = {2024-05-16},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Obels, Pepijn and Lakens, Daniël and Coles, Nicholas A. and Gottfried, Jaroslav and Green, Seth A.},
	month = jun,
	year = {2020},
	note = {Publisher: SAGE Publications Inc},
	pages = {229--237},
	file = {SAGE PDF Full Text:/home/amy/Zotero/storage/PDZCB4EC/Obels et al. - 2020 - Analysis of Open Data and Computational Reproducib.pdf:application/pdf},
}

@article{shoaib_simulation_2022,
	title = {Simulation modeling and analysis of primary health center operations},
	volume = {98},
	issn = {0037-5497},
	url = {https://doi.org/10.1177/00375497211030931},
	doi = {10.1177/00375497211030931},
	abstract = {We present discrete-event simulation models of the operations of primary health centers (PHCs) in the Indian context. Our PHC simulation models incorporate four types of patients seeking medical care: outpatients, inpatients, childbirth cases, and patients seeking antenatal care. A generic modeling approach was adopted to develop simulation models of PHC operations. This involved developing an archetype PHC simulation, which was then adapted to represent two other PHC configurations, differing in numbers of resources and types of services provided, encountered during PHC visits. A model representing a benchmark configuration conforming to government-mandated operational guidelines, with demand estimated from disease burden data and service times closer to international estimates (higher than observed), was also developed. Simulation outcomes for the three observed configurations indicate negligible patient waiting times and low resource utilization values at observed patient demand estimates. However, simulation outcomes for the benchmark configuration indicated significantly higher resource utilization. Simulation experiments to evaluate the effect of potential changes in operational patterns on reducing the utilization of stressed resources for the benchmark case were performed. Our analysis also motivated the development of simple analytical approximations of the average utilization of a server in a queueing system with characteristics similar to the PHC doctor/patient system. Our study represents the first step in an ongoing effort to establish the computational infrastructure required to analyze public health operations in India and can provide researchers in other settings with hierarchical health systems, a template for the development of simulation models of their primary healthcare facilities.},
	language = {en},
	number = {3},
	urldate = {2024-05-16},
	journal = {SIMULATION},
	author = {Shoaib, Mohd and Ramamohan, Varun},
	month = mar,
	year = {2022},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {183--208},
	file = {SAGE PDF Full Text:/home/amy/Zotero/storage/A4MHYUVG/Shoaib and Ramamohan - 2022 - Simulation modeling and analysis of primary health.pdf:application/pdf},
}

@article{gentleman_statistical_2007,
	title = {Statistical {Analyses} and {Reproducible} {Research}},
	volume = {16},
	issn = {1061-8600},
	url = {https://doi.org/10.1198/106186007X178663},
	doi = {10.1198/106186007X178663},
	abstract = {It is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, and so on with the documents that describe and rely on them. This integration allows readers to both verify and adapt the claims in the documents. Authors can easily reproduce the results in the future, and they can present the document's contents in a different medium, for example, with interactive controls. This article describes a software framework for both authoring and distributing these integrated, dynamic documents that contain text, code, data, and any auxiliary content needed to recreate the computations. The documents are dynamic in that the contents—including figures, tables, and so on—can be recalculated each time a view of the document is generated. Our model treats a dynamic document as a master or “source” document from which one can generate different views in the form of traditional, derived documents for different audiences. We introduce the concept of a compendium as a container for one or more dynamic documents and the different elements needed when processing them, such as code and data. The compendium serves as a means for distributing, managing, and updating the collection. The step from disseminating analyses via a compendium to reproducible research is a small one. By reproducible research, we mean research papers with accompanying software tools that allow the reader to directly reproduce the results and employ the computational methods that are presented in the research paper. Some of the issues involved in paradigms for the production, distribution, and use of such reproducible research are discussed.},
	number = {1},
	urldate = {2024-05-17},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Gentleman, Robert and Temple Lang, Duncan},
	month = mar,
	year = {2007},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/106186007X178663},
	keywords = {R, Compendium, Dynamic documents, Literate programming, Markup language, Perl, Python},
	pages = {1--23},
	file = {Full Text PDF:/home/amy/Zotero/storage/K5NJYR9L/Gentleman and Temple Lang - 2007 - Statistical Analyses and Reproducible Research.pdf:application/pdf},
}

@article{arguillas_10_2022,
	title = {10 {Things} for {Curating} {Reproducible} and {FAIR} {Research}},
	url = {https://zenodo.org/records/6797657},
	doi = {https://doi.org/10.15497/RDA00074},
	abstract = {This document, "10 Things for Curating Reproducible and FAIR Research," describes the key issues of curating reproducible and FAIR research (CURE-FAIR). It lists standards-based guidelines for ten practices, focusing primarily on research compendia produced by quantitative data-driven social science.


The "10 CURE-FAIR Things" are intended primarily for data curators and information professionals who are charged with publication and archival of FAIR and computationally reproducible research. Often the first re-users of the research compendium, they have the opportunity to verify that a computation can be executed and that it can reproduce pre-specified results. Secondarily, the "10 CURE-FAIR Things" will be of interest to researchers, publishers, editors, reviewers, and others who have a stake in creating, using, sharing, publishing, or preserving reproducible research.},
	language = {eng},
	urldate = {2024-05-20},
	author = {Arguillas, Florio and Christian, Thu-Mai and Gooch, Mandy and Honeyman, Tom and Peer, Limor and WG, CURE-FAIR},
	month = jun,
	year = {2022},
	note = {Publisher: Zenodo},
	file = {Full Text PDF:/home/amy/Zotero/storage/SAQGXU62/Arguillas et al. - 2022 - 10 Things for Curating Reproducible and FAIR Resea.pdf:application/pdf},
}

@article{marwick_packaging_2018,
	title = {Packaging {Data} {Analytical} {Work} {Reproducibly} {Using} {R} (and {Friends})},
	volume = {72},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2017.1375986},
	doi = {10.1080/00031305.2017.1375986},
	abstract = {Computers are a central tool in the research process, enabling complex and large-scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensuring that this research is reproducible. To address this challenge, we review the concept of the research compendium as a solution for providing a standard and easily recognizable way for organizing the digital materials of a research project to enable other researchers to inspect, reproduce, and extend the research. We investigate how the structure and tooling of software packages of the R programming language are being used to produce research compendia in a variety of disciplines. We also describe how software engineering tools and services are being used by researchers to streamline working with research compendia. Using real-world examples, we show how researchers can improve the reproducibility of their work using research compendia based on R packages and related tools.},
	number = {1},
	urldate = {2024-05-20},
	journal = {The American Statistician},
	author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
	month = jan,
	year = {2018},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2017.1375986},
	keywords = {Computational science, Reproducible research, Data science, Open source software},
	pages = {80--88},
	file = {Full Text PDF:/home/amy/Zotero/storage/9H6L9257/Marwick et al. - 2018 - Packaging Data Analytical Work Reproducibly Using .pdf:application/pdf},
}

@misc{association_for_computing_machinery_acm_artifact_2020,
	title = {Artifact {Review} and {Badging} {Version} 1.1},
	url = {https://www.acm.org/publications/policies/artifact-review-and-badging-current},
	language = {en},
	urldate = {2024-05-20},
	journal = {ACM},
	author = {{Association for Computing Machinery (ACM)}},
	month = aug,
	year = {2020},
	file = {Snapshot:/home/amy/Zotero/storage/QM37RS4C/artifact-review-and-badging-current.html:text/html},
}

@misc{blohowiak_badges_2023,
	title = {Badges to {Acknowledge} {Open} {Practices}},
	url = {https://osf.io/tvyxz/},
	abstract = {The aim is to specify a standard by which we can say that a scientific study has been conducted in accordance with open-science principles and provide visual icons to allow advertising of such good behaviours. 
    Hosted on the Open Science Framework},
	language = {en},
	urldate = {2024-05-20},
	author = {Blohowiak, Ben B. and Cohoon, Johanna and de-Wit, Lee and Eich, Eric and Farach, Frank J. and Hasselman, Fred and Holcombe, Alex O. and Humphreys, Macartan and Lewis, Melissa and Nosek, Brian A.},
	month = sep,
	year = {2023},
	note = {Publisher: OSF},
	file = {Snapshot:/home/amy/Zotero/storage/Z62G42T5/tvyxz.html:text/html},
}

@misc{institute_of_electrical_and_electronics_engineers_ieee_about_2024,
	title = {About {Content} in {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/Xplorehelp/overview-of-ieee-xplore/about-content},
	urldate = {2024-05-20},
	journal = {IEEE Explore},
	author = {{Institute of Electrical and Electronics Engineers (IEEE)}},
	year = {2024},
	file = {About Content in IEEE Xplore:/home/amy/Zotero/storage/EI83P87Z/about-content.html:text/html},
}

@misc{springer_nature_springer_2018,
	title = {Springer {Nature} {Open} data badge},
	url = {https://badgr.com/public/badges/xhW4FLHBRe6Tzz2Cj4Q1tA},
	urldate = {2024-05-20},
	journal = {Canvas Badges},
	author = {{Springer Nature}},
	month = jul,
	year = {2018},
	file = {Springer Nature Open data badge - Canvas Badges:/home/amy/Zotero/storage/JCSU3UQI/xhW4FLHBRe6Tzz2Cj4Q1tA.html:text/html},
}

@article{van_lissa_worcs_2021,
	title = {{WORCS}: {A} workflow for open reproducible code in science},
	volume = {4},
	issn = {2451-8484},
	shorttitle = {{WORCS}},
	url = {https://content.iospress.com/articles/data-science/ds210031},
	doi = {10.3233/DS-210031},
	abstract = {Adopting open science principles can be challenging, requiring conceptual education and training in the use of new tools. This paper introduces the Workflow for Open Reproducible Code in Science (WORCS): A step-by-step procedure that researchers can},
	language = {en},
	number = {1},
	urldate = {2024-05-20},
	journal = {Data Science},
	author = {Van Lissa, Caspar J. and Brandmaier, Andreas M. and Brinkman, Loek and Lamprecht, Anna-Lena and Peikert, Aaron and Struiksma, Marijn E. and Vreede, Barbara M. I.},
	month = jan,
	year = {2021},
	note = {Publisher: IOS Press},
	pages = {29--49},
	file = {Full Text PDF:/home/amy/Zotero/storage/N5P5IQ8K/Van Lissa et al. - 2021 - WORCS A workflow for open reproducible code in sc.pdf:application/pdf},
}

@misc{association_for_psychological_science_aps_psychological_2024,
	title = {Psychological {Science} {Submission} {Guidelines}},
	url = {https://www.psychologicalscience.org/publications/psychological_science/ps-submissions},
	urldate = {2024-11-20},
	journal = {APS},
	author = {{Association for Psychological Science (APS)}},
	month = sep,
	year = {2024},
	file = {Psychological Science Submission Guidelines – Association for Psychological Science – APS:/home/amy/Zotero/storage/MEJIJ7DC/ps-submissions.html:text/html},
}

@article{monks_strengthening_2019,
	title = {Strengthening the reporting of empirical simulation studies: {Introducing} the {STRESS} guidelines},
	volume = {13},
	issn = {1747-7778},
	shorttitle = {Strengthening the reporting of empirical simulation studies},
	url = {https://doi.org/10.1080/17477778.2018.1442155},
	doi = {10.1080/17477778.2018.1442155},
	abstract = {This study develops a standardised checklist approach to improve the reporting of discrete-event simulation, system dynamics and agent-based simulation models within the field of Operational Research and Management Science. Incomplete or ambiguous reporting means that many simulation studies are not reproducible, leaving other modellers with an incomplete picture of what has been done and unable to judge the reliability of the results. Crucially, unclear reporting makes it difficult to reproduce or reuse findings. In this paper, we review the evidence on the quality of model reporting and consolidate previous work. We derive general good practice principles and three 20-item checklists aimed at Strengthening The Reporting of Empirical Simulation Studies (STRESS): STRESS-DES, STRESS-ABS and STRESS-SD for discrete-event simulation, agent-based simulation and system dynamics, respectively. Given the variety of simulation projects, we provide usage and troubleshooting advice to cover a wide range of situations.},
	number = {1},
	urldate = {2024-05-21},
	journal = {Journal of Simulation},
	author = {Monks, Thomas and Currie, Christine S. M. and Onggo, Bhakti Stephan and Robinson, Stewart and Kunc, Martin and Taylor, Simon J. E.},
	month = jan,
	year = {2019},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/17477778.2018.1442155},
	keywords = {reproducibility, Simulation, agent-based simulation, discrete-event simulation, reporting, system dynamics},
	pages = {55--67},
	file = {Full Text PDF:/home/amy/Zotero/storage/A6EXSEUH/Monks et al. - 2019 - Strengthening the reporting of empirical simulatio.pdf:application/pdf},
}

@article{zhang_reporting_2020,
	title = {Reporting {Quality} of {Discrete} {Event} {Simulations} in {Healthcare}—{Results} {From} a {Generic} {Reporting} {Checklist}},
	volume = {23},
	issn = {1098-3015},
	url = {https://www.sciencedirect.com/science/article/pii/S1098301520300401},
	doi = {10.1016/j.jval.2020.01.005},
	abstract = {Objectives
The aims of this study were to formulate a generic reporting checklist for healthcare-related discrete event simulation (DES) studies and to critically appraise the existing studies.
Methods
Based on the principles of accessibility and generality, assessment items were derived from the International Society for Pharmacoeconomics and Outcomes Research (ISPOR)–Society for Medical Decision Making (SMDM) Task Force reports. The resulting checklist was applied to all 211 DES studies identified in a previous review. The proportion of fulfilled checklist items served as an indicator of reporting quality. A logistic regression was conducted to investigate whether study characteristics (eg, publication before or after the publication of the ISPOR-SMDM reports) increased the likelihood of fulfilling more than the mean number of items fulfilled by the appraised DES studies.
Results
An 18-item checklist was formulated covering model conceptualization, parameterization and uncertainty assessment, validation, generalizability, and stakeholder involvement. The reporting quality of the DES models fluctuated around the mean of 63.7\% (SD 11.0\%) over the period studied. A modest nonsignificant improvement in reporting quality was found after the publication of the ISPOR-SMDM reports (64.5\% vs 62.9\%). Items with the lowest performance were related to predictive validation (2.8\% of studies), cross validation (8.5\%), face validity assessment (26.5\%), and stakeholder involvement (27.5\%). Models applied to health economic evaluation (HEE), country under study, and industry sponsorship were significantly associated with the odds of achieving above-average reporting quality.
Conclusions
The checklist is applicable across various model-based analyses beyond HEEs. Adherence to the ISPOR-SMDM guidelines should be improved, particularly regarding model validation.},
	number = {4},
	urldate = {2024-05-21},
	journal = {Value in Health},
	author = {Zhang, Xiange and Lhachimi, Stefan K. and Rogowski, Wolf H.},
	month = apr,
	year = {2020},
	keywords = {discrete event simulation, healthcare decision modeling, reporting quality checklist},
	pages = {506--514},
	file = {Full Text:/home/amy/Zotero/storage/YW3KDRF5/Zhang et al. - 2020 - Reporting Quality of Discrete Event Simulations in.pdf:application/pdf;ScienceDirect Snapshot:/home/amy/Zotero/storage/YGMNWH9Z/S1098301520300401.html:text/html},
}

@misc{wickham_12_2023,
	title = {12 {Licensing}},
	url = {https://r-pkgs.org/license.html},
	urldate = {2024-05-21},
	journal = {R Packages (2e)},
	author = {Wickham, Hadley and Bryan, Jennifer},
	month = apr,
	year = {2023},
	file = {R Packages (2e):/home/amy/Zotero/storage/Q3A9UUCD/r-pkgs.org.html:text/html},
}

@article{grimm_odd_2020,
	title = {The {ODD} {Protocol} for {Describing} {Agent}-{Based} and {Other} {Simulation} {Models}: {A} {Second} {Update} to {Improve} {Clarity}, {Replication}, and {Structural} {Realism}},
	volume = {23},
	issn = {1460-7425},
	shorttitle = {The {ODD} {Protocol} for {Describing} {Agent}-{Based} and {Other} {Simulation} {Models}},
	number = {2},
	journal = {Journal of Artificial Societies and Social Simulation},
	author = {Grimm, Volker and Railsback, Steven F. and Vincenot, Christian E. and Berger, Uta and Gallagher, Cara and DeAngelis, Donald L. and Edmonds, Bruce and Ge, Jiaqi and Giske, Jarl and Groeneveld, Jürgen and Johnston, Alice S. A. and Milles, Alexander and Nabe-Nielsen, Jacob and Polhill, J. Gareth and Radchuk, Viktoriia and Rohwäder, Marie-Sophie and Stillman, Richard A. and Thiele, Jan C. and Ayllón, Daniel},
	year = {2020},
	pages = {7},
	file = {The ODD Protocol for Describing Agent-Based and Other Simulation Models:/home/amy/Zotero/storage/64RFYUQG/7.html:text/html},
}

@article{husereau_consolidated_2013,
	title = {Consolidated {Health} {Economic} {Evaluation} {Reporting} {Standards} ({CHEERS}) {Statement}},
	volume = {16},
	issn = {1098-3015},
	url = {https://www.sciencedirect.com/science/article/pii/S109830151300065X},
	doi = {10.1016/j.jval.2013.02.010},
	abstract = {Economic evaluations of health interventions pose a particular challenge for reporting. There is also a need to consolidate and update existing guidelines and promote their use in a user friendly manner. The Consolidated Health Economic Evaluation Reporting Standards (CHEERS) statement is an attempt to consolidate and update previous health economic evaluation guidelines efforts into one current, useful reporting guidance. The primary audiences for the CHEERS statement are researchers reporting economic evaluations and the editors and peer reviewers assessing them for publication. The need for new reporting guidance was identified by a survey of medical editors. A list of possible items based on a systematic review was created. A two round, modified Delphi panel consisting of representatives from academia, clinical practice, industry, government, and the editorial community was conducted. Out of 44 candidate items, 24 items and accompanying recommendations were developed. The recommendations are contained in a user friendly, 24 item checklist. A copy of the statement, accompanying checklist, and this report can be found on the ISPOR Health Economic Evaluations Publication Guidelines Task Force website: (www.ispor.org/TaskForces/EconomicPubGuidelines.asp). We hope CHEERS will lead to better reporting, and ultimately, better health decisions. To facilitate dissemination and uptake, the CHEERS statement is being co-published across 10 health economics and medical journals. We encourage other journals and groups, to endorse CHEERS. The author team plans to review the checklist for an update in five years.},
	number = {2},
	urldate = {2024-05-21},
	journal = {Value in Health},
	author = {Husereau, Don and Drummond, Michael and Petrou, Stavros and Carswell, Chris and Moher, David and Greenberg, Dan and Augustovski, Federico and Briggs, Andrew H. and Mauskopf, Josephine and Loder, Elizabeth},
	month = mar,
	year = {2013},
	keywords = {humans, biomedical research/methods, biomedical research/standards, costs and cost analysis, guidelines as topic/standards, publishing/standards},
	pages = {e1--e5},
	file = {ScienceDirect Snapshot:/home/amy/Zotero/storage/5R5W5AML/S109830151300065X.html:text/html},
}

@inproceedings{taylor_open_2017,
	title = {Open science: {Approaches} and benefits for modeling \& simulation},
	shorttitle = {Open science},
	url = {https://ieeexplore.ieee.org/document/8247813},
	doi = {10.1109/WSC.2017.8247813},
	abstract = {Open Science is the practice of making scientific research accessible to all. It promotes open access to the artefacts of research, the software, data, results and the scientific articles in which they appear, so that others can validate, use and collaborate. Open Science is also being mandated by many funding bodies. The concept of Open Science is new to many Modelling \& Simulation (M\&S) researchers. To introduce Open Science to our field, this paper unpacks Open Science to understand some of its approaches and benefits. Good practice in the reporting of simulation studies is discussed and the Strengthening the Reporting of Empirical Simulation Studies (STRESS) standardized checklist approach is presented. A case study shows how Digital Object Identifiers, Researcher Registries, Open Access Data Repositories and Scientific Gateways can support Open Science practices for M\&S research. The article concludes with a set of guidelines for adopting Open Science for M\&S.},
	urldate = {2024-06-04},
	booktitle = {2017 {Winter} {Simulation} {Conference} ({WSC})},
	author = {Taylor, Simon J. E. and Anagnostou, Anastasia and Fabiyi, Adedeji and Currie, Christine and Monks, Thomas and Barbera, Roberto and Becker, Bruce},
	month = dec,
	year = {2017},
	note = {ISSN: 1558-4305},
	keywords = {Computational modeling, Gold, Licenses, Logic gates, Object recognition, Open Access},
	pages = {535--549},
	file = {IEEE Xplore Abstract Record:/home/amy/Zotero/storage/G5495T7Y/8247813.html:text/html;IEEE Xplore Full Text PDF:/home/amy/Zotero/storage/WYRPR9KZ/Taylor et al. - 2017 - Open science Approaches and benefits for modeling.pdf:application/pdf},
}

@misc{the_open_modeling_foundation_omf_reusability_2024,
	type = {{OMF}},
	title = {Reusability {Standards}},
	url = {https://www.openmodelingfoundation.org/standards/reusability/},
	urldate = {2024-06-04},
	author = {{The Open Modeling Foundation (OMF)}},
	month = may,
	year = {2024},
	file = {Reusability | The Open Modeling Foundation:/home/amy/Zotero/storage/E454YHB4/reusability.html:text/html},
}

@article{monks_supplementary_2024,
	title = {Supplementary {Materials}: {Computer} model and code sharing practices in healthcare discrete-event simulation: a systematic scoping review. v1.2.0.},
	shorttitle = {Supplementary {Materials}},
	url = {https://zenodo.org/records/11490636},
	doi = {10.5281/zenodo.11490636},
	abstract = {Computer model and code sharing practices in healthcare discrete-event simulation: a systematic scoping review

Overview

The materials, code, and data in this repository support: Monks and Harper (2023). Computer model and code sharing practices in healthcare discrete-event simulation: a systematic scoping review. All materials are published under an MIT permissive

Write up of study

Methods, and Results are kept up to date in our online Jupyter Book https://tommonks.github.io/des\_sharing\_lit\_review

A full write-up of the work is available open access in the Journal of Simulation. If you use this work please cite the paper.

Monks, T., \& Harper, A. (2023). Computer model and code sharing practices in healthcare discrete-event simulation: a systematic scoping review. Journal of Simulation, 1–16. https://doi.org/10.1080/17477778.2023.2260772 

Changes



CITE: added citation file

README: updated overview of repository

README: added citation to Journal of Simulation article.},
	urldate = {2024-06-06},
	journal = {Zenodo},
	author = {Monks, Thomas and Harper, Alison},
	month = jun,
	year = {2024},
	keywords = {Systematic review, Discrete-Event Simulation, Healthcare, Open models, Open Science},
	file = {Snapshot:/home/amy/Zotero/storage/BIVEYHET/11490636.html:text/html},
}

@misc{the_linux_foundation_docker_nodate,
	title = {Docker containers: {What} are the open source licensing considerations?},
	url = {https://www.linuxfoundation.org/resources/publications/docker-containers-what-are-the-open-source-licensing-considerations},
	urldate = {2024-06-06},
	journal = {The Linux Foundation},
	author = {{The Linux Foundation}},
	file = {Docker containers\: What are the open source licensing considerations?:/home/amy/Zotero/storage/X3LYAEL5/docker-containers-what-are-the-open-source-licensing-considerations.html:text/html},
}

@misc{noauthor_docker_nodate,
	title = {Docker containers: {What} are the open source licensing considerations?},
	shorttitle = {Docker containers},
	url = {https://www.linuxfoundation.org/resources/publications/docker-containers-what-are-the-open-source-licensing-considerations},
	abstract = {Tap into the latest open source publications. Discover insights from our projects and open technology thought leaders.},
	language = {en},
	urldate = {2024-06-06},
	file = {Snapshot:/home/amy/Zotero/storage/XI6YY48D/docker-containers-what-are-the-open-source-licensing-considerations.html:text/html},
}

@misc{hoces_how_2020,
	title = {How to {Teach} {Reproducibility} in {Classwork}},
	url = {https://bitss.github.io/WEAI2020_slides},
	abstract = {https://github.com/BITSS/WEAI2020\_slides},
	urldate = {2024-06-12},
	author = {Hoces, Fernando},
	month = jun,
	year = {2020},
	file = {Hoces - 2020 - How to Teach Reproducibility in Classwork.pdf:/home/amy/Zotero/storage/P86MPQGM/Hoces - 2020 - How to Teach Reproducibility in Classwork.pdf:application/pdf},
}

@article{allen_simulation_2020,
	title = {A simulation modelling toolkit for organising outpatient dialysis services during the {COVID}-19 pandemic},
	volume = {15},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0237628},
	doi = {10.1371/journal.pone.0237628},
	abstract = {This study presents two simulation modelling tools to support the organisation of networks of dialysis services during the COVID-19 pandemic. These tools were developed to support renal services in the South of England (the Wessex region caring for 650 dialysis patients), but are applicable elsewhere. A discrete-event simulation was used to model a worst case spread of COVID-19, to stress-test plans for dialysis provision throughout the COVID-19 outbreak. We investigated the ability of the system to manage the mix of COVID-19 positive and negative patients, the likely effects on patients, outpatient workloads across all units, and inpatient workload at the centralised COVID-positive inpatient unit. A second Monte-Carlo vehicle routing model estimated the feasibility of patient transport plans. If current outpatient capacity is maintained there is sufficient capacity in the South of England to keep COVID-19 negative/recovered and positive patients in separate sessions, but rapid reallocation of patients may be needed. Outpatient COVID-19 cases will spillover to a secondary site while other sites will experience a reduction in workload. The primary site chosen to manage infected patients will experience a significant increase in outpatients and inpatients. At the peak of infection, it is predicted there will be up to 140 COVID-19 positive patients with 40 to 90 of these as inpatients, likely breaching current inpatient capacity. Patient transport services will also come under considerable pressure. If patient transport operates on a policy of one positive patient at a time, and two-way transport is needed, a likely scenario estimates 80 ambulance drive time hours per day (not including fixed drop-off and ambulance cleaning times). Relaxing policies on individual patient transport to 2-4 patients per trip can save 40-60\% of drive time. In mixed urban/rural geographies steps may need to be taken to temporarily accommodate renal COVID-19 positive patients closer to treatment facilities.},
	language = {en},
	number = {8},
	urldate = {2024-06-17},
	journal = {PLOS ONE},
	author = {Allen, Michael and Bhanji, Amir and Willemsen, Jonas and Dudfield, Steven and Logan, Stuart and Monks, Thomas},
	month = aug,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Ambulances, Outpatients, COVID 19, Inpatients, Medical dialysis, Pandemics, Respiratory infections, Simulation and modeling},
	pages = {e0237628},
	file = {Full Text PDF:/home/amy/Zotero/storage/S5F2FSBS/Allen et al. - 2020 - A simulation modelling toolkit for organising outp.pdf:application/pdf},
}

@misc{conda_contributors_conda_2023,
	title = {conda: {A} system-level, binary package and environment manager running on all major   operating systems and platforms.},
	url = {https://docs.conda.io/projects/conda/},
	abstract = {Conda is a cross-platform, language-agnostic binary package manager. It is the package manager
  used by Anaconda installations, but it may be used for other systems as well. Conda makes
  environments first-class citizens, making it easy to create independent environments even for
  C libraries. Conda is written entirely in Python, and is BSD licensed open source.},
	author = {{conda contributors}},
	month = jul,
	year = {2023},
}

@misc{python_packaging_authority_virtualenv_2023,
	title = {virtualenv: {Virtual} {Python} {Environment} builder},
	url = {https://virtualenv.pypa.io/en/latest/},
	author = {{Python Packaging Authority}},
	month = dec,
	year = {2023},
}

@misc{r_core_team_r_2024,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2024},
}

@misc{python_core_team_python_2024,
	title = {Python},
	url = {https://www.python.org/},
	publisher = {Python Software Foundation},
	author = {{Python Core Team}},
	year = {2024},
}

@misc{allaire_quarto_2024,
	title = {Quarto},
	url = {https://github.com/quarto-dev/quarto-cli},
	author = {Allaire, J. J. and Teague, Charles and Scheidegger, Carlos and Xie, Yihui and Dervieux, Christophe},
	month = feb,
	year = {2024},
	note = {10.5281/zenodo.5960048},
}

@article{merkel_docker_2014,
	title = {Docker: lightweight {Linux} containers for consistent development and deployment},
	volume = {2014},
	issn = {1075-3583},
	shorttitle = {Docker},
	abstract = {Docker promises the ability to package applications and their dependencies into lightweight containers that move easily between different distros, start up quickly and are isolated from each other.},
	number = {239},
	journal = {Linux Journal},
	author = {Merkel, Dirk},
	month = mar,
	year = {2014},
	pages = {2:2},
}

@misc{ushey_renv_2024,
	title = {renv: {Project} {Environments}},
	url = {https://rstudio.github.io/renv/},
	author = {Ushey, Kevin and Wickham, Hadley},
	year = {2024},
}

@book{national_academies_of_sciences_engineering_and_medicine_reproducibility_2019,
	address = {Washington (DC)},
	title = {Reproducibility and {Replicability} in {Science}},
	copyright = {Copyright 2019 by the National Academy of Sciences. All rights reserved.},
	isbn = {978-0-309-48616-3},
	url = {http://www.ncbi.nlm.nih.gov/books/NBK547537/},
	abstract = {One of the pathways by which the scientific community confirms the validity of a new scientific discovery is by repeating the research that produced it. When a scientific effort fails to independently confirm the computations or results of a previous study, some fear that it may be a symptom of a lack of rigor in science, while others argue that such an observed inconsistency can be an important precursor to new discovery. Concerns about reproducibility and replicability have been expressed in both scientific and popular media. As these concerns came to light, Congress requested that the National Academies of Sciences, Engineering, and Medicine conduct a study to assess the extent of issues related to reproducibility and replicability and to offer recommendations for improving rigor and transparency in scientific research. Reproducibility and Replicability in Science defines reproducibility and replicability and examines the factors that may lead to non-reproducibility and non-replicability in research. Unlike the typical expectation of reproducibility between two computations, expectations about replicability are more nuanced, and in some cases a lack of replicability can aid the process of scientific discovery. This report provides recommendations to researchers, academic institutions, journals, and funders on steps they can take to improve reproducibility and replicability in science.},
	language = {eng},
	urldate = {2024-06-18},
	publisher = {National Academies Press (US)},
	author = {{National Academies of Sciences, Engineering, and Medicine} and {Policy and Global Affairs} and {Committee on Science, Engineering, Medicine, and Public Policy} and {Board on Research Data and Information} and {Division on Engineering and Physical Sciences} and {Committee on Applied and Theoretical Statistics} and {Board on Mathematical Sciences and Analytics} and {Division on Earth and Life Studies} and {Nuclear and Radiation Studies Board} and {Division of Behavioral and Social Sciences and Education} and {Committee on National Statistics; Board on Behavioral, Cognitive, and Sensory Sciences} and {Committee on Reproducibility and Replicability in Science}},
	year = {2019},
	pmid = {31596559},
}

@misc{heather_template_2024,
	title = {Template for computational reproducibility assessments on {STARS}},
	url = {https://zenodo.org/doi/10.5281/zenodo.12168890},
	abstract = {Template repository for assessing the computational reproducibility of discrete-event simulation studies on STARS.},
	urldate = {2024-06-19},
	publisher = {Zenodo},
	author = {Heather, Amy and Monks, Thomas and Harper, Alison and Mustafee, Navonil and Mayne, Andrew},
	month = jun,
	year = {2024},
	file = {Snapshot:/home/amy/Zotero/storage/BAVEFBUV/12168891.html:text/html},
}

@article{shoaib_simulation_2021,
	title = {Simulation {Modelling} and {Analysis} of {Primary} {Health} {Centre} {Operations}},
	url = {https://arxiv.org/abs/2104.12492},
	doi = {10.48550/arXiv.2104.12492},
	abstract = {We present discrete-event simulation models of the operations of primary health centres (PHCs) in the Indian context. Our PHC simulation models incorporate four types of patients seeking medical care: outpatients, inpatients, childbirth cases, and patients seeking antenatal care. A generic modelling approach was adopted to develop simulation models of PHC operations. This involved developing an archetype PHC simulation, which was then adapted to represent two other PHC configurations, differing in numbers of resources and types of services provided, encountered during PHC visits. A model representing a benchmark configuration conforming to government-mandated operational guidelines, with demand estimated from disease burden data and service times closer to international estimates (higher than observed), was also developed. Simulation outcomes for the three observed configurations indicate negligible patient waiting times and low resource utilisation values at observed patient demand estimates. However, simulation outcomes for the benchmark configuration indicated significantly higher resource utilisation. Simulation experiments to evaluate the effect of potential changes in operational patterns on reducing the utilisation of stressed resources for the benchmark case were performed. Our analysis also motivated the development of simple analytical approximations of the average utilisation of a server in a queueing system with characteristics similar to the PHC doctor/patient system. Our study represents the first step in an ongoing effort to establish the computational infrastructure required to analyse public health operations in India, and can provide researchers in other settings with hierarchical health systems a template for the development of simulation models of their primary healthcare facilities.},
	urldate = {2024-06-20},
	journal = {arXiv},
	author = {Shoaib, Mohd and Ramamohan, Varun},
	month = jun,
	year = {2021},
	note = {arXiv:2104.12492 [cs, stat]},
	keywords = {Computer Science - Computers and Society, Statistics - Applications},
	file = {arXiv Fulltext PDF:/home/amy/Zotero/storage/I5EPLMJ4/Shoaib and Ramamohan - 2022 - Simulation Modelling and Analysis of Primary Healt.pdf:application/pdf;arXiv.org Snapshot:/home/amy/Zotero/storage/3EYXWPHK/2104.html:text/html},
}

@article{huang_optimizing_2019,
	title = {Optimizing {Resources} for {Endovascular} {Clot} {Retrieval} for {Acute} {Ischemic} {Stroke}, a {Discrete} {Event} {Simulation}},
	volume = {10},
	issn = {1664-2295},
	url = {https://www.frontiersin.org/journals/neurology/articles/10.3389/fneur.2019.00653/full},
	doi = {10.3389/fneur.2019.00653},
	abstract = {{\textless}p{\textgreater}{\textless}bold{\textgreater}Objective:{\textless}/bold{\textgreater} Endovascular clot retrieval (ECR) is the standard of care for acute ischemic stroke due to large vessel occlusion. Performing ECR is a time critical and complex process involving many specialized care providers and resources. Maximizing patient benefit while minimizing service cost requires optimization of human and physical assets. The aim of this study is to develop a general computational model of an ECR service, which can be used to optimize resource allocation.{\textless}/p{\textgreater}{\textless}p{\textgreater}{\textless}bold{\textgreater}Methods:{\textless}/bold{\textgreater} Using a discrete event simulation approach, we examined ECR performance under a range of possible scenarios and resource use configurations.{\textless}/p{\textgreater}{\textless}p{\textgreater}{\textless}bold{\textgreater}Results:{\textless}/bold{\textgreater} The model demonstrated the impact of competing emergency interventional cases upon ECR treatment times and time impact of allocating more physical (more angiographic suites) or staff resources (extending work hours).{\textless}/p{\textgreater}{\textless}p{\textgreater}{\textless}bold{\textgreater}Conclusion:{\textless}/bold{\textgreater} Our DES model can be used to optimize resources for interventional treatment of acute ischemic stroke and large vessel occlusion. This proof-of-concept study of computational simulation of resource allocation for ECR can be easily extended. For example, center-specific cost data may be incorporated to optimize resource allocation and overall health care value.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2024-07-04},
	journal = {Frontiers in Neurology},
	author = {Huang, Shiwei and Maingard, Julian and Kok, Hong Kuan and Barras, Christen D. and Thijs, Vincent and Chandra, Ronil V. and Brooks, Duncan Mark and Asadi, Hamed},
	month = jun,
	year = {2019},
	note = {Publisher: Frontiers},
	keywords = {discrete event simulation (DES), ECR, endovascular clot retrieval, Mechanical thrombectomy, Resource Allocation, Resource optimization, workflow simulation},
	file = {Full Text:/home/amy/Zotero/storage/F2S2NMN6/Huang et al. - 2019 - Optimizing Resources for Endovascular Clot Retriev.pdf:application/pdf},
}

@article{lim_staff_2020,
	title = {Staff rostering, split team arrangement, social distancing (physical distancing) and use of personal protective equipment to minimize risk of workplace transmission during the {COVID}-19 pandemic: {A} simulation study},
	volume = {86},
	issn = {0009-9120},
	shorttitle = {Staff rostering, split team arrangement, social distancing (physical distancing) and use of personal protective equipment to minimize risk of workplace transmission during the {COVID}-19 pandemic},
	url = {https://www.sciencedirect.com/science/article/pii/S0009912020308390},
	doi = {10.1016/j.clinbiochem.2020.09.003},
	abstract = {Background
The recent global survey promoted by the International Federation of Clinical Chemistry and Laboratory Medicine (IFCC) Taskforce on COVID-19 (coronavirus disease 2019) described staff rostering and organization as significant operational challenges during the COVID-19 pandemic.
Method
A discrete event simulation was used to explore the impact of different permutations of staff roster, including the number of shifts per day, the number of staff on duty per shift, overall number of staff accessible to work in the laboratory (i.e. overall staff pool), the frequency of shift changes (i.e. number of consecutive days worked), fixed work-rest days and split team arrangement on workplace transmission of COVID-19 by a simulated index staff who acquired the infection from the community over 21 days. Additionally, the impact of workplace social distancing (physical distancing) and use of personal protective equipment (PPE) were investigated.
Results
A higher rate of transmission was associated with smaller overall staff pool (expressed as multiples of the number of staff per shift), higher number of shifts per day, higher number of staff per shift, and longer consecutive days worked. Having fixed work-rest arrangement did not significantly reduce the transmission rate unless the workplace outbreak was prolonged. Social distancing and PPE use significantly reduced the transmission rate.
Conclusion
Laboratories should consider organizing the staff into smaller teams/shift and reduce the number of consecutive days worked. Additionally, our observation aligns with the IFCC biosafety recommendation of monitoring staff health (to detect early infection), split team arrangement, workplace social distancing and use of PPE.},
	urldate = {2024-07-19},
	journal = {Clinical Biochemistry},
	author = {Lim, Chun Yee and Bohn, Mary Kathryn and Lippi, Giuseppe and Ferrari, Maurizio and Loh, Tze Ping and Yuen, Kwok-Yung and Adeli, Khosrow and Horvath, Andrea Rita},
	month = dec,
	year = {2020},
	keywords = {COVID-19, Biosafety, Laboratory management, Nosocomial infection, Social distancing, Staff roster},
	pages = {15--22},
	file = {Full Text:/home/amy/Zotero/storage/W5H2F7JI/Lim et al. - 2020 - Staff rostering, split team arrangement, social di.pdf:application/pdf;ScienceDirect Snapshot:/home/amy/Zotero/storage/3PGTFSK3/S0009912020308390.html:text/html},
}

@article{kim_modelling_2021,
	title = {Modelling the impact of changes to abdominal aortic aneurysm screening and treatment services in {England} during the {COVID}-19 pandemic},
	volume = {16},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0253327},
	doi = {10.1371/journal.pone.0253327},
	abstract = {Background The National Health Service (NHS) abdominal aortic aneurysm (AAA) screening programme (NAAASP) in England screens 65-year-old men. The programme monitors those with an aneurysm, and early intervention for large aneurysms reduces ruptures and AAA-related mortality. AAA screening services have been disrupted following COVID-19 but it is not known how this may impact AAA-related mortality, or where efforts should be focussed as services resume. Methods We repurposed a previously validated discrete event simulation model to investigate the impact of COVID-19-related service disruption on key outcomes. This model was used to explore the impact of delayed invitation and reduced attendance in men invited to screening. Additionally, we investigated the impact of temporarily suspending scans, increasing the threshold for elective surgery to 7cm and increasing drop-out in the AAA cohort under surveillance, using data from NAAASP to inform the population. Findings Delaying invitation to primary screening up to two years had little impact on key outcomes whereas a 10\% reduction in attendance could lead to a 2\% lifetime increase in AAA-related deaths. In surveillance patients, a 1-year suspension of surveillance or increase in the elective threshold resulted in a 0.4\% increase in excess AAA-related deaths (8\% in those 5–5.4cm at the start). Longer suspensions or a doubling of drop-out from surveillance would have a pronounced impact on outcomes. Interpretation Efforts should be directed towards encouraging men to attend AAA screening service appointments post-COVID-19. Those with AAAs on surveillance should be prioritised as the screening programme resumes, as changes to these services beyond one year are likely to have a larger impact on surgical burden and AAA-related mortality.},
	language = {en},
	number = {6},
	urldate = {2024-07-26},
	journal = {PLOS ONE},
	author = {Kim, Lois G. and Sweeting, Michael J. and Armer, Morag and Jacomelli, Jo and Nasim, Akhtar and Harrison, Seamus C.},
	month = jun,
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Medical risk factors, England, COVID 19, Pandemics, Aneurysms, Screening guidelines, Surgical and invasive medical procedures, Surgical repair},
	pages = {e0253327},
	file = {Full Text PDF:/home/amy/Zotero/storage/V8HBFWYI/Kim et al. - 2021 - Modelling the impact of changes to abdominal aorti.pdf:application/pdf},
}

@article{johnson_cost_2021,
	title = {Cost {Effectiveness} of {Case} {Detection} {Strategies} for the {Early} {Detection} of {COPD}},
	volume = {19},
	issn = {1179-1896},
	url = {https://doi.org/10.1007/s40258-020-00616-2},
	doi = {10.1007/s40258-020-00616-2},
	abstract = {The value of early detection and treatment of chronic obstructive pulmonary disease (COPD) is currently unknown. We assessed the cost effectiveness of primary care-based case detection strategies for COPD.},
	language = {en},
	number = {2},
	urldate = {2024-08-01},
	journal = {Applied Health Economics and Health Policy},
	author = {Johnson, Kate M. and Sadatsafavi, Mohsen and Adibi, Amin and Lynd, Larry and Harrison, Mark and Tavakoli, Hamid and Sin, Don D. and Bryan, Stirling},
	month = mar,
	year = {2021},
	pages = {203--215},
	file = {Full Text PDF:/home/amy/Zotero/storage/E4668TVI/Johnson et al. - 2021 - Cost Effectiveness of Case Detection Strategies fo.pdf:application/pdf},
}

@inproceedings{anagnostou_facs-charm_2022,
	title = {{FACS}-{CHARM}: {A} {Hybrid} {Agent}-{Based} and {Discrete}-{Event} {Simulation} {Approach} for {Covid}-19 {Management} at {Regional} {Level}},
	shorttitle = {{FACS}-{CHARM}},
	url = {https://ieeexplore.ieee.org/document/10015462},
	doi = {10.1109/WSC57314.2022.10015462},
	abstract = {Pandemics have huge impact on all aspect of people's lives. As we have experienced during the Coronavirus pandemic, healthcare, education and the economy have been put under extreme strain. It is important therefore to be able to respond to such events fast in order to limit the damage to the society. Decision-makers typically are advised by experts in order to inform their response strategies. One of the tools that is widely used to support evidence-based decisions is modeling and simulation. In this paper, we present a hybrid agent-based and discrete-event simulation for the Coronavirus pandemic management at regional level. Our model considers disease dynamics, population interactions and dynamic ICU bed capacity management and predicts the impact of various public health preventive measures on the population and the healthcare service.},
	urldate = {2024-08-01},
	booktitle = {2022 {Winter} {Simulation} {Conference} ({WSC})},
	author = {Anagnostou, Anastasia and Groen, Derek and Taylor, Simon J.E. and Suleimenova, Diana and Abubakar, Nura and Saha, Arindam and Mintram, Kate and Ghorbani, Maziar and Daroge, Habiba and Islam, Tasin and Xue, Yani and Okine, Edward and Anokye, Nana},
	month = dec,
	year = {2022},
	note = {ISSN: 1558-4305},
	keywords = {Sociology, Hospitals, Predictive models, Pandemics, COVID-19, Education, Statistics},
	pages = {1223--1234},
	file = {IEEE Xplore Abstract Record:/home/amy/Zotero/storage/42K7RQBK/10015462.html:text/html;IEEE Xplore Full Text PDF:/home/amy/Zotero/storage/L3M9SVUV/Anagnostou et al. - 2022 - FACS-CHARM A Hybrid Agent-Based and Discrete-Even.pdf:application/pdf},
}

@article{glover_discrete_2018,
	title = {Discrete {Event} {Simulation} for {Decision} {Modeling} in {Health} {Care}: {Lessons} from {Abdominal} {Aortic} {Aneurysm} {Screening}},
	volume = {38},
	issn = {0272-989X},
	shorttitle = {Discrete {Event} {Simulation} for {Decision} {Modeling} in {Health} {Care}},
	url = {https://doi.org/10.1177/0272989X17753380},
	doi = {10.1177/0272989X17753380},
	abstract = {Markov models are often used to evaluate the cost-effectiveness of new healthcare interventions but they are sometimes not flexible enough to allow accurate modeling or investigation of alternative scenarios and policies. A Markov model previously demonstrated that a one-off invitation to screening for abdominal aortic aneurysm (AAA) for men aged 65 y in the UK and subsequent follow-up of identified AAAs was likely to be highly cost-effective at thresholds commonly adopted in the UK (£20,000 to £30,000 per quality adjusted life-year). However, new evidence has emerged and the decision problem has evolved to include exploration of the circumstances under which AAA screening may be cost-effective, which the Markov model is not easily able to address. A new model to handle this more complex decision problem was needed, and the case of AAA screening thus provides an illustration of the relative merits of Markov models and discrete event simulation (DES) models. An individual-level DES model was built using the R programming language to reflect possible events and pathways of individuals invited to screening v. those not invited. The model was validated against key events and cost-effectiveness, as observed in a large, randomized trial. Different screening protocol scenarios were investigated to demonstrate the flexibility of the DES. The case of AAA screening highlights the benefits of DES, particularly in the context of screening studies.},
	language = {en},
	number = {4},
	urldate = {2024-08-02},
	journal = {Medical Decision Making},
	author = {Glover, Matthew J. and Jones, Edmund and Masconi, Katya L. and Sweeting, Michael J. and Thompson, Simon G. and Powell, Janet T. and Ulug, Pinar and Bown, Matthew J.},
	month = may,
	year = {2018},
	note = {Publisher: SAGE Publications Inc STM},
	pages = {439--451},
	file = {SAGE PDF Full Text:/home/amy/Zotero/storage/P2JPSDTZ/Glover et al. - 2018 - Discrete Event Simulation for Decision Modeling in.pdf:application/pdf},
}

@article{thompson_screening_2018,
	title = {Screening women aged 65 years or over for abdominal aortic aneurysm: a modelling study and health economic evaluation},
	volume = {22},
	issn = {1366-5278, 2046-4924},
	shorttitle = {Screening women aged 65 years or over for abdominal aortic aneurysm},
	url = {https://www.journalslibrary.nihr.ac.uk/hta/hta22430},
	doi = {10.3310/hta22430},
	abstract = {Background
              Abdominal aortic aneurysm (AAA) screening programmes have been established for men in the UK to reduce deaths from AAA rupture. Whether or not screening should be extended to women is uncertain.
            
            
              Objective
              To evaluate the cost-effectiveness of population screening for AAAs in women and compare a range of screening options.
            
            
              Design
              A discrete event simulation (DES) model was developed to provide a clinically realistic model of screening, surveillance, and elective and emergency AAA repair operations. Input parameters specifically for women were employed. The model was run for 10 million women, with parameter uncertainty addressed by probabilistic and deterministic sensitivity analyses.
            
            
              Setting
              Population screening in the UK.
            
            
              Participants
              Women aged ≥ 65 years, followed up to the age of 95 years.
            
            
              Interventions
              Invitation to ultrasound screening, followed by surveillance for small AAAs and elective surgical repair for large AAAs.
            
            
              Main outcome measures
              Number of operations undertaken, AAA-related mortality, quality-adjusted life-years (QALYs), NHS costs and cost-effectiveness with annual discounting.
            
            
              Data sources
              AAA surveillance data, National Vascular Registry, Hospital Episode Statistics, trials of elective and emergency AAA surgery, and the NHS Abdominal Aortic Aneurysm Screening Programme (NAAASP).
            
            
              Review methods
              Systematic reviews of AAA prevalence and, for elective operations, suitability for endovascular aneurysm repair, non-intervention rates, operative mortality and literature reviews for other parameters.
            
            
              Results
              The prevalence of AAAs (aortic diameter of ≥ 3.0 cm) was estimated as 0.43\% in women aged 65 years and 1.15\% at age 75 years. The corresponding attendance rates following invitation to screening were estimated as 73\% and 62\%, respectively. The base-case model adopted the same age at screening (65 years), definition of an AAA (diameter of ≥ 3.0 cm), surveillance intervals (1 year for AAAs with diameter of 3.0–4.4 cm, 3 months for AAAs with diameter of 4.5–5.4 cm) and AAA diameter for consideration of surgery (5.5 cm) as in NAAASP for men. Per woman invited to screening, the estimated gain in QALYs was 0.00110, and the incremental cost was £33.99. This gave an incremental cost-effectiveness ratio (ICER) of £31,000 per QALY gained. The corresponding incremental net monetary benefit at a threshold of £20,000 per QALY gained was –£12.03 (95\% uncertainty interval –£27.88 to £22.12). Almost no sensitivity analyses brought the ICER below £20,000 per QALY gained; an exception was doubling the AAA prevalence to 0.86\%, which resulted in an ICER of £13,000. Alternative screening options (increasing the screening age to 70 years, lowering the threshold for considering surgery to diameters of 5.0 cm or 4.5 cm, lowering the diameter defining an AAA in women to 2.5 cm and lengthening the surveillance intervals for the smallest AAAs) did not bring the ICER below £20,000 per QALY gained when considered either singly or in combination.
            
            
              Limitations
              The model for women was not directly validated against empirical data. Some parameters were poorly estimated, potentially lacking relevance or unavailable for women.
            
            
              Conclusion
              The accepted criteria for a population-based AAA screening programme in women are not currently met.
            
            
              Future work
              A large-scale study is needed of the exact aortic size distribution for women screened at relevant ages. The DES model can be adapted to evaluate screening options in men.
            
            
              Study registration
              This study is registered as PROSPERO CRD42015020444 and CRD42016043227.
            
            
              Funding
              The National Institute for Health Research Health Technology Assessment programme.},
	language = {en},
	number = {43},
	urldate = {2024-09-09},
	journal = {Health Technology Assessment},
	author = {Thompson, Simon G and Bown, Matthew J and Glover, Matthew J and Jones, Edmund and Masconi, Katya L and Michaels, Jonathan A and Powell, Janet T and Ulug, Pinar and Sweeting, Michael J},
	month = aug,
	year = {2018},
	pages = {1--142},
	file = {Full Text:/home/amy/Zotero/storage/ZJHMYIGT/Thompson et al. - 2018 - Screening women aged 65 years or over for abdomina.pdf:application/pdf},
}

@article{hernandez_optimal_2015,
	title = {Optimal staffing strategies for points of dispensing},
	volume = {83},
	issn = {0360-8352},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835215000728},
	doi = {10.1016/j.cie.2015.02.015},
	abstract = {We present a heuristic-based multi-objective optimization approach for minimizing staff and maximizing throughput at Points-of-Dispensing (PODs). PODs are sites quickly set up by local health departments to rapidly dispense life-saving medical countermeasures during large-scale public health emergencies. Current modeling tools require decision makers to modify their models and re-run them for each “what if” scenario they are charged with preparing for, e.g. what happens if more/less staff are available. The exploration of these “what if” scenarios becomes tedious if there are many variables to change and the decision space quickly becomes too large to analyze effectively. Currently, to understand the trade-offs between throughput and staffing levels, public health emergency managers must maximize throughput subject to a specified staffing level. Then, they must repeatedly change the constraint (altering the maximum staff allowed) and re-run the model. In contrast, by approaching the problem from a multi-objective perspective and integrating discrete event and optimization tools, we automate of the exploration of the decision space. This approach allows public health emergency planners to examine far more potential solutions and to focus tangible planning resources on areas that show theoretical promise. Such an approach can also expose previously unidentified constraints in existing plans.},
	urldate = {2024-09-20},
	journal = {Computers \& Industrial Engineering},
	author = {Hernandez, Ivan and Ramirez-Marquez, Jose E. and Starr, David and McKay, Ryan and Guthartz, Seth and Motherwell, Matt and Barcellona, Jessica},
	month = may,
	year = {2015},
	keywords = {Simulation, Multi-criteria analysis, OR in health services, Uncertainty modeling},
	pages = {172--183},
	file = {ScienceDirect Snapshot:/home/amy/Zotero/storage/2WE8EJH5/S0360835215000728.html:text/html},
}

@article{wood_value_2021,
	title = {The {Value} of {Triage} during {Periods} of {Intense} {COVID}-19 {Demand}: {Simulation} {Modeling} {Study}},
	volume = {41},
	issn = {0272-989X},
	shorttitle = {The {Value} of {Triage} during {Periods} of {Intense} {COVID}-19 {Demand}},
	url = {https://doi.org/10.1177/0272989X21994035},
	doi = {10.1177/0272989X21994035},
	abstract = {BackgroundDuring the COVID-19 pandemic, many intensive care units have been overwhelmed by unprecedented levels of demand. Notwithstanding ethical considerations, the prioritization of patients with better prognoses may support a more effective use of available capacity in maximizing aggregate outcomes. This has prompted various proposed triage criteria, although in none of these has an objective assessment been made in terms of impact on number of lives and life-years saved.DesignAn open-source computer simulation model was constructed for approximating the intensive care admission and discharge dynamics under triage. The model was calibrated from observational data for 9505 patient admissions to UK intensive care units. To explore triage efficacy under various conditions, scenario analysis was performed using a range of demand trajectories corresponding to differing nonpharmaceutical interventions.ResultsTriaging patients at the point of expressed demand had negligible effect on deaths but reduces life-years lost by up to 8.4\% (95\% confidence interval: 2.6\% to 18.7\%). Greater value may be possible through “reverse triage”, that is, promptly discharging any patient not meeting the criteria if admission cannot otherwise be guaranteed for one who does. Under such policy, life-years lost can be reduced by 11.7\% (2.8\% to 25.8\%), which represents 23.0\% (5.4\% to 50.1\%) of what is operationally feasible with no limit on capacity and in the absence of improved clinical treatments.ConclusionsThe effect of simple triage is limited by a tradeoff between reduced deaths within intensive care (due to improved outcomes) and increased deaths resulting from declined admission (due to lower throughput given the longer lengths of stay of survivors). Improvements can be found through reverse triage, at the expense of potentially complex ethical considerations.},
	language = {en},
	number = {4},
	urldate = {2024-09-27},
	journal = {Medical Decision Making},
	author = {Wood, Richard M. and Pratt, Adrian C. and Kenward, Charlie and McWilliams, Christopher J. and Booton, Ross D. and Thomas, Matthew J. and Bourdeaux, Christopher P. and Vasilakis, Christos},
	month = may,
	year = {2021},
	note = {Publisher: SAGE Publications Inc STM},
	pages = {393--407},
	file = {SAGE PDF Full Text:/home/amy/Zotero/storage/N9BG5WCC/Wood et al. - 2021 - The Value of Triage during Periods of Intense COVI.pdf:application/pdf},
}

@article{baker_1500_2016,
	title = {1,500 scientists lift the lid on reproducibility},
	volume = {533},
	copyright = {2016 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/533452a},
	doi = {10.1038/533452a},
	abstract = {Survey sheds light on the ‘crisis’ rocking research.},
	language = {en},
	number = {7604},
	urldate = {2024-10-11},
	journal = {Nature},
	author = {Baker, Monya},
	month = may,
	year = {2016},
	note = {Publisher: Nature Publishing Group},
	keywords = {Publishing, Peer review, Research management},
	pages = {452--454},
	file = {Full Text PDF:/home/amy/Zotero/storage/LF25TVFZ/Baker - 2016 - 1,500 scientists lift the lid on reproducibility.pdf:application/pdf;Snapshot:/home/amy/Zotero/storage/85H4DVRJ/533452a.html:text/html},
}

@article{wood_covid-19_2020,
	title = {{COVID}-19 scenario modelling for the mitigation of capacity-dependent deaths in intensive care},
	volume = {23},
	issn = {1572-9389},
	url = {https://doi.org/10.1007/s10729-020-09511-7},
	doi = {10.1007/s10729-020-09511-7},
	abstract = {Managing healthcare demand and capacity is especially difficult in the context of the COVID-19 pandemic, where limited intensive care resources can be overwhelmed by a large number of cases requiring admission in a short space of time. If patients are unable to access this specialist resource, then death is a likely outcome. In appreciating these ‘capacity-dependent’ deaths, this paper reports on the clinically-led development of a stochastic discrete event simulation model designed to capture the key dynamics of the intensive care admissions process for COVID-19 patients. With application to a large public hospital in England during an early stage of the pandemic, the purpose of this study was to estimate the extent to which such capacity-dependent deaths can be mitigated through demand-side initiatives involving non-pharmaceutical interventions and supply-side measures to increase surge capacity. Based on information available at the time, results suggest that total capacity-dependent deaths can be reduced by 75\% through a combination of increasing capacity from 45 to 100 beds, reducing length of stay by 25\%, and flattening the peak demand to 26 admissions per day. Accounting for the additional ‘capacity-independent’ deaths, which occur even when appropriate care is available within the intensive care setting, yields an aggregate reduction in total deaths of 30\%. The modelling tool, which is freely available and open source, has since been used to support COVID-19 response planning at a number of healthcare systems within the UK National Health Service.},
	language = {en},
	number = {3},
	urldate = {2024-10-15},
	journal = {Health Care Management Science},
	author = {Wood, Richard M. and McWilliams, Christopher J. and Thomas, Matthew J. and Bourdeaux, Christopher P. and Vasilakis, Christos},
	month = sep,
	year = {2020},
	keywords = {Simulation, COVID-19, Capacity management, Coronavirus, Intensive care, Operations research},
	pages = {315--324},
	file = {Full Text PDF:/home/amy/Zotero/storage/D6JY58A2/Wood et al. - 2020 - COVID-19 scenario modelling for the mitigation of .pdf:application/pdf},
}

@article{korbmacher_replication_2023,
	title = {The replication crisis has led to positive structural, procedural, and community changes},
	volume = {1},
	issn = {2731-9121},
	url = {https://doi.org/10.1038/s44271-023-00003-2},
	doi = {10.1038/s44271-023-00003-2},
	abstract = {The emergence of large-scale replication projects yielding successful rates substantially lower than expected caused the behavioural, cognitive, and social sciences to experience a so-called ‘replication crisis’. In this Perspective, we reframe this ‘crisis’ through the lens of a credibility revolution, focusing on positive structural, procedural and community-driven changes. Second, we outline a path to expand ongoing advances and improvements. The credibility revolution has been an impetus to several substantive changes which will have a positive, long-term impact on our research environment.},
	number = {1},
	journal = {Communications Psychology},
	author = {Korbmacher, Max and Azevedo, Flavio and Pennington, Charlotte R. and Hartmann, Helena and Pownall, Madeleine and Schmidt, Kathleen and Elsherif, Mahmoud and Breznau, Nate and Robertson, Olly and Kalandadze, Tamara and Yu, Shijun and Baker, Bradley J. and O’Mahony, Aoife and Olsnes, Jørgen Ø. -S. and Shaw, John J. and Gjoneska, Biljana and Yamada, Yuki and Röer, Jan P. and Murphy, Jennifer and Alzahawi, Shilaan and Grinschgl, Sandra and Oliveira, Catia M. and Wingen, Tobias and Yeung, Siu Kit and Liu, Meng and König, Laura M. and Albayrak-Aydemir, Nihan and Lecuona, Oscar and Micheli, Leticia and Evans, Thomas},
	month = jul,
	year = {2023},
	pages = {3},
}

@article{samuel_computational_2024,
	title = {Computational reproducibility of {Jupyter} notebooks from biomedical publications},
	volume = {13},
	issn = {2047-217X},
	url = {https://doi.org/10.1093/gigascience/giad113},
	doi = {10.1093/gigascience/giad113},
	abstract = {Jupyter notebooks facilitate the bundling of executable code with its documentation and output in one interactive environment, and they represent a popular mechanism to document and share computational workflows, including for research publications. The reproducibility of computational aspects of research is a key component of scientific reproducibility but has not yet been assessed at scale for Jupyter notebooks associated with biomedical publications.We address computational reproducibility at 2 levels: (i) using fully automated workflows, we analyzed the computational reproducibility of Jupyter notebooks associated with publications indexed in the biomedical literature repository PubMed Central. We identified such notebooks by mining the article’s full text, trying to locate them on GitHub, and attempting to rerun them in an environment as close to the original as possible. We documented reproduction success and exceptions and explored relationships between notebook reproducibility and variables related to the notebooks or publications. (ii) This study represents a reproducibility attempt in and of itself, using essentially the same methodology twice on PubMed Central over the course of 2 years, during which the corpus of Jupyter notebooks from articles indexed in PubMed Central has grown in a highly dynamic fashion.Out of 27,271 Jupyter notebooks from 2,660 GitHub repositories associated with 3,467 publications, 22,578 notebooks were written in Python, including 15,817 that had their dependencies declared in standard requirement files and that we attempted to rerun automatically. For 10,388 of these, all declared dependencies could be installed successfully, and we reran them to assess reproducibility. Of these, 1,203 notebooks ran through without any errors, including 879 that produced results identical to those reported in the original notebook and 324 for which our results differed from the originally reported ones. Running the other notebooks resulted in exceptions.We zoom in on common problems and practices, highlight trends, and discuss potential improvements to Jupyter-related workflows associated with biomedical publications.},
	urldate = {2024-10-17},
	journal = {GigaScience},
	author = {Samuel, Sheeba and Mietchen, Daniel},
	month = jan,
	year = {2024},
	pages = {giad113},
	file = {Full Text PDF:/home/amy/Zotero/storage/QJLG6JW8/Samuel and Mietchen - 2024 - Computational reproducibility of Jupyter notebooks.pdf:application/pdf},
}

@article{sadatsafavi_development_2019,
	title = {Development and {Validation} of the {Evaluation} {Platform} in {COPD} ({EPIC}): {A} {Population}-{Based} {Outcomes} {Model} of {COPD} for {Canada}},
	volume = {39},
	issn = {0272-989X},
	shorttitle = {Development and {Validation} of the {Evaluation} {Platform} in {COPD} ({EPIC})},
	url = {https://doi.org/10.1177/0272989X18824098},
	doi = {10.1177/0272989X18824098},
	abstract = {Background. We report the development, validation, and implementation of an open-source population-based outcomes model of chronic obstructive pulmonary disease (COPD) for Canada. Methods. Evaluation Platform in COPD (EPIC) is a discrete-event simulation model of Canadians 40 years of age or older. Three core features of EPIC are its open-population design (incorporating projections of future population growth, aging, and smoking trends), its incorporation of heterogeneity in lung function decline and burden of exacerbations, and its modeling of the natural history of COPD from inception. Multiple original data analyses, as well as values reported in the literature, were used to populate the model. Extensive face validity and internal and external validity evaluations were performed. Results. The model was internally validated on demographic projections, mortality rates, lung function trajectories, COPD exacerbations, costs and health state utility values, and stability of COPD prevalence over time within strata of risk factors. In external validation, it moderately overestimated the rate of overall exacerbations in 2 independent trials but generated consistent estimates of rate of severe exacerbations and mortality. Limitations. In its current version, EPIC does not consider uncertainty in the evidence. Several components such as additional (e.g., environmental and occupational) risk factors, treatment, symptoms, and comorbidity will have to be added in future iterations. Predictive validity of EPIC needs to be examined prospectively against future empirical studies. Conclusions. EPIC is the first multipurpose, open-source, outcome- and policy-focused model of COPD for Canada. Platforms of this type have the capacity to be iteratively updated to incorporate the latest evidence and to project the outcomes of many different scenarios within a consistent framework.},
	language = {en},
	number = {2},
	urldate = {2024-10-24},
	journal = {Medical Decision Making},
	author = {Sadatsafavi, Mohsen and Ghanbarian, Shahzad and Adibi, Amin and Johnson, Kate and FitzGerald, J. Mark and Flanagan, William and Bryan, Stirling and Sin, Don},
	month = feb,
	year = {2019},
	note = {Publisher: SAGE Publications Inc STM},
	pages = {152--167},
	file = {SAGE PDF Full Text:/home/amy/Zotero/storage/PD7PRXSQ/Sadatsafavi et al. - 2019 - Development and Validation of the Evaluation Platf.pdf:application/pdf},
}

@article{cadwallader_survey_2022,
	title = {A survey of researchers’ code sharing and code reuse practices, and assessment of interactive notebook prototypes},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2167-8359},
	url = {https://peerj.com/articles/13933},
	doi = {10.7717/peerj.13933},
	abstract = {This research aimed to understand the needs and habits of researchers in relation to code sharing and reuse; gather feedback on prototype code notebooks created by NeuroLibre; and help determine strategies that publishers could use to increase code sharing. We surveyed 188 researchers in computational biology. Respondents were asked about how often and why they look at code, which methods of accessing code they find useful and why, what aspects of code sharing are important to them, and how satisfied they are with their ability to complete these tasks. Respondents were asked to look at a prototype code notebook and give feedback on its features. Respondents were also asked how much time they spent preparing code and if they would be willing to increase this to use a code sharing tool, such as a notebook. As a reader of research articles the most common reason (70\%) for looking at code was to gain a better understanding of the article. The most commonly encountered method for code sharing–linking articles to a code repository–was also the most useful method of accessing code from the reader’s perspective. As authors, the respondents were largely satisfied with their ability to carry out tasks related to code sharing. The most important of these tasks were ensuring that the code was running in the correct environment, and sharing code with good documentation. The average researcher, according to our results, is unwilling to incur additional costs (in time, effort or expenditure) that are currently needed to use code sharing tools alongside a publication. We infer this means we need different models for funding and producing interactive or executable research outputs if they are to reach a large number of researchers. For the purpose of increasing the amount of code shared by authors,
              PLOS Computational Biology
              is, as a result, focusing on policy rather than tools.},
	language = {en},
	urldate = {2024-11-06},
	journal = {PeerJ},
	author = {Cadwallader, Lauren and Hrynaszkiewicz, Iain},
	month = aug,
	year = {2022},
	pages = {e13933},
	file = {Full Text:/home/amy/Zotero/storage/2PVYDHZH/Cadwallader and Hrynaszkiewicz - 2022 - A survey of researchers’ code sharing and code reu.pdf:application/pdf},
}

@article{noauthor_revisiting_2022,
	title = {Revisiting code reusability},
	volume = {4},
	copyright = {2022 Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-022-00554-9},
	doi = {10.1038/s42256-022-00554-9},
	abstract = {We introduced reusability reports, an article type to highlight code reusability, almost two years ago. On the basis of the results and positive feedback from authors and referees, we remain enthusiastic about the format.},
	language = {en},
	number = {10},
	urldate = {2024-11-06},
	journal = {Nature Machine Intelligence},
	month = oct,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computer science, Scientific community},
	pages = {801--801},
	file = {Full Text PDF:/home/amy/Zotero/storage/Y55ZFNDA/2022 - Revisiting code reusability.pdf:application/pdf},
}

@article{mejba_evolution_2023,
	title = {The {Evolution} and {Impact} of {Code} {Reuse}: {A} {Deep} {Dive} into {Challenges}, {Reuse} {Strategies} and {Security}},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {The {Evolution} and {Impact} of {Code} {Reuse}},
	url = {https://zenodo.org/doi/10.5281/zenodo.10141558},
	doi = {10.5281/ZENODO.10141558},
	abstract = {Code reuse, the practice of using pre-existing software code in new applications, is a widely adopted strategy in software development due to its potential to increase productivity, improve code quality, and reduce errors. However, it also presents unique challenges such as understanding and integrating reused code, managing potential bugs and security vulnerabilities, and dealing with licensing and ownership issues. This paper provides an in-depth analysis of code reuse, exploring its benefits, challenges, and strategies for effective implementation. It delves into strategies such as modular design, use of libraries and frameworks, design patterns, object-oriented programming, APIs and microservices, code documentation, automated testing, refactoring, code reviews, and continuous integration/continuous deployment. The paper also discusses common problems encountered during code reuse and provides comprehensive solutions to these problems. The aim is to provide a thorough understanding of code reuse and a guide for developers to maximize its potential benefits while mitigating its challenges. By implementing the strategies and solutions discussed in this paper, developers can create more robust, maintainable, and secure software through effective code reuse.},
	language = {en},
	urldate = {2024-11-06},
	author = {Mejba, Raoha Bin and Miazi, Sabbir Morshed and Palash, Ashikur Rahaman and Sobuz, Touhidur Rahman and Harshana Ranasinghe, Ranasinghe Arachchige Tharindu},
	month = nov,
	year = {2023},
	note = {Publisher: Zenodo},
	file = {Mejba et al. - 2023 - The Evolution and Impact of Code Reuse A Deep Div.pdf:/home/amy/Zotero/storage/DUH6LF7N/Mejba et al. - 2023 - The Evolution and Impact of Code Reuse A Deep Div.pdf:application/pdf},
}

@article{curty_attitudes_2017,
	title = {Attitudes and norms affecting scientists’ data reuse},
	volume = {12},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0189288},
	doi = {10.1371/journal.pone.0189288},
	abstract = {The value of sharing scientific research data is widely appreciated, but factors that hinder or prompt the reuse of data remain poorly understood. Using the Theory of Reasoned Action, we test the relationship between the beliefs and attitudes of scientists towards data reuse, and their self-reported data reuse behaviour. To do so, we used existing responses to selected questions from a worldwide survey of scientists developed and administered by the DataONE Usability and Assessment Working Group (thus practicing data reuse ourselves). Results show that the perceived efficacy and efficiency of data reuse are strong predictors of reuse behaviour, and that the perceived importance of data reuse corresponds to greater reuse. Expressed lack of trust in existing data and perceived norms against data reuse were not found to be major impediments for reuse contrary to our expectations. We found that reported use of models and remotely-sensed data was associated with greater reuse. The results suggest that data reuse would be encouraged and normalized by demonstration of its value. We offer some theoretical and practical suggestions that could help to legitimize investment and policies in favor of data sharing.},
	language = {en},
	number = {12},
	urldate = {2024-11-06},
	journal = {PLOS ONE},
	author = {Curty, Renata Gonçalves and Crowston, Kevin and Specht, Alison and Grant, Bruce W. and Dalton, Elizabeth D.},
	month = dec,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Metadata, Careers, Careers in research, Data management, Psychological attitudes, Scientists, Survey research, Surveys},
	pages = {e0189288},
	file = {Full Text PDF:/home/amy/Zotero/storage/AMF8JQV4/Curty et al. - 2017 - Attitudes and norms affecting scientists’ data reu.pdf:application/pdf},
}

@article{dupre_beyond_2022,
	title = {Beyond advertising: {New} infrastructures for publishing integrated research objects},
	volume = {18},
	issn = {1553-7358},
	shorttitle = {Beyond advertising},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009651},
	doi = {10.1371/journal.pcbi.1009651},
	language = {en},
	number = {1},
	urldate = {2024-11-06},
	journal = {PLOS Computational Biology},
	author = {DuPre, Elizabeth and Holdgraf, Chris and Karakuzu, Agah and Tetrel, Loïc and Bellec, Pierre and Stikov, Nikola and Poline, Jean-Baptiste},
	month = jan,
	year = {2022},
	note = {Publisher: Public Library of Science},
	keywords = {Scientific publishing, Peer review, Data management, Scientists, Advertising, Cloud computing, Clouds, Internet},
	pages = {e1009651},
	file = {Full Text PDF:/home/amy/Zotero/storage/DQHBHPQV/DuPre et al. - 2022 - Beyond advertising New infrastructures for publis.pdf:application/pdf},
}

@article{benureau_re-run_2018,
	title = {Re-run, {Repeat}, {Reproduce}, {Reuse}, {Replicate}: {Transforming} {Code} into {Scientific} {Contributions}},
	volume = {11},
	issn = {1662-5196},
	shorttitle = {Re-run, {Repeat}, {Reproduce}, {Reuse}, {Replicate}},
	url = {https://www.frontiersin.org/journals/neuroinformatics/articles/10.3389/fninf.2017.00069/full},
	doi = {10.3389/fninf.2017.00069},
	abstract = {{\textless}p{\textgreater}Scientific code is different from production software. Scientific code, by producing results that are then analyzed and interpreted, participates in the elaboration of scientific conclusions. This imposes specific constraints on the code that are often overlooked in practice. We articulate, with a small example, five characteristics that a scientific code in computational science should possess: re-runnable, repeatable, reproducible, reusable, and replicable. The code should be executable (re-runnable) and produce the same result more than once (repeatable); it should allow an investigator to reobtain the published results (reproducible) while being easy to use, understand and modify (reusable), and it should act as an available reference for any ambiguity in the algorithmic descriptions of the article (replicable).{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2024-11-06},
	journal = {Frontiers in Neuroinformatics},
	author = {Benureau, Fabien C. Y. and Rougier, Nicolas P.},
	month = jan,
	year = {2018},
	note = {Publisher: Frontiers},
	keywords = {Reproducibility of Results, best practices, computational science, replicability, Reproducible Research, reproducible science, Software Development},
	file = {Full Text PDF:/home/amy/Zotero/storage/J7CEL7LP/Benureau and Rougier - 2018 - Re-run, Repeat, Reproduce, Reuse, Replicate Trans.pdf:application/pdf},
}

@article{wilson_good_2017,
	title = {Good enough practices in scientific computing},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510},
	doi = {10.1371/journal.pcbi.1005510},
	abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
	language = {en},
	number = {6},
	urldate = {2024-11-06},
	journal = {PLOS Computational Biology},
	author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
	month = jun,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Metadata, Reproducibility, Data management, Computer software, Control systems, Programming languages, Software tools, Source code},
	pages = {e1005510},
	file = {Full Text PDF:/home/amy/Zotero/storage/IF5UE78V/Wilson et al. - 2017 - Good enough practices in scientific computing.pdf:application/pdf},
}

@article{gomes_why_2022,
	title = {Why don't we share data and code? {Perceived} barriers and benefits to public archiving practices},
	volume = {289},
	shorttitle = {Why don't we share data and code?},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rspb.2022.1113},
	doi = {10.1098/rspb.2022.1113},
	abstract = {The biological sciences community is increasingly recognizing the value of open, reproducible and transparent research practices for science and society at large. Despite this recognition, many researchers fail to share their data and code publicly. This pattern may arise from knowledge barriers about how to archive data and code, concerns about its reuse, and misaligned career incentives. Here, we define, categorize and discuss barriers to data and code sharing that are relevant to many research fields. We explore how real and perceived barriers might be overcome or reframed in the light of the benefits relative to costs. By elucidating these barriers and the contexts in which they arise, we can take steps to mitigate them and align our actions with the goals of open science, both as individual scientists and as a scientific community.},
	number = {1987},
	urldate = {2024-11-06},
	journal = {Proceedings of the Royal Society B: Biological Sciences},
	author = {Gomes, Dylan G. E. and Pottier, Patrice and Crystal-Ornelas, Robert and Hudgins, Emma J. and Foroughirad, Vivienne and Sánchez-Reyes, Luna L. and Turba, Rachel and Martinez, Paula Andrea and Moreau, David and Bertram, Michael G. and Smout, Cooper A. and Gaynor, Kaitlyn M.},
	month = nov,
	year = {2022},
	note = {Publisher: Royal Society},
	keywords = {open science, reproducibility, data science, code reuse‌, data reuse, transparency},
	pages = {20221113},
	file = {Full Text PDF:/home/amy/Zotero/storage/LCAAHYDR/Gomes et al. - 2022 - Why don't we share data and code Perceived barrie.pdf:application/pdf},
}

@article{connolly_software_2023,
	title = {Software {Engineering} {Practices} in {Academia}: {Promoting} the {3Rs}—{Readability}, {Resilience}, and {Reuse}},
	volume = {5},
	shorttitle = {Software {Engineering} {Practices} in {Academia}},
	url = {https://hdsr.mitpress.mit.edu/pub/f0f7h5cu},
	doi = {10.1162/99608f92.018bf012},
	abstract = {Over the past decade as data science has become integral to the research workflow, we, like many others, have learned that good data science requires high-quality software engineering. Unfortunately, our experience is that many data science projects can be limited by the absence of software engineering processes. We advocate that data science projects should incorporate what we call the 3Rs of software engineering: readability (human understandable codes), resilience (fails rarely/gracefully), and reuse (can easily be used by others and can be embedded in other software). This article discusses engineering practices that promote 3R software in academia. We emphasize that best practices in academia may differ from those in industry because of substantial differences in project scope (most academic projects have a single developer who is the sole user) and the reward systems in place in academia. We provide a framework for selecting a level of software engineering rigor that aligns well with the project scope, something that may change over time. We further discuss how to improve training in software engineering skills in an academic environment and how to build communities of practice that span across disciplines.},
	language = {en},
	number = {2},
	urldate = {2024-11-06},
	journal = {Harvard Data Science Review},
	author = {Connolly, Andrew and Hellerstein, Joseph and Alterman, Naomi and Beck, David and Fatland, Rob and Lazowska, Ed and Mandava, Vani and Stone, Sarah},
	month = apr,
	year = {2023},
	file = {Connolly et al. - 2023 - Software Engineering Practices in Academia Promot.pdf:/home/amy/Zotero/storage/PCTS9VWW/Connolly et al. - 2023 - Software Engineering Practices in Academia Promot.pdf:application/pdf},
}

@misc{hrynaszkiewicz_survey_2021,
	title = {A survey of code sharing practice and policy in computational biology},
	url = {https://osf.io/f73a6},
	doi = {10.31219/osf.io/f73a6},
	abstract = {Sharing of code supports reproducible research but fewer journals have policies on code sharing compared to data sharing, and there is little evidence on researchers’ attitudes and experiences with code sharing. Before introducing a stronger policy on sharing of code, the Editors and publisher of the journal PLOS Computational Biology wished to test, via an online survey, the suitability of a proposed mandatory code sharing policy with its community of authors. Previous research has established, in 2019, 41\% of papers in the journal linked to shared code. We also wanted to understand the potential impact of the proposed policy on authors' submissions to the journal, and their concerns about code sharing.

We received 214 completed survey responses, all of whom had generated code in their research previously. 80\% had published in PLOS Computational Biology and 88\% of whom were based in Europe or North America. Overall, respondents reported they were more likely to submit to the journal if it had a mandatory code sharing policy and US researchers were more positive than the average for all respondents. Researchers whose main discipline is Medicine and Health sciences viewed the proposed policy less favourably, as did the most senior researchers (those with more than 100 publications) compared to early and mid-career researchers.

The authors surveyed report that, on average, 71\% of their research articles have associated code, and that for the average author, code has not been shared for 32\% of these papers. The most common reasons for not sharing code previously are practical issues, which are unlikely to prevent compliance with the policy. A lack of time to share code was the most common reason. 22\% of respondents who had not shared their code in the past cited intellectual property (IP) concerns - a concern that might prevent public sharing of code under a mandatory code sharing policy. The results also imply that 18\% of the respondents’ previous publications did not have the associated code shared and IP concerns were not cited, suggesting more papers in the journal could share code.

To remain inclusive of all researchers in the community, the policy was designed to allow researchers who can demonstrate they are legally restricted from sharing their code to be granted an exemption to public sharing of code.

As a secondary goal of the survey we wanted to determine if researchers have unmet needs in their ability to share their own code, and to access other researchers' code. Consistent with our previous research on data sharing, we found potential opportunities for new products or features that support code accessibility or reuse. We found researchers were on average satisfied with their ability to share their own code, suggesting that offering new products or features to support sharing in the absence of a stronger policy would not increase the availability of code with the journal's publications.},
	language = {en-us},
	urldate = {2024-11-06},
	publisher = {OSF},
	author = {Hrynaszkiewicz, Iain and Harney, James and Cadwallader, Lauren},
	month = apr,
	year = {2021},
	keywords = {Open science, Journal policy, Code sharing, Computational biology, Open research, Publishing practices, Survey results},
}

@article{eglen_toward_2017,
	title = {Toward standard practices for sharing computer code and programs in neuroscience},
	volume = {20},
	copyright = {2017 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.4550},
	doi = {10.1038/nn.4550},
	abstract = {Computational techniques are central in many areas of neuroscience and are relatively easy to share. This paper describes why computer programs underlying scientific publications should be shared and lists simple steps for sharing. Together with ongoing efforts in data sharing, this should aid reproducibility of research.},
	language = {en},
	number = {6},
	urldate = {2024-11-06},
	journal = {Nature Neuroscience},
	author = {Eglen, Stephen J. and Marwick, Ben and Halchenko, Yaroslav O. and Hanke, Michael and Sufi, Shoaib and Gleeson, Padraig and Silver, R. Angus and Davison, Andrew P. and Lanyon, Linda and Abrams, Mathew and Wachtler, Thomas and Willshaw, David J. and Pouzat, Christophe and Poline, Jean-Baptiste},
	month = jun,
	year = {2017},
	note = {Publisher: Nature Publishing Group},
	keywords = {Scientific community, Neuroscience},
	pages = {770--773},
	file = {Full Text PDF:/home/amy/Zotero/storage/BQKS8F5K/Eglen et al. - 2017 - Toward standard practices for sharing computer cod.pdf:application/pdf},
}

@inproceedings{stodden_enabling_2018,
	address = {New York, NY, USA},
	series = {P-{RECS}'18},
	title = {Enabling the {Verification} of {Computational} {Results}: {An} {Empirical} {Evaluation} of {Computational} {Reproducibility}},
	isbn = {978-1-4503-5861-3},
	shorttitle = {Enabling the {Verification} of {Computational} {Results}},
	url = {https://dl.acm.org/doi/10.1145/3214239.3214242},
	doi = {10.1145/3214239.3214242},
	abstract = {The ability to independently regenerate published computational claims is widely recognized as a key component of scientific reproducibility. In this article we take a narrow interpretation of this goal, and attempt to regenerate published claims from author-supplied information, including data, code, inputs, and other provided specifications, on a different computational system than that used by the original authors. We are motivated by Claerbout and Donoho's exhortation of the importance of providing complete information for reproducibility of the published claim. We chose the Elsevier journal, the Journal of Computational Physics, which has stated author guidelines that encourage the availability of computational digital artifacts that support scholarly findings. In an IRB approved study at the University of Illinois at Urbana-Champaign (IRB \#17329) we gathered artifacts from a sample of authors who published in this journal in 2016 and 2017. We then used the ICERM criteria generated at the 2012 ICERM workshop "Reproducibility in Computational and Experimental Mathematics" to evaluate the sufficiency of the information provided in the publications and the ease with which the digital artifacts afforded computational reproducibility. We find that, for the articles for which we obtained computational artifacts, we could not easily regenerate the findings for 67\% of them, and we were unable to easily regenerate all the findings for any of the articles. We then evaluated the artifacts we did obtain (55 of 306 articles) and find that the main barriers to computational reproducibility are inadequate documentation of code, data, and workflow information (70.9\%), missing code function and setting information, and missing licensing information (75\%). We recommend improvements based on these findings, including the deposit of supporting digital artifacts for reproducibility as a condition of publication, and verification of computational findings via re-execution of the code when possible.},
	urldate = {2024-11-06},
	booktitle = {Proceedings of the {First} {International} {Workshop} on {Practical} {Reproducible} {Evaluation} of {Computer} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Stodden, Victoria and Krafczyk, Matthew S. and Bhaskar, Adhithya},
	month = jun,
	year = {2018},
	pages = {1--5},
	file = {Full Text PDF:/home/amy/Zotero/storage/RUW2MJET/Stodden et al. - 2018 - Enabling the Verification of Computational Results.pdf:application/pdf},
}

@article{mccullough_lessons_2006,
	title = {Lessons from the {JMCB} {Archive}},
	volume = {38},
	issn = {0022-2879},
	url = {https://www.jstor.org/stable/3838995},
	abstract = {We examine the online archive of the Journal of Money, Credit, and Banking, in which an author is required to deposit the data and code that replicate the results of his paper. We find that most authors do not fulfill this requirement. Of more than 150 empirical articles, fewer than 15 could be replicated. Despite all this, there is no doubt that a data/code archive is more conducive to replicable research than the alternatives. We make recommendations to improve the functioning of the archive.},
	number = {4},
	urldate = {2024-11-06},
	journal = {Journal of Money, Credit and Banking},
	author = {McCullough, B. D. and McGeary, Kerry Anne and Harrison, Teresa D.},
	year = {2006},
	note = {Publisher: [Wiley, Ohio State University Press]},
	pages = {1093--1107},
}

@misc{galiani_incentives_2017,
	type = {Working {Paper}},
	series = {Working {Paper} {Series}},
	title = {Incentives for {Replication} in {Economics}},
	url = {https://www.nber.org/papers/w23576},
	doi = {10.3386/w23576},
	abstract = {Replication is a critical component of scientific credibility as it increases our confidence in the reliability of the knowledge generated by original research. Yet, replication is the exception rather than the rule in economics. In this paper, we examine why replication is so rare and propose changes to the incentives to replicate. Our study focuses on software code replication, which seeks to replicate the results in the original paper using the same data as the original study and verifying that the analysis code is correct. We analyse the effectiveness of the current model for code replication in the context of three desirable characteristics: unbiasedness, fairness and efficiency. We find substantial evidence of “overturn bias” that likely leads to many false positives in terms of “finding” or claiming mistakes in the original analysis. Overturn bias comes from the fact that replications that overturn original results are much easier to publish than those that confirm original results. In a survey of editors, almost all responded they would in principle publish a replication study that overturned the results of the original study, but only 29\% responded that they would consider publishing a replication study that confirmed the original study results. We also find that most replication effort is devoted to so called important papers and that the cost of replication is high in that posited data and software are very hard to use. We outline a new model for the journals to take over replication post acceptance and prepublication that would solve the incentive problems raised in this paper.},
	urldate = {2024-11-06},
	publisher = {National Bureau of Economic Research},
	author = {Galiani, Sebastian and Gertler, Paul and Romero, Mauricio},
	month = jul,
	year = {2017},
	file = {Full Text PDF:/home/amy/Zotero/storage/RZKSMHA9/Galiani et al. - 2017 - Incentives for Replication in Economics.pdf:application/pdf},
}

@article{chang_is_2022,
	title = {Is {Economics} {Research} {Replicable}? {Sixty} {Published} {Papers} {From} {Thirteen} {Journals} {Say} “{Often} {Not}”},
	volume = {11},
	issn = {2164-5744, 2164-5760},
	shorttitle = {Is {Economics} {Research} {Replicable}?},
	url = {http://www.nowpublishers.com/article/Details/CFR-0053},
	doi = {10.1561/104.00000053},
	language = {en},
	number = {1},
	urldate = {2024-11-06},
	journal = {Critical Finance Review},
	author = {Chang, Andrew and Li, Phillip},
	year = {2022},
	pages = {185--206},
}

@article{stockemer_data_2018,
	title = {Data {Access}, {Transparency}, and {Replication}: {New} {Insights} from the {Political} {Behavior} {Literature}},
	volume = {51},
	issn = {1049-0965, 1537-5935},
	shorttitle = {Data {Access}, {Transparency}, and {Replication}},
	url = {https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/data-access-transparency-and-replication-new-insights-from-the-political-behavior-literature/64CA07CBA652E299079FF32BC5A6DCB3},
	doi = {10.1017/S1049096518000926},
	abstract = {Do researchers share their quantitative data and are the quantitative results that are published in political science journals replicable? We attempt to answer these questions by analyzing all articles published in the 2015 issues of three political behaviorist journals (i.e., Electoral Studies, Party Politics, and Journal of Elections, Public Opinion \& Parties)—all of which did not have a binding data-sharing and replication policy as of 2015. We found that authors are still reluctant to share their data; only slightly more than half of the authors in these journals do so. For those who share their data, we mainly confirmed the initial results reported in the respective articles in roughly 70\% of the times. Only roughly 5\% of the articles yielded significantly different results from those reported in the publication. However, we also found that roughly 25\% of the articles organized the data and/or code so poorly that replication was impossible.},
	language = {en},
	number = {4},
	urldate = {2024-11-07},
	journal = {PS: Political Science \& Politics},
	author = {Stockemer, Daniel and Koehler, Sebastian and Lentz, Tobias},
	month = oct,
	year = {2018},
	pages = {799--803},
	file = {Full Text PDF:/home/amy/Zotero/storage/Y6HAFSM7/Stockemer et al. - 2018 - Data Access, Transparency, and Replication New In.pdf:application/pdf},
}

@article{naudet_data_2018,
	title = {Data sharing and reanalysis of randomized controlled trials in leading biomedical journals with a full data sharing policy: survey of studies published in {The} {BMJ} and {PLOS} {Medicine}},
	volume = {360},
	copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions. This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.},
	issn = {0959-8138, 1756-1833},
	shorttitle = {Data sharing and reanalysis of randomized controlled trials in leading biomedical journals with a full data sharing policy},
	url = {https://www.bmj.com/content/360/bmj.k400},
	doi = {10.1136/bmj.k400},
	abstract = {Objectives To explore the effectiveness of data sharing by randomized controlled trials (RCTs) in journals with a full data sharing policy and to describe potential difficulties encountered in the process of performing reanalyses of the primary outcomes.
Design Survey of published RCTs.
Setting PubMed/Medline.
Eligibility criteria RCTs that had been submitted and published by The BMJ and PLOS Medicine subsequent to the adoption of data sharing policies by these journals.
Main outcome measure The primary outcome was data availability, defined as the eventual receipt of complete data with clear labelling. Primary outcomes were reanalyzed to assess to what extent studies were reproduced. Difficulties encountered were described.
Results 37 RCTs (21 from The BMJ and 16 from PLOS Medicine) published between 2013 and 2016 met the eligibility criteria. 17/37 (46\%, 95\% confidence interval 30\% to 62\%) satisfied the definition of data availability and 14 of the 17 (82\%, 59\% to 94\%) were fully reproduced on all their primary outcomes. Of the remaining RCTs, errors were identified in two but reached similar conclusions and one paper did not provide enough information in the Methods section to reproduce the analyses. Difficulties identified included problems in contacting corresponding authors and lack of resources on their behalf in preparing the datasets. In addition, there was a range of different data sharing practices across study groups.
Conclusions Data availability was not optimal in two journals with a strong policy for data sharing. When investigators shared data, most reanalyses largely reproduced the original results. Data sharing practices need to become more widespread and streamlined to allow meaningful reanalyses and reuse of data.
Trial registration Open Science Framework osf.io/c4zke.},
	language = {en},
	urldate = {2024-11-07},
	journal = {BMJ},
	author = {Naudet, Florian and Sakarovitch, Charlotte and Janiaud, Perrine and Cristea, Ioana and Fanelli, Daniele and Moher, David and Ioannidis, John P. A.},
	month = feb,
	year = {2018},
	pmid = {29440066},
	note = {Publisher: British Medical Journal Publishing Group
Section: Research},
	pages = {k400},
	file = {Full Text PDF:/home/amy/Zotero/storage/AQJYDIMS/Naudet et al. - 2018 - Data sharing and reanalysis of randomized controll.pdf:application/pdf},
}

@inproceedings{raff_step_2019,
	title = {A {Step} {Toward} {Quantifying} {Independently} {Reproducible} {Machine} {Learning} {Research}},
	volume = {32},
	url = {https://proceedings.neurips.cc/paper/2019/hash/c429429bf1f2af051f2021dc92a8ebea-Abstract.html},
	abstract = {What makes a paper independently reproducible? Debates on reproducibility center around intuition or assumptions but lack empirical results. Our field focuses on releasing code, which is important, but is not sufficient for determining reproducibility. We take the first step toward a quantifiable answer by manually attempting to implement 255 papers published from 1984 until 2017, recording features of each paper, and performing statistical analysis of the results. For each paper, we did not look at the authors code, if released, in order to prevent bias toward discrepancies between code and paper.},
	urldate = {2024-11-07},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Raff, Edward},
	year = {2019},
	file = {Full Text PDF:/home/amy/Zotero/storage/7KJGWDLU/Raff - 2019 - A Step Toward Quantifying Independently Reproducib.pdf:application/pdf},
}

@article{stagge_assessing_2019,
	title = {Assessing data availability and research reproducibility in hydrology and water resources},
	volume = {6},
	copyright = {2019 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata201930},
	doi = {10.1038/sdata.2019.30},
	abstract = {There is broad interest to improve the reproducibility of published research. We developed a survey tool to assess the availability of digital research artifacts published alongside peer-reviewed journal articles (e.g. data, models, code, directions for use) and reproducibility of article results. We used the tool to assess 360 of the 1,989 articles published by six hydrology and water resources journals in 2017. Like studies from other fields, we reproduced results for only a small fraction of articles (1.6\% of tested articles) using their available artifacts. We estimated, with 95\% confidence, that results might be reproduced for only 0.6\% to 6.8\% of all 1,989 articles. Unlike prior studies, the survey tool identified key bottlenecks to making work more reproducible. Bottlenecks include: only some digital artifacts available (44\% of articles), no directions (89\%), or all artifacts available but results not reproducible (5\%). The tool (or extensions) can help authors, journals, funders, and institutions to self-assess manuscripts, provide feedback to improve reproducibility, and recognize and reward reproducible articles as examples for others.},
	language = {en},
	number = {1},
	urldate = {2024-11-07},
	journal = {Scientific Data},
	author = {Stagge, James H. and Rosenberg, David E. and Abdallah, Adel M. and Akbar, Hadia and Attallah, Nour A. and James, Ryan},
	month = feb,
	year = {2019},
	note = {Publisher: Nature Publishing Group},
	keywords = {Publishing, Hydrology, Research data},
	pages = {190030},
	file = {Full Text PDF:/home/amy/Zotero/storage/K2NFJIGZ/Stagge et al. - 2019 - Assessing data availability and research reproduci.pdf:application/pdf},
}

@article{eubank_lessons_2016,
	title = {Lessons from a {Decade} of {Replications} at the {Quarterly} {Journal} of {Political} {Science}},
	volume = {49},
	issn = {1049-0965, 1537-5935},
	url = {https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/lessons-from-a-decade-of-replications-at-the-quarterly-journal-of-political-science/284B2830BFD99888B42D4CEABC28B9EE},
	doi = {10.1017/S1049096516000196},
	abstract = {To allow researchers to investigate not only whether a paper’s methods are theoretically sound but also whether they have been properly implemented and are robust to alternative specifications, it is necessary that published papers be accompanied by their underlying data and code. This article describes experiences and lessons learned at the Quarterly Journal of Political Science since it began requiring authors to provide this type of replication code in 2005. It finds that of the 24 empirical papers subjected to in-house replication review since September 2012, only four packages did not require any modifications. Most troubling, 14 packages (58\%) had results in the paper that differed from those generated by the author’s own code. Based on these experiences, this article presents a set of guidelines for authors and journals for improving the reliability and usability of replication packages.},
	language = {en},
	number = {2},
	urldate = {2024-11-07},
	journal = {PS: Political Science \& Politics},
	author = {Eubank, Nicholas},
	month = apr,
	year = {2016},
	pages = {273--276},
	file = {Full Text PDF:/home/amy/Zotero/storage/98TKVFYM/Eubank - 2016 - Lessons from a Decade of Replications at the Quart.pdf:application/pdf},
}

@article{artner_reproducibility_2021,
	title = {The reproducibility of statistical results in psychological research: {An} investigation using unpublished raw data},
	volume = {26},
	issn = {1939-1463},
	shorttitle = {The reproducibility of statistical results in psychological research},
	doi = {10.1037/met0000365},
	abstract = {We investigated the reproducibility of the major statistical conclusions drawn in 46 articles published in 2012 in three APA journals. After having identified 232 key statistical claims, we tried to reproduce, for each claim, the test statistic, its degrees of freedom, and the corresponding p value, starting from the raw data that were provided by the authors and closely following the Method section in the article. Out of the 232 claims, we were able to successfully reproduce 163 (70\%), 18 of which only by deviating from the article’s analytical description. Thirteen (7\%) of the 185 claims deemed significant by the authors are no longer so. The reproduction successes were often the result of cumbersome and time-consuming trial-and-error work, suggesting that APA style reporting in conjunction with raw data makes numerical verification at least hard, if not impossible. This article discusses the types of mistakes we could identify and the tediousness of our reproduction efforts in the light of a newly developed taxonomy for reproducibility. We then link our findings with other findings of empirical research on this topic, give practical recommendations on how to achieve reproducibility, and discuss the challenges of large-scale reproducibility checks as well as promising ideas that could considerably increase the reproducibility of psychological research. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
	number = {5},
	journal = {Psychological Methods},
	author = {Artner, Richard and Verliefde, Thomas and Steegen, Sara and Gomes, Sara and Traets, Frits and Tuerlinckx, Francis and Vanpaemel, Wolf},
	year = {2021},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Statistical Analysis, Statistics, American Psychological Association, Data Sets, Errors, Experimental Replication, Experimentation, Scientific Communication},
	pages = {527--546},
	file = {Accepted Version:/home/amy/Zotero/storage/3ZUKR4JJ/Artner et al. - 2021 - The reproducibility of statistical results in psyc.pdf:application/pdf},
}

@article{maassen_reproducibility_2020,
	title = {Reproducibility of individual effect sizes in meta-analyses in psychology},
	volume = {15},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0233107},
	doi = {10.1371/journal.pone.0233107},
	abstract = {To determine the reproducibility of psychological meta-analyses, we investigated whether we could reproduce 500 primary study effect sizes drawn from 33 published meta-analyses based on the information given in the meta-analyses, and whether recomputations of primary study effect sizes altered the overall results of the meta-analysis. Results showed that almost half (k = 224) of all sampled primary effect sizes could not be reproduced based on the reported information in the meta-analysis, mostly because of incomplete or missing information on how effect sizes from primary studies were selected and computed. Overall, this led to small discrepancies in the computation of mean effect sizes, confidence intervals and heterogeneity estimates in 13 out of 33 meta-analyses. We provide recommendations to improve transparency in the reporting of the entire meta-analytic process, including the use of preregistration, data and workflow sharing, and explicit coding practices.},
	language = {en},
	number = {5},
	urldate = {2024-11-07},
	journal = {PLOS ONE},
	author = {Maassen, Esther and Assen, Marcel A. L. M. van and Nuijten, Michèle B. and Olsson-Collentine, Anton and Wicherts, Jelte M.},
	month = may,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Psychology, Systematic reviews, Reproducibility, Peer review, Clinical psychology, Metaanalysis, Publication ethics, Research reporting guidelines},
	pages = {e0233107},
	file = {Full Text PDF:/home/amy/Zotero/storage/P3KYHGG6/Maassen et al. - 2020 - Reproducibility of individual effect sizes in meta.pdf:application/pdf},
}

@article{chambers_verification_2020,
	title = {\textit{{Verification} {Reports}}: {A} new article type at \textit{{Cortex}}},
	volume = {129},
	issn = {0010-9452},
	shorttitle = {\textit{{Verification} {Reports}}},
	url = {https://www.sciencedirect.com/science/article/pii/S0010945220301738},
	doi = {10.1016/j.cortex.2020.04.020},
	urldate = {2024-11-07},
	journal = {Cortex},
	author = {Chambers, Christopher D.},
	month = aug,
	year = {2020},
	pages = {A1--A3},
	file = {Accepted Version:/home/amy/Zotero/storage/TRMF2L5W/Chambers - 2020 - Verification Reports A new article type at.pdf:application/pdf;ScienceDirect Snapshot:/home/amy/Zotero/storage/ITQFC56F/S0010945220301738.html:text/html},
}

@article{ostermann_advancing_2017,
	title = {Advancing {Science} with {VGI}: {Reproducibility} and {Replicability} of {Recent} {Studies} using {VGI}},
	volume = {21},
	copyright = {© 2015 John Wiley \& Sons Ltd},
	issn = {1467-9671},
	shorttitle = {Advancing {Science} with {VGI}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12195},
	doi = {10.1111/tgis.12195},
	abstract = {In scientific research, reproducibility and replicability are requirements to ensure the advancement of our body of knowledge. This holds true also for VGI-related research and studies. However, the characteristics of VGI suggest particular difficulties in ensuring reproducibility and replicability. In this article, we aim to examine the current situation in VGI-related research, and identify strategies to ensure realization of its full potential. To do so, we first investigate the different aspects of reproducibility and replicability and their impact on VGI-related research. These impacts are different depending on the objectives of the study. Therefore, we examine the study focus of VGI-related research to assess the current body of research and structure our assessment. This work is based on a rigorous review of the elements of reproducibility and a systematic mapping and analysis of 58 papers on the use of VGI in the crisis management field. Results of our investigation show that reproducibility issues related to data are a serious concern, while reproducibility issues related to analysis methods and processes face fewer challenges. However, since most studies still focus on analyzing the source data, reproducibility and replicability are still an unsolved problem in VGI-related research. Therefore, we show initiatives tackling the problem, and finally formulate strategies to improve the situation.},
	language = {en},
	number = {2},
	urldate = {2024-11-07},
	journal = {Transactions in GIS},
	author = {Ostermann, Frank O. and Granell, Carlos},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/tgis.12195},
	pages = {224--237},
	file = {Full Text PDF:/home/amy/Zotero/storage/AMFJQG7F/Ostermann and Granell - 2017 - Advancing Science with VGI Reproducibility and Re.pdf:application/pdf;Snapshot:/home/amy/Zotero/storage/C67Q8JQR/tgis.html:text/html},
}

@article{gil_toward_2016,
	title = {Toward the {Geoscience} {Paper} of the {Future}: {Best} practices for documenting and sharing research from data to software to provenance},
	volume = {3},
	issn = {2333-5084},
	shorttitle = {Toward the {Geoscience} {Paper} of the {Future}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/2015EA000136},
	doi = {10.1002/2015EA000136},
	abstract = {Geoscientists now live in a world rich with digital data and methods, and their computational research cannot be fully captured in traditional publications. The Geoscience Paper of the Future (GPF) presents an approach to fully document, share, and cite all their research products including data, software, and computational provenance. This article proposes best practices for GPF authors to make data, software, and methods openly accessible, citable, and well documented. The publication of digital objects empowers scientists to manage their research products as valuable scientific assets in an open and transparent way that enables broader access by other scientists, students, decision makers, and the public. Improving documentation and dissemination of research will accelerate the pace of scientific discovery by improving the ability of others to build upon published work.},
	language = {en},
	number = {10},
	urldate = {2024-11-07},
	journal = {Earth and Space Science},
	author = {Gil, Yolanda and David, Cédric H. and Demir, Ibrahim and Essawy, Bakinam T. and Fulweiler, Robinson W. and Goodall, Jonathan L. and Karlstrom, Leif and Lee, Huikyo and Mills, Heath J. and Oh, Ji-Hyun and Pierce, Suzanne A. and Pope, Allen and Tzeng, Mimi W. and Villamizar, Sandra R. and Yu, Xuan},
	year = {2016},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/2015EA000136},
	keywords = {reproducibility, workflow, data sharing, geoscience paper of the future, provenance, software reuse},
	pages = {388--415},
	file = {Snapshot:/home/amy/Zotero/storage/PXARVXD5/2015EA000136.html:text/html},
}

@article{skaggs_reproducible_2015,
	title = {Reproducible {Research} in {Vadose} {Zone} {Sciences}},
	volume = {14},
	issn = {1539-1663},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.2136/vzj2015.06.0088},
	doi = {10.2136/vzj2015.06.0088},
	abstract = {Core Ideas A significant portion of present-day geoscience research is computational. Science would benefit from greater transparency in computational research. Vadose Zone Journal is launching a Reproducible Research program. Code and data underlying a research article will be published alongside articles. A significant portion of present-day soil and Earth science research is computational, involving complex data analysis pipelines, advanced mathematical and statistical models, and sophisticated computer codes. Opportunities for scientific progress are greatly diminished if reproducing and building on published research is difficult or impossible due to the complexity of these computational systems. Vadose Zone Journal (VZJ) is launching a Reproducible Research (RR) program in which code and data underlying a research article will be published alongside the article, thereby enabling readers to analyze data in a manner similar to that presented in the article and build on results in future research and applications. In this article, we discuss reproducible research, its background and use across other disciplines, its value to the scientific community, and its implementation in VZJ.},
	language = {en},
	number = {10},
	urldate = {2024-11-07},
	journal = {Vadose Zone Journal},
	author = {Skaggs, T.h. and Young, M.h. and Vrugt, J.a.},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.2136/vzj2015.06.0088},
	pages = {vzj2015.06.0088},
	file = {Full Text:/home/amy/Zotero/storage/J34H3Z8L/Skaggs et al. - 2015 - Reproducible Research in Vadose Zone Sciences.pdf:application/pdf;Snapshot:/home/amy/Zotero/storage/8EF2K5HI/vzj2015.06.html:text/html},
}

@article{hardwicke_data_2018,
	title = {Data availability, reusability, and analytic reproducibility: evaluating the impact of a mandatory open data policy at the journal {Cognition}},
	volume = {5},
	shorttitle = {Data availability, reusability, and analytic reproducibility},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.180448},
	doi = {10.1098/rsos.180448},
	abstract = {Access to data is a critical feature of an efficient, progressive and ultimately self-correcting scientific ecosystem. But the extent to which in-principle benefits of data sharing are realized in practice is unclear. Crucially, it is largely unknown whether published findings can be reproduced by repeating reported analyses upon shared data (‘analytic reproducibility’). To investigate this, we conducted an observational evaluation of a mandatory open data policy introduced at the journal Cognition. Interrupted time-series analyses indicated a substantial post-policy increase in data available statements (104/417, 25\% pre-policy to 136/174, 78\% post-policy), although not all data appeared reusable (23/104, 22\% pre-policy to 85/136, 62\%, post-policy). For 35 of the articles determined to have reusable data, we attempted to reproduce 1324 target values. Ultimately, 64 values could not be reproduced within a 10\% margin of error. For 22 articles all target values were reproduced, but 11 of these required author assistance. For 13 articles at least one value could not be reproduced despite author assistance. Importantly, there were no clear indications that original conclusions were seriously impacted. Mandatory open data policies can increase the frequency and quality of data sharing. However, suboptimal data curation, unclear analysis specification and reporting errors can impede analytic reproducibility, undermining the utility of data sharing and the credibility of scientific findings.},
	number = {8},
	urldate = {2024-11-07},
	journal = {Royal Society Open Science},
	author = {Hardwicke, Tom E. and Mathur, Maya B. and MacDonald, Kyle and Nilsonne, Gustav and Banks, George C. and Kidwell, Mallory C. and Hofelich Mohr, Alicia and Clayton, Elizabeth and Yoon, Erica J. and Henry Tessler, Michael and Lenne, Richie L. and Altman, Sara and Long, Bria and Frank, Michael C.},
	month = aug,
	year = {2018},
	note = {Publisher: Royal Society},
	keywords = {open science, reproducibility, open data, journal policy, interrupted time series, meta-science},
	pages = {180448},
	file = {Full Text PDF:/home/amy/Zotero/storage/E56SYYI4/Hardwicke et al. - 2018 - Data availability, reusability, and analytic repro.pdf:application/pdf},
}

@article{sandve_ten_2013,
	title = {Ten {Simple} {Rules} for {Reproducible} {Computational} {Research}},
	volume = {9},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285},
	doi = {10.1371/journal.pcbi.1003285},
	language = {en},
	number = {10},
	urldate = {2024-11-13},
	journal = {PLOS Computational Biology},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	month = oct,
	year = {2013},
	note = {Publisher: Public Library of Science},
	keywords = {Replication studies, Reproducibility, Source code, Archives, Computer and information sciences, Computer applications, Genome analysis, Habits},
	pages = {e1003285},
	file = {Full Text PDF:/home/amy/Zotero/storage/UEDNQV5Y/Sandve et al. - 2013 - Ten Simple Rules for Reproducible Computational Re.pdf:application/pdf},
}

@misc{eynden_survey_2016,
	title = {Survey of {Wellcome} researchers and their attitudes to open research},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://doi.org/10.6084/m9.figshare.4055448.v1},
	abstract = {Results of a survey of Wellcome researchers to find out what they think about open research, how they practice it, and some of the barriers they face. {\textless}br{\textgreater}This work was commissioned by the Wellcome Trust and conducted by the London School of Hygiene and Tropical Medicine and the UK Data Service.{\textless}br{\textgreater}},
	urldate = {2024-11-13},
	publisher = {Wellcome Trust},
	author = {Eynden, Veerle Van Den and Knight, Gareth and Vlad, Anca and Radler, Barry and Tenopir, Carol and Leon, David and Manista, Frank and Whitworth, Jimmy and Corti, Louise},
	year = {2016},
	keywords = {Survey Results},
}

@article{colavizza_analysis_2024,
	title = {An analysis of the effects of sharing research data, code, and preprints on citations},
	volume = {19},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0311493},
	doi = {10.1371/journal.pone.0311493},
	abstract = {Calls to make scientific research more open have gained traction with a range of societal stakeholders. Open Science practices include but are not limited to the early sharing of results via preprints and openly sharing outputs such as data and code to make research more reproducible and extensible. Existing evidence shows that adopting Open Science practices has effects in several domains. In this study, we investigate whether adopting one or more Open Science practices leads to significantly higher citations for an associated publication, which is one form of academic impact. We use a novel dataset known as Open Science Indicators, produced by PLOS and DataSeer, which includes all PLOS publications from 2018 to 2023 as well as a comparison group sampled from the PMC Open Access Subset. In total, we analyze circa 122’000 publications. We calculate publication and author-level citation indicators and use a broad set of control variables to isolate the effect of Open Science Indicators on received citations. We show that Open Science practices are adopted to different degrees across scientific disciplines. We find that the early release of a publication as a preprint correlates with a significant positive citation advantage of about 20.2\% (±.7) on average. We also find that sharing data in an online repository correlates with a smaller yet still positive citation advantage of 4.3\% (±.8) on average. However, we do not find a significant citation advantage for sharing code. Further research is needed on additional or alternative measures of impact beyond citations. Our results are likely to be of interest to researchers, as well as publishers, research funders, and policymakers.},
	language = {en},
	number = {10},
	urldate = {2024-11-14},
	journal = {PLOS ONE},
	author = {Colavizza, Giovanni and Cadwallader, Lauren and LaFlamme, Marcel and Dozot, Grégory and Lecorney, Stéphane and Rappo, Daniel and Hrynaszkiewicz, Iain},
	month = oct,
	year = {2024},
	note = {Publisher: Public Library of Science},
	keywords = {Open science, Reproducibility, Careers, Bibliometrics, Citation analysis, Linear regression analysis, Research assessment, Science policy},
	pages = {e0311493},
	file = {Full Text PDF:/home/amy/Zotero/storage/HZKJK3YR/Colavizza et al. - 2024 - An analysis of the effects of sharing research dat.pdf:application/pdf},
}

@article{trisovic_large-scale_2022,
	title = {A large-scale study on research code quality and execution},
	volume = {9},
	copyright = {2022 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-022-01143-6},
	doi = {10.1038/s41597-022-01143-6},
	abstract = {This article presents a study on the quality and execution of research code from publicly-available replication datasets at the Harvard Dataverse repository. Research code is typically created by a group of scientists and published together with academic papers to facilitate research transparency and reproducibility. For this study, we define ten questions to address aspects impacting research reproducibility and reuse. First, we retrieve and analyze more than 2000 replication datasets with over 9000 unique R files published from 2010 to 2020. Second, we execute the code in a clean runtime environment to assess its ease of reuse. Common coding errors were identified, and some of them were solved with automatic code cleaning to aid code execution. We find that 74\% of R files failed to complete without error in the initial execution, while 56\% failed when code cleaning was applied, showing that many errors can be prevented with good coding practices. We also analyze the replication datasets from journals’ collections and discuss the impact of the journal policy strictness on the code re-execution rate. Finally, based on our results, we propose a set of recommendations for code dissemination aimed at researchers, journals, and repositories.},
	language = {en},
	number = {1},
	urldate = {2024-11-14},
	journal = {Scientific Data},
	author = {Trisovic, Ana and Lau, Matthew K. and Pasquier, Thomas and Crosas, Mercè},
	month = feb,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Software, Information technology, Research data},
	pages = {60},
	file = {Full Text PDF:/home/amy/Zotero/storage/YX35W8EE/Trisovic et al. - 2022 - A large-scale study on research code quality and e.pdf:application/pdf},
}

@misc{heather_protocol_2024,
	title = {Protocol for assessing the computational reproducibility of discrete-event simulation models on {STARS}},
	url = {https://doi.org/10.5281/zenodo.12179846},
	abstract = {This protocol will be used to assess the computational reproducibility of published healthcare discrete-event simulation (DES) models created using Python or R. It forms part of the project STARS: “Sharing Tools and Artefacts for Reproducible Simulations in healthcare”.},
	publisher = {Zenodo},
	author = {Heather, Amy and Monks, Thomas and Harper, Alison and Mustafee, Navonil and Mayne, Andrew},
	month = jun,
	year = {2024},
	doi = {10.5281/zenodo.12179846},
	file = {Full Text:/home/amy/Zotero/storage/Z4QU8XLV/Heather et al. - 2024 - Protocol for assessing the computational reproduci.pdf:application/pdf},
}

@article{andersen_time_2021,
	title = {Time from submission to publication varied widely for biomedical journals: a systematic review},
	volume = {37},
	issn = {0300-7995},
	shorttitle = {Time from submission to publication varied widely for biomedical journals},
	url = {https://doi.org/10.1080/03007995.2021.1905622},
	doi = {10.1080/03007995.2021.1905622},
	abstract = {Fast dissemination of research is important for improving treatments and thus benefitting patients, caregivers, and researchers. However, getting scientific papers published may take a long time. The editorial handling time can be delayed by several processes both before and after acceptance of the paper. The aim of this study was to systematically review the editorial handling time of biomedical peer-reviewed literature (i.e. time from submission to publication). The protocol for this systematic review was registered in PROSPERO (CRD42020196238). PubMed and EMBASE were searched systematically on 29 May 2020. We included publications on the timespan between submission and publication for accepted articles published in biomedical journals. Of the 4197 unique studies identified in the search, 69 were included in the systematic review. The mean timespan from submission to publication varied from 91 to 639 days, while the median timespan varied from 70 to 558 days. Submission to acceptance and acceptance to publication timespans showed similar disparity with means ranging from 50 to 276 and 11 to 362 days, respectively. Data were too statistically heterogeneous to perform meta-analyses. Editorial handling times of journals varied widely from a few months to almost two years, which delays the availability of new evidence. The editorial handling time did not differ between submission-to-acceptance-time and acceptance-to-publication-time. Examining differences in editorial processes between journals with long and short editorial handling times may help uncover, which processes are frequent causes of delay and thereby where to improve.},
	number = {6},
	urldate = {2024-11-14},
	journal = {Current Medical Research and Opinion},
	author = {Andersen, Mikkel Zola and Fonnes, Siv and Rosenberg, Jacob},
	month = jun,
	year = {2021},
	pmid = {33735591},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/03007995.2021.1905622},
	keywords = {systematic review, acceptance, journalology, publication delay, Publication time, submission},
	pages = {985--993},
	file = {Full Text PDF:/home/amy/Zotero/storage/YS2ZRM22/Andersen et al. - 2021 - Time from submission to publication varied widely .pdf:application/pdf},
}

@article{stodden_empirical_2018,
	title = {An empirical analysis of journal policy effectiveness for computational reproducibility},
	volume = {115},
	url = {https://www.pnas.org/doi/full/10.1073/pnas.1708290115},
	doi = {10.1073/pnas.1708290115},
	abstract = {A key component of scientific communication is sufficient information for other researchers in the field to reproduce published findings. For computational and data-enabled research, this has often been interpreted to mean making available the raw data from which results were generated, the computer code that generated the findings, and any additional information needed such as workflows and input parameters. Many journals are revising author guidelines to include data and code availability. This work evaluates the effectiveness of journal policy that requires the data and code necessary for reproducibility be made available postpublication by the authors upon request. We assess the effectiveness of such a policy by (i) requesting data and code from authors and (ii) attempting replication of the published findings. We chose a random sample of 204 scientific papers published in the journal Science after the implementation of their policy in February 2011. We found that we were able to obtain artifacts from 44\% of our sample and were able to reproduce the findings for 26\%. We find this policy—author remission of data and code postpublication upon request—an improvement over no policy, but currently insufficient for reproducibility.},
	number = {11},
	urldate = {2024-11-14},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Stodden, Victoria and Seiler, Jennifer and Ma, Zhaokun},
	month = mar,
	year = {2018},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {2584--2589},
	file = {Full Text PDF:/home/amy/Zotero/storage/8Z287AHJ/Stodden et al. - 2018 - An empirical analysis of journal policy effectiven.pdf:application/pdf},
}

@article{fisar_reproducibility_2024,
	title = {Reproducibility in {Management} {Science}},
	volume = {70},
	issn = {0025-1909},
	url = {https://pubsonline.informs.org/doi/10.1287/mnsc.2023.03556},
	doi = {10.1287/mnsc.2023.03556},
	abstract = {With the help of more than 700 reviewers, we assess the reproducibility of nearly 500 articles published in the journal Management Science before and after the introduction of a new Data and Code Disclosure policy in 2019. When considering only articles for which data accessibility and hardware and software requirements were not an obstacle for reviewers, the results of more than 95\% of articles under the new disclosure policy could be fully or largely computationally reproduced. However, for 29\% of articles, at least part of the data set was not accessible to the reviewer. Considering all articles in our sample reduces the share of reproduced articles to 68\%. These figures represent a significant increase compared with the period before the introduction of the disclosure policy, where only 12\% of articles voluntarily provided replication materials, of which 55\% could be (largely) reproduced. Substantial heterogeneity in reproducibility rates across different fields is mainly driven by differences in data set accessibility. Other reasons for unsuccessful reproduction attempts include missing code, unresolvable code errors, weak or missing documentation, and software and hardware requirements and code complexity. Our findings highlight the importance of journal code and data disclosure policies and suggest potential avenues for enhancing their effectiveness. This paper was accepted by David Simchi-Levi, behavioral economics and decision analysis–fast track. Supplemental Material: The online appendices and data are available at https://doi.org/10.1287/mnsc.2023.03556.},
	number = {3},
	urldate = {2024-11-14},
	journal = {Management Science},
	author = {Fišar, Miloš and Greiner, Ben and Huber, Christoph and Katok, Elena and Ozkes, Ali I.},
	month = mar,
	year = {2024},
	note = {Publisher: INFORMS},
	keywords = {reproducibility, crowd science, replication},
	pages = {1343--1356},
	file = {Full Text PDF:/home/amy/Zotero/storage/ULZ3XRPX/Fišar et al. - 2024 - Reproducibility in Management Science.pdf:application/pdf},
}

@misc{springer_nature_springer_2024,
	title = {Springer {Nature} announces unified open code policy to better support open research practices},
	url = {https://group.springernature.com/gp/group/media/press-releases/unified-code-sharing-policy-promoting-open-science/26789930},
	urldate = {2024-11-14},
	author = {{Springer Nature}},
	month = feb,
	year = {2024},
	file = {Springer Nature announces unified open code policy to better support open research practices | Springer Nature Group | Springer Nature:/home/amy/Zotero/storage/YAQ68D3J/26789930.html:text/html},
}

@article{hamilton_prevalence_2023,
	title = {Prevalence and predictors of data and code sharing in the medical and health sciences: systematic review with meta-analysis of individual participant data},
	volume = {382},
	copyright = {© Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.. http://creativecommons.org/licenses/by-nc/4.0/This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.},
	issn = {1756-1833},
	shorttitle = {Prevalence and predictors of data and code sharing in the medical and health sciences},
	url = {https://www.bmj.com/content/382/bmj-2023-075767},
	doi = {10.1136/bmj-2023-075767},
	abstract = {Objectives To synthesise research investigating data and code sharing in medicine and health to establish an accurate representation of the prevalence of sharing, how this frequency has changed over time, and what factors influence availability.
Design Systematic review with meta-analysis of individual participant data.
Data sources Ovid Medline, Ovid Embase, and the preprint servers medRxiv, bioRxiv, and MetaArXiv were searched from inception to 1 July 2021. Forward citation searches were also performed on 30 August 2022.
Review methods Meta-research studies that investigated data or code sharing across a sample of scientific articles presenting original medical and health research were identified. Two authors screened records, assessed the risk of bias, and extracted summary data from study reports when individual participant data could not be retrieved. Key outcomes of interest were the prevalence of statements that declared that data or code were publicly or privately available (declared availability) and the success rates of retrieving these products (actual availability). The associations between data and code availability and several factors (eg, journal policy, type of data, trial design, and human participants) were also examined. A two stage approach to meta-analysis of individual participant data was performed, with proportions and risk ratios pooled with the Hartung-Knapp-Sidik-Jonkman method for random effects meta-analysis.
Results The review included 105 meta-research studies examining 2 121 580 articles across 31 specialties. Eligible studies examined a median of 195 primary articles (interquartile range 113-475), with a median publication year of 2015 (interquartile range 2012-2018). Only eight studies (8\%) were classified as having a low risk of bias. Meta-analyses showed a prevalence of declared and actual public data availability of 8\% (95\% confidence interval 5\% to 11\%) and 2\% (1\% to 3\%), respectively, between 2016 and 2021. For public code sharing, both the prevalence of declared and actual availability were estimated to be {\textless}0.5\% since 2016. Meta-regressions indicated that only declared public data sharing prevalence estimates have increased over time. Compliance with mandatory data sharing policies ranged from 0\% to 100\% across journals and varied by type of data. In contrast, success in privately obtaining data and code from authors historically ranged between 0\% and 37\% and 0\% and 23\%, respectively.
Conclusions The review found that public code sharing was persistently low across medical research. Declarations of data sharing were also low, increasing over time, but did not always correspond to actual sharing of data. The effectiveness of mandatory data sharing policies varied substantially by journal and type of data, a finding that might be informative for policy makers when designing policies and allocating resources to audit compliance.
Systematic review registration Open Science Framework doi:10.17605/OSF.IO/7SX8U.},
	language = {en},
	urldate = {2024-11-15},
	journal = {BMJ},
	author = {Hamilton, Daniel G. and Hong, Kyungwan and Fraser, Hannah and Rowhani-Farid, Anisa and Fidler, Fiona and Page, Matthew J.},
	month = jul,
	year = {2023},
	pmid = {37433624},
	note = {Publisher: British Medical Journal Publishing Group
Section: Research},
	pages = {e075767},
	file = {Full Text PDF:/home/amy/Zotero/storage/FILBGNV5/Hamilton et al. - 2023 - Prevalence and predictors of data and code sharing.pdf:application/pdf},
}

@article{loder_mandatory_2024,
	title = {Mandatory data and code sharing for research published by {The} {BMJ}},
	volume = {384},
	copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions},
	issn = {1756-1833},
	url = {https://www.bmj.com/content/384/bmj.q324},
	doi = {10.1136/bmj.q324},
	abstract = {{\textless}p{\textgreater}New policy requires authors to share analytic codes from all studies and data from all trials {\textless}/p{\textgreater}},
	language = {en},
	urldate = {2024-11-15},
	journal = {BMJ},
	author = {Loder, Elizabeth and Macdonald, Helen and Bloom, Theodora and Abbasi, Kamran},
	month = mar,
	year = {2024},
	pmid = {38443070},
	note = {Publisher: British Medical Journal Publishing Group
Section: Editorial},
	pages = {q324},
	file = {Full Text PDF:/home/amy/Zotero/storage/AV7LWM7G/Loder et al. - 2024 - Mandatory data and code sharing for research publi.pdf:application/pdf},
}

@article{noauthor_code_2023,
	title = {Code sharing in the spotlight},
	volume = {3},
	copyright = {2023 Springer Nature America, Inc.},
	issn = {2662-8457},
	url = {https://www.nature.com/articles/s43588-023-00566-4},
	doi = {10.1038/s43588-023-00566-4},
	abstract = {The Year of Open Science has highlighted the importance of sharing the code associated with peer-reviewed manuscripts. We at Nature Computational Science provide support — via policies and implementations within our submission system — to facilitate this task.},
	language = {en},
	number = {11},
	urldate = {2024-11-15},
	journal = {Nature Computational Science},
	month = nov,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Software, Computational science, Publishing, Policy},
	pages = {907--907},
	file = {Full Text PDF:/home/amy/Zotero/storage/6BIB6HPL/2023 - Code sharing in the spotlight.pdf:application/pdf},
}

@article{cadwallader_collaborating_2021,
	title = {Collaborating with our community to increase code sharing},
	volume = {17},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008867},
	doi = {10.1371/journal.pcbi.1008867},
	language = {en},
	number = {3},
	urldate = {2024-11-15},
	journal = {PLOS Computational Biology},
	author = {Cadwallader, Lauren and Papin, Jason A. and Gabhann, Feilim Mac and Kirk, Rebecca},
	month = mar,
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Scientific publishing, Reproducibility, Scientists, Survey research, Surveys, Computational biology, Publication ethics, Science policy},
	pages = {e1008867},
	file = {Full Text PDF:/home/amy/Zotero/storage/KMY2QHSW/Cadwallader et al. - 2021 - Collaborating with our community to increase code .pdf:application/pdf},
}

@article{noauthor_promoting_2024,
	title = {Promoting reproduction and replication at scale},
	volume = {8},
	copyright = {2024 Springer Nature Limited},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-024-01818-7},
	doi = {10.1038/s41562-024-01818-7},
	abstract = {Nature Human Behaviour is partnering with the Institute for Replication for the large-scale reproduction and replication of our published research.},
	language = {en},
	number = {1},
	urldate = {2024-11-15},
	journal = {Nature Human Behaviour},
	month = jan,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {general, Behavioral Sciences, Experimental Psychology, Life Sciences, Microeconomics, Neurosciences, Personality and Social Psychology},
	pages = {1--1},
	file = {Full Text PDF:/home/amy/Zotero/storage/LV3CJYG2/2024 - Promoting reproduction and replication at scale.pdf:application/pdf},
}

@article{hardwicke_transparency_2024,
	title = {Transparency {Is} {Now} the {Default} at {Psychological} {Science}},
	volume = {35},
	issn = {0956-7976},
	url = {https://doi.org/10.1177/09567976231221573},
	doi = {10.1177/09567976231221573},
	language = {en},
	number = {7},
	urldate = {2024-11-15},
	journal = {Psychological Science},
	author = {Hardwicke, Tom E. and Vazire, Simine},
	month = jul,
	year = {2024},
	note = {Publisher: SAGE Publications Inc},
	pages = {708--711},
	file = {SAGE PDF Full Text:/home/amy/Zotero/storage/MQQMBMNC/Hardwicke and Vazire - 2024 - Transparency Is Now the Default at Psychological S.pdf:application/pdf},
}

@misc{centre_for_open_science_top_nodate,
	title = {{TOP} {Guidelines}},
	url = {https://www.cos.io/initiatives/top-guidelines},
	urldate = {2024-11-15},
	journal = {Centre for Open Science},
	author = {{Centre for Open Science}},
	file = {TOP Guidelines:/home/amy/Zotero/storage/QWL4AEIS/top-guidelines.html:text/html},
}

@article{philip_simulation_2023,
	title = {Simulation modelling of hospital outpatient department: a review of the literature and bibliometric analysis},
	volume = {99},
	issn = {0037-5497},
	shorttitle = {Simulation modelling of hospital outpatient department},
	url = {https://doi.org/10.1177/00375497221139282},
	doi = {10.1177/00375497221139282},
	abstract = {The increase in demand for outpatient departments (OPDs) has contributed to overcrowded clinics and patient dissatisfaction. Computer simulation can help decision-makers meet the operational challenge of balancing the demand for outpatient services with considerations of available capacity. The paper presents a synthesis of the literature on simulation modeling in OPD using two approaches: a bibliometric analysis (employing keyword co-occurrence network) and a literature classification focusing on OPD strategy, OPD performance measures, and simulation techniques. Our review is based on 161 papers, published between 2006 and 2020, identified through a methodological search of the literature. The objective of the review is threefold: (1) to identify the major and emerging research issues in general and specialized OPD, (2) to find the commonly used performance measures in OPD and how it is associated with the strategies used to improve the performance, and (3) to identify the commonly used simulation methods for OPD modeling. A key finding from the bibliometric analysis is that most OPD research can be classified under one of the four clusters—“organization and management,”“patient satisfaction,”“overbooking,” and “performance.” We also find that patient waiting time has received much attention among the performance measures reported in the literature, followed by server idle time/overtime (server here is the OPD consultant or other healthcare resource). Our review serves as a key reference point for scholars, practitioners, students, and healthcare stakeholders, and those who use quantitative tools to aid operational decision-making.},
	language = {en},
	number = {6},
	urldate = {2024-11-15},
	journal = {SIMULATION},
	author = {Philip, Aby M and Prasannavenkatesan, Shanmugam and Mustafee, Navonil},
	month = jun,
	year = {2023},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {573--597},
	file = {SAGE PDF Full Text:/home/amy/Zotero/storage/4RHLN4JM/Philip et al. - 2023 - Simulation modelling of hospital outpatient depart.pdf:application/pdf},
}

@article{roy_healthcare_2021,
	title = {Healthcare services: {A} systematic review of patient-centric logistics issues using simulation},
	volume = {72},
	issn = {0160-5682},
	shorttitle = {Healthcare services},
	url = {https://doi.org/10.1080/01605682.2020.1790306},
	doi = {10.1080/01605682.2020.1790306},
	abstract = {Healthcare has material-centric external and patient-centric internal logistics. Researchers widely use simulation approaches to model healthcare internal logistics due to the problem complexity. There is a need to map the existing knowledge base to systematically identify the emerging research themes of this domain. This work presents a systematic literature review to identify the patient-centric logistics issues in healthcare modelled using simulation. In all, 583 papers published from 2008 to 2017 in the Clarivate Analytics Web of Science database have been collected; 238 articles were shortlisted for the review. Using keyword co-occurrence and cluster analysis, thirteen research clusters are identified, with eight of them central to the research domain and deserving further attention. Among the simulation approaches, discrete event simulation is most prevalent followed by hybrid approaches (that use two or more simulation techniques or simulation combined with analytical methods), system dynamics, agent-based simulation, and Monte Carlo simulation.},
	number = {10},
	urldate = {2024-11-15},
	journal = {Journal of the Operational Research Society},
	author = {Roy, Sumanta and Prasanna Venkatesan, Shanmugam and Goh, Mark},
	month = oct,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01605682.2020.1790306},
	keywords = {simulation, bibliometric, co-occurrence analysis, Healthcare logistics, literature review},
	pages = {2342--2364},
	file = {Full Text PDF:/home/amy/Zotero/storage/PG7B7NGA/Roy et al. - 2021 - Healthcare services A systematic review of patien.pdf:application/pdf},
}

@article{salleh_simulation_2017,
	title = {Simulation {Modelling} in {Healthcare}: {An} {Umbrella} {Review} of {Systematic} {Literature} {Reviews}},
	volume = {35},
	issn = {1179-2027},
	shorttitle = {Simulation {Modelling} in {Healthcare}},
	url = {https://doi.org/10.1007/s40273-017-0523-3},
	doi = {10.1007/s40273-017-0523-3},
	abstract = {Numerous studies examine simulation modelling in healthcare. These studies present a bewildering array of simulation techniques and applications, making it challenging to characterise the literature.},
	language = {en},
	number = {9},
	urldate = {2024-11-15},
	journal = {PharmacoEconomics},
	author = {Salleh, Syed and Thokala, Praveen and Brennan, Alan and Hughes, Ruby and Booth, Andrew},
	month = sep,
	year = {2017},
	pages = {937--949},
	file = {Full Text PDF:/home/amy/Zotero/storage/8G6ZQFMT/Salleh et al. - 2017 - Simulation Modelling in Healthcare An Umbrella Re.pdf:application/pdf},
}

@article{salmon_structured_2018,
	title = {A structured literature review of simulation modelling applied to {Emergency} {Departments}: {Current} patterns and emerging trends},
	volume = {19},
	issn = {2211-6923},
	shorttitle = {A structured literature review of simulation modelling applied to {Emergency} {Departments}},
	url = {https://www.sciencedirect.com/science/article/pii/S2211692317301042},
	doi = {10.1016/j.orhc.2018.01.001},
	abstract = {The public importance, wait-for-treatment ethos and clear geographic layout of Emergency Departments (EDs) has contributed to them being one of the most commonly modelled systems in healthcare Operational Research (OR). EDs are presently contending with higher than ever attendances, to which clinical research does not appear to have a comprehensive solution, whilst OR methodologies still need to command the trust of decision makers. With potentially greater acceptance of OR methodologies driven by heightened efforts to engage clinicians in evidence based approaches, we present a comprehensive review of the current literature. Whilst not the first in this area, our review is more broadly focused and thus able to serve both as a resource for modellers of methodology and study design, and as an introduction for decision makers. Our systematic literature search aimed to identify all English language papers from the year 2000 onward. We categorise papers using the defined dimensions of purpose, application area, method, scope and sponsor (originator). Of 254 retrievals, we find that new publications are currently appearing at approximately 25 per year, up seven fold since 2000. We find positive trends in terms of recent publications (75\% since 2008) as well as a trend towards achieving publication in journals, including healthcare related journals, which may assist in bringing simulation to a clinical audience and facilitating future engagement. The majority of projects appear to be of academic origin, based on Discrete Event Simulation, and focused on capacity, process and workforce issues at an operational level. However, the use of hybrid modelling may be associated with a more strategic outlook, as do projects originated at the request of healthcare organisations. We present a selection of case studies to illustrate both our classification and findings, and suggest directions for further research.},
	urldate = {2024-11-15},
	journal = {Operations Research for Health Care},
	author = {Salmon, Andrew and Rachuba, Sebastian and Briscoe, Simon and Pitt, Martin},
	month = dec,
	year = {2018},
	keywords = {Simulation, 4-hour target, Emergency Department, Systematic, Taxonomy, Winter pressure},
	pages = {1--13},
	file = {ScienceDirect Snapshot:/home/amy/Zotero/storage/QFLYWWNC/S2211692317301042.html:text/html},
}

@article{so_reusability_2023,
	title = {Reusability report: {Evaluating} reproducibility and reusability of a fine-tuned model to predict drug response in cancer patient samples},
	volume = {5},
	copyright = {2023 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2522-5839},
	shorttitle = {Reusability report},
	url = {https://www.nature.com/articles/s42256-023-00688-4},
	doi = {10.1038/s42256-023-00688-4},
	abstract = {Machine learning and artificial intelligence methods are increasingly being used in personalized medicine, including precision oncology. Ma et al. (Nature Cancer 2021) have developed a new method called ‘transfer of cell line response prediction’ (TCRP) to train predictors of drug response in cancer cell lines and optimize their performance in higher complex cancer model systems via few-shot learning. TCRP has been presented as a successful modelling approach in multiple case studies. Given the importance of this approach for assisting clinicians in their treatment decision processes, we sought to independently reproduce the authors’ findings and improve the reusability of TCRP in new case studies, including validation in clinical-trial datasets—a high bar for drug-response prediction. Our reproducibility results, while not reaching the same level of superiority as those of the original authors, were able to confirm the superiority of TCRP in the original clinical context. Our reusability results indicate that, in the majority of novel clinical contexts, TCRP remains the superior method for predicting response for both preclinical and clinical settings. Our results thus support the superiority of TCRP over established statistical and machine learning approaches in preclinical and clinical settings. We also developed new resources to increase the reusability of the TCRP model for future improvements and validation studies.},
	language = {en},
	number = {7},
	urldate = {2024-11-15},
	journal = {Nature Machine Intelligence},
	author = {So, Emily and Yu, Fengqing and Wang, Bo and Haibe-Kains, Benjamin},
	month = jul,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational models, Predictive medicine},
	pages = {792--798},
	file = {Full Text PDF:/home/amy/Zotero/storage/TP2B5XHD/So et al. - 2023 - Reusability report Evaluating reproducibility and.pdf:application/pdf},
}

@article{xu_reusability_2024,
	title = {Reusability report: {Uncovering} associations in biomedical bipartite networks via a bilinear attention network with domain adaptation},
	volume = {6},
	copyright = {2024 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2522-5839},
	shorttitle = {Reusability report},
	url = {https://www.nature.com/articles/s42256-024-00822-w},
	doi = {10.1038/s42256-024-00822-w},
	abstract = {Conditional domain adversarial learning presents a promising approach for enhancing the generalizability of deep learning-based methods. Inspired by the efficacy of conditional domain adversarial networks, Bai and colleagues introduced DrugBAN, a methodology designed to explicitly learn pairwise local interactions between drugs and targets. DrugBAN leverages drug molecular graphs and target protein sequences, employing conditional domain adversarial networks to improve the ability to adapt to out-of-distribution data and thereby ensuring superior prediction accuracy for new drug–target pairs. Here we examine the reusability of DrugBAN and extend the evaluation of its generalizability across a wider range of biomedical contexts beyond the original datasets. Various clustering-based strategies are implemented to resplit the source and target domains to assess the robustness of DrugBAN. We also apply this cross-domain adaptation technique to the prediction of cell line–drug responses and mutation–drug associations. The analysis serves as a stepping-off point to better understand and establish a general template applicable to link prediction tasks in biomedical bipartite networks.},
	language = {en},
	number = {4},
	urldate = {2024-11-15},
	journal = {Nature Machine Intelligence},
	author = {Xu, Tao and Shi, Haoyuan and Gao, Wanling and Wang, Xiaosong and Yue, Zhenyu},
	month = apr,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational biology and bioinformatics, Drug discovery},
	pages = {461--466},
	file = {Full Text PDF:/home/amy/Zotero/storage/SU4HG8YH/Xu et al. - 2024 - Reusability report Uncovering associations in bio.pdf:application/pdf},
}

@article{mcmanus_barriers_2019,
	title = {Barriers and {Facilitators} to {Model} {Replication} {Within} {Health} {Economics}},
	volume = {22},
	issn = {1098-3015},
	url = {https://www.sciencedirect.com/science/article/pii/S1098301519321928},
	doi = {10.1016/j.jval.2019.04.1928},
	abstract = {Background
Model replication is important because it enables researchers to check research integrity and transparency and, potentially, to inform the model conceptualization process when developing a new or updated model.
Objective
The aim of this study was to evaluate the replicability of published decision analytic models and to identify the barriers and facilitators to replication.
Methods
Replication attempts of 5 published economic modeling studies were made. The replications were conducted using only publicly available information within the manuscripts and supplementary materials. The replicator attempted to reproduce the key results detailed in the paper, for example, the total cost, total outcomes, and if applicable, incremental cost-effectiveness ratio reported. Although a replication attempt was not explicitly defined as a success or failure, the replicated results were compared for percentage difference to the original results.
Results
In conducting the replication attempts, common barriers and facilitators emerged. For most case studies, the replicator needed to make additional assumptions when recreating the model. This was often exacerbated by conflicting information being presented in the text and the tables. Across the case studies, the variation between original and replicated results ranged from −4.54\% to 108.00\% for costs and −3.81\% to 0.40\% for outcomes.
Conclusion
This study demonstrates that although models may appear to be comprehensively reported, it is often not enough to facilitate a precise replication. Further work is needed to understand how to improve model transparency and in turn increase the chances of replication, thus ensuring future usability.},
	number = {9},
	urldate = {2024-11-19},
	journal = {Value in Health},
	author = {McManus, Emma and Turner, David and Gray, Ewan and Khawar, Haseeb and Okoli, Toochukwu and Sach, Tracey},
	month = sep,
	year = {2019},
	keywords = {reproducibility, replication, decision-analytic modeling, reporting transparency},
	pages = {1018--1025},
	file = {Accepted Version:/home/amy/Zotero/storage/VSFIY5LG/McManus et al. - 2019 - Barriers and Facilitators to Model Replication Wit.pdf:application/pdf;ScienceDirect Snapshot:/home/amy/Zotero/storage/W7TCSVPA/S1098301519321928.html:text/html},
}

@article{philips_good_2006,
	title = {Good {Practice} {Guidelines} for {Decision}-{Analytic} {Modelling} in {Health} {Technology} {Assessment}},
	volume = {24},
	issn = {1179-2027},
	url = {https://doi.org/10.2165/00019053-200624040-00006},
	doi = {10.2165/00019053-200624040-00006},
	abstract = {The use of decision-analytic modelling for the purpose of health technology assessment (HTA) has increased dramatically in recent years. Several guidelines for best practice have emerged in the literature; however, there is no agreed standard for what constitutes a ‘good model’ or how models should be formally assessed. The objective of this paper is to identify, review and consolidate existing guidelines on the use of decision-analytic modelling for the purpose of HTA and to develop a consistent framework against which the quality of models may be assessed.},
	language = {en},
	number = {4},
	urldate = {2024-11-19},
	journal = {PharmacoEconomics},
	author = {Philips, Zoë and Bojke, Laura and Sculpher, Mark and Claxton, Karl and Golder, Su},
	month = apr,
	year = {2006},
	keywords = {Appraisal Committee, Decision Uncertainty, Health Technology Assessment, Probabilistic Sensitivity Analysis, Review Team},
	pages = {355--371},
	file = {Full Text PDF:/home/amy/Zotero/storage/C3H9RES7/Philips et al. - 2006 - Good Practice Guidelines for Decision-Analytic Mod.pdf:application/pdf},
}

@article{robinson_simulation_2023,
	title = {Simulation as a tool to model potential workflow enhancements in radiotherapy treatment pathways – {A} systematic review},
	volume = {24},
	copyright = {© 2023 The Authors. Journal of Applied Clinical Medical Physics published by Wiley Periodicals, LLC on behalf of The American Association of Physicists in Medicine.},
	issn = {1526-9914},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/acm2.14132},
	doi = {10.1002/acm2.14132},
	abstract = {This systematic review aimed to synthesize and summarize the use of simulation of radiotherapy pathways. The objective was to establish the suitability of those simulations in modeling the potential introduction of processes and technologies to speed up radiotherapy pathways. A systematic literature search was carried out using PubMed and Scopus databases to evaluate the use of simulation in radiotherapy pathways. Full journal articles and conference proceedings were considered, and the search was limited to the English language only. To be eligible for inclusion, articles had to model multiple sequential processes in the radiotherapy pathway concurrently to demonstrate the suitability of simulation modeling in typical pathways. Papers solely modeling scheduling, capacity, or queuing strategies were excluded. In total, 151 potential studies were identified and screened to find 18 relevant studies in October 2022. Studies showed that various pathways could be modeled, including the entire pathway from referral to end of treatment or the constituent phases such as pre-treatment, treatment, or other subcomponents. The data required to generate models varied from study to study, but at least 3 months of data were needed. This review demonstrates that modeling and simulation of radiotherapy pathways are feasible and that model output matches real-world systems. Validated models give researchers confidence to modify models with potential workflow enhancements to assess their potential effect on real-world systems. It is recommended that researchers follow best practice guidelines when building models to ensure that they are fit for purpose and to enable decision makers to have confidence in their results.},
	language = {en},
	number = {10},
	urldate = {2024-11-19},
	journal = {Journal of Applied Clinical Medical Physics},
	author = {Robinson, Andrew and Asaduzzaman, Md and Jena, Raj and Naemi, Roozbeh},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/acm2.14132},
	keywords = {discrete event simulation, computer simulations, operations research, pathway, radiotherapy, waiting times},
	pages = {e14132},
	file = {Full Text PDF:/home/amy/Zotero/storage/I7U9L36U/Robinson et al. - 2023 - Simulation as a tool to model potential workflow e.pdf:application/pdf;Snapshot:/home/amy/Zotero/storage/3X648CQY/acm2.html:text/html},
}

@phdthesis{nwanosike_direct_2023,
	title = {Direct {Oral} {Anticoagulants} ({DOACs}) use in patients with renal insufficiency and obesity},
	url = {https://pure.hud.ac.uk/ws/portalfiles/portal/83727839/Final_thesis_Nwanosike.pdf},
	language = {en},
	school = {University of Huddersfield},
	author = {Nwanosike, Ezekwesiri Michael},
	month = sep,
	year = {2023},
	file = {Nwanosike - DIRECT ORAL ANTICOAGULANTS (DOACs) USE IN PATIENTS.pdf:/home/amy/Zotero/storage/95SMRJJ5/Nwanosike - DIRECT ORAL ANTICOAGULANTS (DOACs) USE IN PATIENTS.pdf:application/pdf},
}

@misc{heather_stars_2024,
	title = {{STARS}: {Computational} reproducibility of {Hernandez} et al. 2015},
	shorttitle = {{STARS}},
	url = {https://doi.org/10.5281/zenodo.13971045},
	abstract = {This repository forms part of work package 1 on the project STARS: Sharing Tools and Artefacts for Reproducible Simulations. It assesses the computational reproducibility of: Hernandez, I., Ramirez-Marquez, J., Starr, D., McKay, R., Guthartz, S., Motherwell, M., Barcellona, J. Optimal staffing strategies for points of dispensing. Computers \& Industrial Engineering 83 (2015). https://doi.org/10.1016/j.cie.2015.02.015.},
	urldate = {2024-11-19},
	publisher = {Zenodo},
	author = {Heather, Amy and Monks, Thomas and Harper, Alison},
	month = oct,
	year = {2024},
	doi = {10.5281/zenodo.13971045},
	file = {Snapshot:/home/amy/Zotero/storage/SZR7H3ND/13971045.html:text/html},
}

@misc{anagnostou_charm_2022,
	title = {{CHARM}: {dynamiC} {Hospital} {wARd} {Management}},
	url = {https://doi.org/10.17633/rd.brunel.18517892.v1},
	publisher = {Brunel University London},
	author = {Anagnostou, Anastasia},
	month = jan,
	year = {2022},
}
