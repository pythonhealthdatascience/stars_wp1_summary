[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STARS Work Package 1",
    "section": "",
    "text": "Overview\nThis book describes the findings from work package 1 of the project STARS: Sharing Tools and Artefacts for Reproducible Simulations in healthcare.\nUse the sidebar to navigate through:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "STARS Work Package 1",
    "section": "",
    "text": "Introduction - background on the STARS project, pilot work, and the aim of work package 1\nMethods - summarises the methods which are described in detail in our protocol\nResults - describes the results of the reproductions and evaluations, and reflections from the process\nDiscussion - considers and applies findings",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#funding",
    "href": "index.html#funding",
    "title": "STARS Work Package 1",
    "section": "Funding",
    "text": "Funding\nThis work is supported by the Medical Research Council [grant number MR/Z503915/1].",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "STARS Work Package 1",
    "section": "License",
    "text": "License\nThis book is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "pages/background.html",
    "href": "pages/background.html",
    "title": "2  Introduction",
    "section": "",
    "text": "2.1 Pilot work",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "pages/background.html#pilot-work",
    "href": "pages/background.html#pilot-work",
    "title": "2  Introduction",
    "section": "",
    "text": "2.1.1 Review of healthcare simulation sharing practices\nMonks and Harper (2023) explored how discrete-event simulation (DES) models used in a health context (e.g. health services, health economics) were shared and whether this sharing adhered to best practice. The full study can be viewed at:\n\nMonks, Thomas, and Alison Harper. 2023. “Computer Model and Code Sharing Practices in Healthcare Discrete-Event Simulation: A Systematic Scoping Review.” Journal of Simulation 0 (0): 1–16. https://doi.org/10.1080/17477778.2023.2260772.\n\nIn summary, they identified 564 papers describing a DES model from a health context published from 2019 to 2022. Of these, only 8.3% (47/564) had available model code (either sharing the code themselves, or citing an openly available model). Looking by year, this rose from 4.0% for studies published in 2019, to 9.0% for 2022.\nFurther findings:\n\nMore likely that code was shared if model was:\n\nCreated using free and open source software (FOSS) (28.7%, 29/101)\nA COVID-19 model (24.6%, 17/69)\n\nOf the papers that did share a model:\n\nMost were written in a programming language (66%, 31/47), the rest in a commercial off the shelf Visual Interactive Modelling (VIM) software\nThese were evaluated in a best practice audit, with the results as follows: “In general, computer models and artefacts were published without a DOI (n = 7); rarely included ORCIDs for authors (n = 6); rarely included an open licence (n = 21); were mostly supported by a README file (n = 28); rarely included documentation detailing how to run the model (n = 15); provided no form of formal or informal dependency management (n = 21); did not include any evidence of model testing (n = 3); were almost all downloadable (n = 38); and rarely executable via a cloud-based platform (n = 10).” (Monks and Harper (2023))\n\nFew studies used a reporting guideline (12.8%, 72/564) - mostly using:\n\nOne of the International Society for Pharmacoeconomics and Outcomes Research (ISPOR) publications (n=37), or\nThe Strengthening the Reporting of Empirical Simulation Studies (STRESS) guidelines from Monks et al. (2019) (n=22)\n\n\nThe review concludes that “there are many (simple) best practices the community can adopt, such as the use of trusted archives, and documentation, to improve its sharing”. (Monks and Harper (2023))\n\n\n2.1.2 Pilot STARS framework\nMonks, Harper, and Mustafee (2024) introduces a pilot framework for sharing DES models called STARS: Sharing Tools and Artefacts for Reusable Simulations. Note that this “reusable” is changed into “reproducible” for the STARS project as we build on this work in the current project.\nThe pilot STARS framework consists of essential components (minimum to make models “long-term, citable, functional, appropriately licenced”) and optional components (enhance model “accessibility, understanding, and maintainability”). (Monks, Harper, and Mustafee (2024))\nThe essential components are:\n\nOpen license\nDependency management\nFOSS model\nMinimum documentation\nOpen Researcher and Contributor IDs (ORCID)\nCitation information\nRemote code repository\nOpen science archive\n\nThe optional components are:\n\nEnhanced documentation\nDocumentation hosting\nOnline coding environment\nModel interface\nWeb app hosting\n\nThis is summarised in the diagram below…\n\n\n\nSTARS framework overview\n\n\nThis was supported by example implementations in Python:\n\nExample 1 - stars-treat-sim\nExample 2 - stars-streamlit-example and stars-simpy-example-docs - with web app and hosted docs\nExample 3 - stars-ciw-example - with web app and hosted docs",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "pages/background.html#stars-project",
    "href": "pages/background.html#stars-project",
    "title": "2  Introduction",
    "section": "2.2 STARS project",
    "text": "2.2 STARS project\nThe MRC-funded STARS project builds on this pilot work. As stated in the funding application, the objective of this project is “to improve the quality and quantity of shared discrete-event simulation models, tools and other research artefacts:\n\nIdentify barriers, and good practices for sharing simulation models;\nDevelop a new framework for sharing computer models applicable the most common free and open-source languages;\nTest the framework in both retrospective and prospective case studies;\nDevelop online interactive training materials;\nTransfer knowledge of our STARS framework to health data science researchers;\nEnsure sustainability of materials;\nSupport our partner archival journals adopt open science principles and our findings;”\n\nThis objectives will be achieved through four work packages:\nWork package 1: Reproducibility of computational results\n\nAssess the computational reproducibility of six published DES models created in Python and R.\nEvaluate the publication, code and associated artefacts against reporting guidelines, best practice for code sharing, and criteria from journal artefact badges.\n\nWork package 2: R and Python framework for sharing DES models\n\nImprove the pilot framework (e.g. extend baesd on barriers and enablers to reproduction observed in work package 1, and making it relevant to R models)\nProvide time-saving measures for researchers (e.g. automated support for STRESS, use of large language models (LLM) to support creating of summaries, automated testing of models, continuous integration tools)\n\nWork package 3: Prospective and retrospective application of the framework\n\nApply STARS framework within two case studies (one prospective and one retrospective)\n\nWork package 4: Training\n\nDevelop online interactive training materials to support researchers in using the STARS framework\n\nFrom this point onwards, this site/book summarises the findings from work package 1.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "pages/background.html#references",
    "href": "pages/background.html#references",
    "title": "2  Introduction",
    "section": "2.3 References",
    "text": "2.3 References\n\n\n\n\nMonks, Thomas, Christine S. M. Currie, Bhakti Stephan Onggo, Stewart Robinson, Martin Kunc, and Simon J. E. Taylor. 2019. “Strengthening the Reporting of Empirical Simulation Studies: Introducing the STRESS Guidelines.” Journal of Simulation 13 (1): 55–67. https://doi.org/10.1080/17477778.2018.1442155.\n\n\nMonks, Thomas, and Alison Harper. 2023. “Computer Model and Code Sharing Practices in Healthcare Discrete-Event Simulation: A Systematic Scoping Review.” Journal of Simulation 0 (0): 1–16. https://doi.org/10.1080/17477778.2023.2260772.\n\n\nMonks, Thomas, Alison Harper, and Navonil Mustafee. 2024. “Towards Sharing Tools and Artefacts for Reusable Simulations in Healthcare.” Journal of Simulation 0 (0): 1–20. https://doi.org/10.1080/17477778.2024.2347882.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "pages/protocol.html",
    "href": "pages/protocol.html",
    "title": "3  Methods",
    "section": "",
    "text": "3.1 Protocol summary\nFor this work, six published healthcare DES models were selected. These were models with publicly available code under an open license (either already available or add on request from the STARS team). For each model, the follow stages of work were conducted:\nStage 1: Reproduction - assessing the computational reproducibility of each study\nStage 2: Evaluation - evaluating the publication, code and associated artefacts against sharing and reporting standards\nStage 3: Report and research compendium - summary report and organised repository\nFor each study, a quarto site was produced which shared the results from the reproduction and evaluation and the summary report. Throughout the work, a detailed logbook was kept to keep track of timings and to record work on each stage, such as detailing troubleshooting steps during the reproduction, or uncertainities discussed with another STARS team member during the evaluation.\nSummary diagram\nThis process is captured in the diagram below:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "pages/protocol.html#protocol-summary",
    "href": "pages/protocol.html#protocol-summary",
    "title": "3  Methods",
    "section": "",
    "text": "Informed authors about study and, if not available, asked if they would be happy to add an open license to their code\nSet up repository for reproduction with the article and code\nRead the article and defined the scope of the reproduction, archiving the scope (and repository) on Zenodo before proceeding\nLooked over the model code, created a suitable environment with the software and packages required, and then ran the model. For each study, with any issues faced in running the model, troubleshooting was performed such as modifying or writing code. If troubleshooting was exhaused and there were still issues or discrepancies in the results, the original study authors were informed and provided the opportunity to advice on the reason for this (although with no pressure or requirement to do so)\nFor each item in the scope, a decision was made as to whether this had been successfully reproduced or not. This was a subjective decision which allowed some expected deviation due to model stochasticity (for example, lack of seed control).\nThis is timed (including time to produce each item in the scope), and limited to a maximum of 40 horus\n\n\n\nThe publication was evaluated against reporting guidelines for DES:\n\nMonks et al. (2019) - STRESS-DES: Strengthening The Reporting of Empirical Simulation Studies (Discrete-Event Simulation) (Version 1.0).\nZhang, Lhachimi, and Rogowski (2020) - The generic reporting checklist for healthcare-related discrete event simulation studies derived from the the International Society for Pharmacoeconomics and Outcomes Research Society for Medical Decision Making (ISPOR-SDM) Modeling Good Research Practices Task Force reports.\n\nThe model code and associated artefacts (e.g. the GitHub repository shared by the authors) was evaluated against:\n\nThe criteria of badges related to reproducibility from various organisations and journals - namely:\n\nNational Information Standards Organisation (NISO)(NISO Reproducibility Badging and Definitions Working Group (2021))\nAssociation for Computing Machinery (ACM) (Association for Computing Machinery (ACM) (2020))\nCenter for Open Science (COS) (Blohowiak et al. (2023))\nInstitute of Electrical and Electronics Engineers (IEEE) (Institute of Electrical and Electronics Engineers (IEEE) (n.d.))\nPsychological Science (Hardwicke and Vazire (2023) and Association for Psychological Science (APS) (2023))\n\nRecommendations from the pilot STARS framework for the sharing of code and associated materials from discrete-event simulation models (Monks, Harper, and Mustafee (2024)).\n\nThis is timed\n\n\n\nWrote a report summarising the computational reproducibility assessment and evaluation\nRestructed the reposuitory into a “research compendium”, which essentially consisted of organising the repository to ensure it is easy and clear for someone else to re-run. Steps included:\n\nAdding run times to the model notebooks\nWrite a README for the reproduction folder\nMoving data, methods and outputs into seperate folders\nCreating tests which check if a user can get the same results from the model as we did during the reproduction\nA Dockerfile and Docker image published on the GitHub container registry\n\nA second researcher from the STARS team then attempted to use the repository and confirm whether they were able to reproduce the results of the first researcher\nFinally, the repository was archived on Zenodo, and the authors were informed.\n\n\n\n\n\n\n\nWorkflow for STARS work package 1",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "pages/protocol.html#minor-deviations-from-the-protocol",
    "href": "pages/protocol.html#minor-deviations-from-the-protocol",
    "title": "3  Methods",
    "section": "3.2 Minor deviations from the protocol",
    "text": "3.2 Minor deviations from the protocol\nThere were some minor deviations from the protocol, which are explained below…\n\n\n\n\n\n\n\nDeviation\nDescription and reason for the change\n\n\n\n\nUsing the latest software packages\nIn the protocol, I had planned that - if no versions were provided we select a version of the software and each package that is closest to but still prior to the date of the code archive or paper publication. I kept to this for the Python models (easily set using a conda/mamba environment). However, I had great difficulties attempting to do this in R, and could not successfully backdate both. As such, I used the latest versions of R and each package for those studies\n\n\nUsing percentage difference in results to help decided reproduction success\nThis is not particularly deviation, as I did explore this, but I ultimately found it very unhelpful, as the percentage difference could be greatly impacted by scale (for example, 0.1 vs 0.2 would appear much greater than 3 vs 4, but the actual meaning of these differences might be similar (e.g. both might be considered a small difference) depending on the scale used and what is being compared - whilst in another context with a different scale, 0.1 vs 0.2 might actually reflect a huge difference!).\n\n\nMoving onto evaluation stage before receive author response regarding reproduction discrepancy\nIn the protocol, we required that authors are contacted if there are any remaining difficulties in running the code or items in the scope that were not reproduced. The authors were given a total of four weeks to respond if they chose to. We had implied that we must wait for this time to pass before continuing to the evaluation stage (since the three stages were presented as being completed one after another). The rationale for this was that the timings for the reproduction would be influenced by whether the evaluation had been completed or not, and vice versa. However, given the many possible influences on the timings, this was considered negligble.\n\n\nOrganisation of the repository for the research compendium\nIn the protocol, we had planned that seperate folders were created for data, methods and outputs. This was generally followed but, if an alternative structure seemed more suitable (for example, if the original study already divided items well, but perhaps with different folder names or with multiple scripts folders or so on, we might have used that original structure, as it still served the purpose of being clear and easy to re-run, whilst reducing the number of differences compared with the original study).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "pages/protocol.html#timings",
    "href": "pages/protocol.html#timings",
    "title": "3  Methods",
    "section": "3.3 Timings",
    "text": "3.3 Timings\nAs per the protocol, the reproduction and evaluation stages were timed. Although this was conducted carefully and thoroughly, it will not be perfect, and we recognise some of the potential sources of variation in timings between studies, such as:\n\nWhether we consistently included amendments to the quarto site and repository and time spent on GitHub commits etc. within the timings for the reproduction.\nFor the first R study (Huang et al. (2019)), I initially tried to create an environment with R and package versions prior to the article publication date, although had great difficulties with this and ended up using the latest versions. This contributed to the set-up time during this reproduction, but on later R models (Kim et al. (2021) and Johnson et al. (2021)), based on that experience, I did not attempt to backdate them when getting started.\nAny estimated times (for example, if I were partway through working but someone in the office came to talk to me and I forgot to note the time of that, I might estimate if that were about five or ten minutes of conversation, and set the time accordingly).\nTimings from consensus discussions regarding uncertainities in the evaluation or reproduction (as these might be longer if done in person rather than over email - or vice versa - and I sometimes spent longer on sorting/tidying these for some studies than others, which I would have included in the time)\nWhether subjectively feel that need to add random seeds during reproduction stage, if results vary considerably between each run, and so a certain seed could get a much more similar result than another\n\nAt an estimate, this uncertainty between study timings would lead me to conclude that the timings are approximately correct, give or take up to about four hours. However, this is just an estimate, and it is worth noting that Krafczyk et al. (2021), who also conducted computational reproducibility assessments in a different context, estimated that human error introduced a maximum of 8 hours ambiguity in the timings, due to the “non-precise nature of starting and stopping the watch consistently”.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "pages/protocol.html#references",
    "href": "pages/protocol.html#references",
    "title": "3  Methods",
    "section": "3.4 References",
    "text": "3.4 References\n\n\n\n\nAssociation for Computing Machinery (ACM). 2020. “Artifact Review and Badging Version 1.1.” ACM. https://www.acm.org/publications/policies/artifact-review-and-badging-current.\n\n\nAssociation for Psychological Science (APS). 2023. “Psychological Science Submission Guidelines.” APS. https://www.psychologicalscience.org/publications/psychological_science/ps-submissions.\n\n\nBlohowiak, Ben B., Johanna Cohoon, Lee de-Wit, Eric Eich, Frank J. Farach, Fred Hasselman, Alex O. Holcombe, Macartan Humphreys, Melissa Lewis, and Brian A. Nosek. 2023. “Badges to Acknowledge Open Practices.” https://osf.io/tvyxz/.\n\n\nHardwicke, Tom E., and Simine Vazire. 2023. “Transparency Is Now the Default at Psychological Science.” Psychological Science 0 (0). https://doi.org/https://doi.org/10.1177/09567976231221573.\n\n\nHeather, Amy, Thomas Monks, Alison Harper, Navonil Mustafee, and Andrew Mayne. 2024. “Protocol for Assessing the Computational Reproducibility of Discrete-Event Simulation Models on STARS,” June. https://zenodo.org/records/12179846.\n\n\nHuang, Shiwei, Julian Maingard, Hong Kuan Kok, Christen D. Barras, Vincent Thijs, Ronil V. Chandra, Duncan Mark Brooks, and Hamed Asadi. 2019. “Optimizing Resources for Endovascular Clot Retrieval for Acute Ischemic Stroke, a Discrete Event Simulation.” Frontiers in Neurology 10 (June). https://doi.org/10.3389/fneur.2019.00653.\n\n\nInstitute of Electrical and Electronics Engineers (IEEE). n.d. “About Content in IEEE Xplore.” IEEE Explore. Accessed May 20, 2024. https://ieeexplore.ieee.org/Xplorehelp/overview-of-ieee-xplore/about-content.\n\n\nJohnson, Kate M., Mohsen Sadatsafavi, Amin Adibi, Larry Lynd, Mark Harrison, Hamid Tavakoli, Don D. Sin, and Stirling Bryan. 2021. “Cost Effectiveness of Case Detection Strategies for the Early Detection of COPD.” Applied Health Economics and Health Policy 19 (2): 203–15. https://doi.org/10.1007/s40258-020-00616-2.\n\n\nKim, Lois G., Michael J. Sweeting, Morag Armer, Jo Jacomelli, Akhtar Nasim, and Seamus C. Harrison. 2021. “Modelling the Impact of Changes to Abdominal Aortic Aneurysm Screening and Treatment Services in England During the COVID-19 Pandemic.” PLOS ONE 16 (6): e0253327. https://doi.org/10.1371/journal.pone.0253327.\n\n\nKrafczyk, M. S., A. Shi, A. Bhaskar, D. Marinov, and V. Stodden. 2021. “Learning from Reproducing Computational Results: Introducing Three Principles and the Reproduction Package.” Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 379 (2197): 20200069. https://doi.org/10.1098/rsta.2020.0069.\n\n\nMonks, Thomas, Christine S. M. Currie, Bhakti Stephan Onggo, Stewart Robinson, Martin Kunc, and Simon J. E. Taylor. 2019. “Strengthening the Reporting of Empirical Simulation Studies: Introducing the STRESS Guidelines.” Journal of Simulation 13 (1): 55–67. https://doi.org/10.1080/17477778.2018.1442155.\n\n\nMonks, Thomas, Alison Harper, and Navonil Mustafee. 2024. “Towards Sharing Tools and Artefacts for Reusable Simulations in Healthcare.” Journal of Simulation 0 (0): 1–20. https://doi.org/10.1080/17477778.2024.2347882.\n\n\nNISO Reproducibility Badging and Definitions Working Group. 2021. “Reproducibility Badging and Definitions.” https://doi.org/10.3789/niso-rp-31-2021.\n\n\nZhang, Xiange, Stefan K. Lhachimi, and Wolf H. Rogowski. 2020. “Reporting Quality of Discrete Event Simulations in Healthcare—Results From a Generic Reporting Checklist.” Value in Health 23 (4): 506–14. https://doi.org/10.1016/j.jval.2020.01.005.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "pages/reproduction.html",
    "href": "pages/reproduction.html",
    "title": "4  Reproduction",
    "section": "",
    "text": "4.1 Studies\nShoaib and Ramamohan (2021): Uses python (salabim) to model primary health centres (PHCs) in India. The model has four patient types: outpatients, inpatients, childbirth cases and antenatal care patients. Four model configurations are developed based on observed PHC practices or government-mandated operational guidelines. The paper explores different operational patterns for scenarios where very high utilisation was observed, to explore what might help reduce utilisation of these resources. Note: The article was as Shoaib and Ramamohan (2022), but we used the green open access pre-print Shoaib and Ramamohan (2021). Link to reproduction.\nHuang et al. (2019): Uses R (simmer) to model an endovascular clot retrieval (ECR) service. ECR is a treatment for acute ischaemic stroke. The model includes the stroke pathway, as well as three other pathways that share resources with the stroke pathway: an elective non-stroke interventional neuroradiology pathway, an emergency interventional radiology pathway, and an elective interventional radiology pathway. The paper explores waiting times and resource utilisation - particularly focussing on the biplane angiographic suite (angioINR). A few scenarios are tried to help examine why the wait times are so high for the angioINR. Link to reproduction.\nLim et al. (2020): Uses python (numpy and pandas) to model the transmission of COVID-19 in a laboratory. It examines the proportion of staff infected in scenarios varying the: number of shifts per day; number of staff per shift; overall staff pool; shift patterns; secondary attack rate of the virus; introduction of protective measures (social distancing and personal protective equipment). Link to reproduction.\nKim et al. (2021): Adapts a previously developed R (Rcpp, expm, msm, foreach, iterators, doParallel) model for abdominal aortic aneurysm (AAA) screening of men in England. The model is adapted/used to explore different approaches to resuming screening and surgical repair for AAA, as these survives were paused or substantially reduced during COVID-19 due to concerns about virus transmission. Link to reproduction.\nAnagnostou et al. (2022): This paper includes two models - we have focussed just on the dynamiC Hospital wARd Management (CHARM) model. CHARM uses Python (simpy) to model intensive care units (ICU) in the COVID-19 pandemic (as well as subsequent stays in a recovery bed). It includes three types of admission to the ICU (emergency, elective or COVID-19). COVID-19 patients are kept seperate, and if they run out of capacity due to a surge in COVID-19 admissions, additional capacity can be pooled from the elective and emergency capacity. Link to reproduction.\nJohnson et al. (2021): TBC",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reproduction</span>"
    ]
  },
  {
    "objectID": "pages/reproduction.html#scope",
    "href": "pages/reproduction.html#scope",
    "title": "4  Reproduction",
    "section": "4.2 Scope",
    "text": "4.2 Scope\n\n\n\n\n\n\n\n\n\nStudy\nScope\nSuccess\nTime\n\n\n\n\nShoaib and Ramamohan 2022\n17 items:• 1 table• 9 figures• 7 in-text results\n16 out of 17 (94%)\n28h 14m\n\n\nHuang et al. 2019\n8 items:• 5 figures• 3 in-text results\n3 out of 8 (37.5%)\n24h 10m\n\n\nLim et al. 2020\n9 items:• 5 tables• 4 figures\n9 out of 9 (100%)\n12h 27m\n\n\nKim et al. 2021\n10 items:• 3 tables• 6 figures• 1 in-text result\n10 out of 10 (100%)\n13h 59m\n\n\nAnagnostou et al. 2022\n1 item:• 1 figure\n1 out of 1 (100%)\n2h 10m\n\n\nJohnson et al. 2021\n5 items:• 1 table• 4 figures\nTBC\nTBC",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reproduction</span>"
    ]
  },
  {
    "objectID": "pages/reproduction.html#time-to-completion",
    "href": "pages/reproduction.html#time-to-completion",
    "title": "4  Reproduction",
    "section": "4.3 Time to completion",
    "text": "4.3 Time to completion\n\nNon-interactive figure:\n\n\n\n\n\n\n\n\n\nInteractive figure:",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reproduction</span>"
    ]
  },
  {
    "objectID": "pages/reproduction.html#references",
    "href": "pages/reproduction.html#references",
    "title": "4  Reproduction",
    "section": "4.4 References",
    "text": "4.4 References\n\n\n\n\nAnagnostou, Anastasia, Derek Groen, Simon J. E. Taylor, Diana Suleimenova, Nura Abubakar, Arindam Saha, Kate Mintram, et al. 2022. “FACS-CHARM: A Hybrid Agent-Based and Discrete-Event Simulation Approach for Covid-19 Management at Regional Level.” In 2022 Winter Simulation Conference (WSC), 1223–34. https://doi.org/10.1109/WSC57314.2022.10015462.\n\n\nHuang, Shiwei, Julian Maingard, Hong Kuan Kok, Christen D. Barras, Vincent Thijs, Ronil V. Chandra, Duncan Mark Brooks, and Hamed Asadi. 2019. “Optimizing Resources for Endovascular Clot Retrieval for Acute Ischemic Stroke, a Discrete Event Simulation.” Frontiers in Neurology 10 (June). https://doi.org/10.3389/fneur.2019.00653.\n\n\nJohnson, Kate M., Mohsen Sadatsafavi, Amin Adibi, Larry Lynd, Mark Harrison, Hamid Tavakoli, Don D. Sin, and Stirling Bryan. 2021. “Cost Effectiveness of Case Detection Strategies for the Early Detection of COPD.” Applied Health Economics and Health Policy 19 (2): 203–15. https://doi.org/10.1007/s40258-020-00616-2.\n\n\nKim, Lois G., Michael J. Sweeting, Morag Armer, Jo Jacomelli, Akhtar Nasim, and Seamus C. Harrison. 2021. “Modelling the Impact of Changes to Abdominal Aortic Aneurysm Screening and Treatment Services in England During the COVID-19 Pandemic.” PLOS ONE 16 (6): e0253327. https://doi.org/10.1371/journal.pone.0253327.\n\n\nLim, Chun Yee, Mary Kathryn Bohn, Giuseppe Lippi, Maurizio Ferrari, Tze Ping Loh, Kwok-Yung Yuen, Khosrow Adeli, and Andrea Rita Horvath. 2020. “Staff Rostering, Split Team Arrangement, Social Distancing (Physical Distancing) and Use of Personal Protective Equipment to Minimize Risk of Workplace Transmission During the COVID-19 Pandemic: A Simulation Study.” Clinical Biochemistry 86 (December): 15–22. https://doi.org/10.1016/j.clinbiochem.2020.09.003.\n\n\nShoaib, Mohd, and Varun Ramamohan. 2021. “Simulation Modelling and Analysis of Primary Health Centre Operations.” arXiv, June. https://doi.org/10.48550/arXiv.2104.12492.\n\n\n———. 2022. “Simulation Modeling and Analysis of Primary Health Center Operations.” SIMULATION 98 (3): 183–208. https://doi.org/10.1177/00375497211030931.",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reproduction</span>"
    ]
  },
  {
    "objectID": "pages/reflections.html",
    "href": "pages/reflections.html",
    "title": "5  Reflections from reproductions",
    "section": "",
    "text": "5.1 Environment",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reflections from reproductions</span>"
    ]
  },
  {
    "objectID": "pages/reflections.html#environment",
    "href": "pages/reflections.html#environment",
    "title": "5  Reflections from reproductions",
    "section": "",
    "text": "List required packages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n❌\n🟡\n✅\n✅\n\n\n\n\nShoaib and Ramamohan (2021): Not met. This became a time-consuming issue as it took a while to identify a dependency that was needed for the code to work (greenlet) (based on reading the documentation for salabim), and a while longer to realise I had installed another package when the package I needed was in base (statistics).\nHuang et al. (2019): Not met. However, this was fairly easily resolved based on imports to .R script, and then on extra imports suggested by RStudio when I tried and failed to run the script.\nLim et al. (2020): Partially met. The only packages needed (numpy and pandas) are mentioned in the paper (although only listed as imports in the script).\nKim et al. (2021): Fully met. Provides commands to install packages required at the start of scripts, which I could then easily base renv on automatically (as it detects them).\nAnagnostou et al. (2022): Fully met. Provides requirements.txt\nJohnson et al. (2021): \nReflections:\n\nThe import statements can be sufficient in indicating all the packages required but this is not always the case if there are “hidden”/unmentioned dependencies that don’t get imported\nThere are various options for listing the packages (e.g. comprehensive import statements, installation lines in the script, environment files).\nThis was a common issue.\n\n\n\n\n\n\n\n\n\n\nProvide versions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n❌\n🟡\n🟡\n🟡\n\n\n\n\nShoaib and Ramamohan (2021): Not met. I had to backdate the package versions as the model didn’t work with the latest.\nHuang et al. (2019): Not met. I initially tried to create an environment with R and package versions that were prior to the article publication date. However, I had great difficulties implementing this with R, and never managed to successfully do this. This was related to:\n\nThe difficulty of switching between R versions\nProblems in finding available/a source for specific package versions for specific versions or R\n\nLim et al. (2020): Partially met. Provides major Python version, but chose minor and the package versions based on article publication date.\nKim et al. (2021): Partially met. States version of R but not package. Due to prior issues with backdating R, used latest versions. There were no issues using the latest versions of R and packages, but if there had been, it would be important to know what versions had previously been used and worked.\nAnagnostou et al. (2022): Partially met (depending on how strict you are being). The Python version was stated in the paper, and the simpy version was stated in the complementary app repository (although neither were mentioned in the model repository itself).\nJohnson et al. (2021): \nReflections:\n\nModels will sometimes work with the latest versions of packages, but likewise, you will sometimes need to backdate as it no longer works with the latest\nFor Python, it was very easy to “backdate” the python and package versions. However, I found this very difficult to in R, and ended up always using the latest versions.\nVersions are sometimes provided elsewhere (e.g. in paper, in other repositories), but would be handy to be in model repository itself\nThis was a very common issue.",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reflections from reproductions</span>"
    ]
  },
  {
    "objectID": "pages/reflections.html#structure-of-code-and-scripts",
    "href": "pages/reflections.html#structure-of-code-and-scripts",
    "title": "5  Reflections from reproductions",
    "section": "5.2 Structure of code and scripts",
    "text": "5.2 Structure of code and scripts\n\n\n\n\n\n\nModel is provided in a “runnable” format\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n✅\n❌\n✅\n✅\n✅\n\n\n\n\nShoaib and Ramamohan (2021): Fully met. Provided as a single .py file which ran model with function main().\nHuang et al. (2019): Not met. The model code was provided within the code for a web application, but the paper was not focused on this application, and instead on specific model scenarios. I had to extract the model code and transform it into a format that was “runnable” as an R script/notebook.\nLim et al. (2020): Fully met. Provided as a single .py file which ran the model with a for loop.\nKim et al. (2021): Fully met. Has seperate .R scripts for each scenario which ran the model by calling functions from elsewhere in repository.\nAnagnostou et al. (2022): Fully met. Can run model from command line.\nJohnson et al. (2021): \nReflections:\n\nIf you are presenting the results of a model, then provide the code for that model in a “runnable” format.\nThis was an uncommon issue.\n\n\n\n\n\n\n\n\n\n\nModel is designed to be run programmatically (i.e. can run model with different parameters without needing to change the model code)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n✅\n✅\n✅\n✅\n\n\n\n\nShoaib and Ramamohan (2021): Not met. The model is set up as classes and run using a function. However, it is not designed to allow any variation in inputs. Everything uses default inputs, and it designed in such a way that - if you wish to vary model parameters - you need to directly change these in the script itself. This meant you couldn’t run multiple versions of the model using the same script. It also meant hidden errors were more likely (e.g. if miss changing a parameter somewhere, or input the wrong parameters and don’t realise).\nHuang et al. (2019): Fully met. Model was set up as a function, with many of the required parameters already set as “changeable” inputs to that function.\nLim et al. (2020): Fully met. The model is created from a series of functions and run with a for loop that iterates through different parameters. As such, the model is able to be run programmatically (within that for loop, which varied e.g. staff per shift and so on and re-ran the model).\nKim et al. (2021): Fully met. Each scenario is an R script which states different parameters and then calls functions to run model.\nAnagnostou et al. (2022): Fully met. Change inputs in input .csv files.\nJohnson et al. (2021): \nReflections:\n\nDesign model so that you can re-run it with different parameters without needing to make changes to the model code itself.\n\nThis allows you to run multiple versions of the model with the same script.\nIt also reduces the likelihood of missing errors (e.g. if miss changing an input parameter somewhere, or input the wrong parameters and don’t realise).\n\nThis was an uncommon issue.\n\n\n\n\n\n\n\n\n\n\nDon’t hard code parameters that you will want to change for scenario analyses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n🟡\n❌\n✅\nN/A\n\n\n\n\nShoaib and Ramamohan (2021): Not met. Although some parameters sat “outside” of the model within the main() function (and hence were more “changeable”, even if not “changeable” inputs to that function, but changed directly in script). However, many of the other parameters were hard-coded within the model itself. It took time to spot where these were and correctly adjust them to be modifiable inputs.\nHuang et al. (2019): Partially met. Pretty much all of the parameters that we wanted to change were not hard coded and were instead inputs to the model function simulate_nav(). However, I did need to add an exclusive_use scenario which conditionally changed ir_resources, but that is the only exception. I also add ed_triage as a changeable input but didn’t end up needing that to reproduce any results (was just part of troubleshooting). I also\nLim et al. (2020): Not met. Some parameters were not hard coded within the model, but lots of them were not.\nKim et al. (2021): Fully met. All model parameters could be varied from “outside” the model code itself, as they were provided as changeable inputs to the model.\nAnagnostou et al. (2022): N/A as no scenarios.\nJohnson et al. (2021): \nReflections:\n\nIt can be quite difficult to change parameters that are hard coded into the model. Ideally, all the parameters that a user might want to change should be easily changeable and not hard coded.\nThis is a somewhat common issue.\nThere is overlap between this and whether the code for scenarios is provided (as typically, the code for scenario is conditionally changing parameter values, although this can be facilitated by not hard coding the parameters, so you call need to change the values from “outside” the model code, rather than making changes to the model functions themselves). Hence, have included as two seperate reflections.\n\n\n\n\n\n\n\n\n\n\nAvoid large amounts of code duplication\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n✅\n✅\n❌\n✅\n\n\n\n\nShoaib and Ramamohan (2021): Not met. The model often contained very similar blocks of code before or after warm-up. This has the potential to introduce mistakes - with a suspected (although unconfirmed) mistake being that the lower boundary for the doctor consultation times in configuration 1 differed before and after warm-up.\nHuang et al. (2019): Fully met.\nLim et al. (2020): Fully met.\nKim et al. (2021): Not met. There was alot of duplication when running each scenario (e.g. repeated calls to Eventsandcosts, and repeatedly defining the same parameters). This meant, if changing a parameter that you want to be consistent between all the scripts (e.g. number of persons), you had to change each of the scripts one by one.\nJohnson et al. (2021): Fully met.\nJohnson et al. (2021): \nReflections: Large amounts of code duplication are non-ideal as they can:\n\nMake code less readable\nMake it trickier to change universal parameters\nIncrease the likelihood of introducing mistakes\n\n\n\n\n\n\n\n\n\n\nInclude sufficient comments in the code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n❌\n✅\n🟡\n🟡\n\n\n\n\nShoaib and Ramamohan (2021) and Huang et al. (2019): Not met. Would have benefitted from more comments, as it took some time to ensure I have correctly understood code, particularly if they used lots of abbreviations.\nLim et al. (2020): Fully met. There were lots of comments in the code (including doc-string-style comments at the start of functions) that aided understanding of how it worked.\nKim et al. (2021): Partially met. Didn’t have any particular issues in working out the code. There are sufficient comments in the scenario scripts and at the start of the model scripts, although within the model scripts, there were sometimes quite dense sections of code that would likely benefit from some additional comments.\nAnagnostou et al. (2022): Partially met. Didn’t have to delve into the code much, so can’t speak from experience as to whether the comments were sufficient. From looking through the model code, several scripts have lots of comments and docstrings for each function, but some do not.\nJohnson et al. (2021): \nReflections:\n\nWith increasing code complexity, the inclusion of sufficient comments becomes increasingly important, as it can otherwise be quite time consuming to figure out how to fix and change sections of code\nDefine abbreviations used within the code\nGood to have consistent comments and docstrings throughout (i.e. on all scripts, on not just some of them)",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reflections from reproductions</span>"
    ]
  },
  {
    "objectID": "pages/reflections.html#run-time-and-memory-usage",
    "href": "pages/reflections.html#run-time-and-memory-usage",
    "title": "5  Reflections from reproductions",
    "section": "5.3 Run time and memory usage",
    "text": "5.3 Run time and memory usage\n\n\n\n\n\n\nQuicker models are easier to work with\n\n\n\n\n\nI have not evaluated like as a criteria, as a long run time is not inherently a bad thing. However, I definitely found that the run time of models had a big impact on how easy it was to reproduce results as longer run times meant it was tricky (or even impossible) to run in the first place, or tricky to re-run.\nThe studies where I made adjustments were:\n\nShoaib and Ramamohan (2021): Add parallel processing and ran fewer replications\nHuang et al. (2019): No changes made.\nLim et al. (2020): Add parallel processing\nKim et al. (2021): Reduced number of people in simulation, and switched from serial to the provided parallel option.\nAnagnostou et al. (2022): Model was super quick which made it really easy to run and re-run each time\nJohnson et al. (2021): \n\nFor Kim et al. (2021), an error appears to have been introduced with the aoorta diameter thresholds by switching between nested and unnested lists, which I’m anticipating was unresolved due to the long run times of the model meaning they weren’t all run in sequence at the end.\nReflections:\n\nReduce model run time if possible as it makes it easier to work with, and facilitates doing full re-runs of all scenarios (which can be important with code changes, etc).\n\nRelatedly, it is good practice to re-run all scripts before finishing up, as then you can spot any errors like the one mentioned for Kim et al. (2021)\n\nCommon issue (to varying degrees - i.e. taking 20 minutes, up to taking several hours).\n\n\n\n\n\n\n\n\n\n\nFor slow models, state the expected run time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n🟡\n❌\n❌\n❌\nN/A\n\n\n\n\nShoaib and Ramamohan (2021): Partially met. Run time stated in paper but not repository.\nHuang et al. (2019): Not met.\nLim et al. (2020): Not met.\nKim et al. (2021): Not met. A prior paper describing the model development mentions the run time, but not the current paper or repository.\nAnagnostou et al. (2022): Not applicable. Very quick! Seconds! So not particularly relevant - although, you could argue, potentially still important if there were some error that made it look like the model were running continuously (e.g. stuck in a loop) - although this is relatively unlikely.\nJohnson et al. (2021): \nReflections:\n\nFor long models with no statement, it can take a while to realise that it’s not an error in the code or anything, but actually just a long run time! And hard to know how long to expect, and whether it is without the capacities of your machine and so on.\nCommon issue.\n\n\n\n\n\n\n\n\n\n\nFor computationally expensive models, state memory usage and provide alternatives for lower spec machines\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\nN/A\nN/A\nN/A\n❌\nN/A\n\n\n\n\nShoaib and Ramamohan (2021), Huang et al. (2019), and Lim et al. (2020): Not applicable. Didn’t find it to be too computationally expensive for my machine.\nKim et al. (2021): Not met. Unable to run on my machine (serial took too long to run (would have to leave laptop on for many many hours which isn’t feasible), and parallel was too computationally expensive and crashed the machine (with the original number of people)). This is not mentioned in the repository or paper, but only referred to in a prior publication. Would’ve been handy if it included suggestions like reducing number of people and so on (which is what I had to do to feasibly run it).\nAnagnostou et al. (2022): Not applicable. Runs in seconds.\nReflections:\n\nSome models are so computationally expensive that it may be simply impossible to run it a feasible length of time without a high powered machine.\nIf a model is computationally expensive, it would be good to provide suggested alternatives that allow it to be run on lower spec machines\nNot a common problem - only relevant to computationally expensive models",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reflections from reproductions</span>"
    ]
  },
  {
    "objectID": "pages/reflections.html#parameters-scenarios-and-outputs",
    "href": "pages/reflections.html#parameters-scenarios-and-outputs",
    "title": "5  Reflections from reproductions",
    "section": "5.4 Parameters, scenarios and outputs",
    "text": "5.4 Parameters, scenarios and outputs\n\n\n\n\n\n\nProvide code for all scenarios\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n❌\n❌\n❌\nN/A\n\n\n\n\nShoaib and Ramamohan (2021): Not met. There were several instances where it took quite a while to understand how and where to modify the code in order to run scenarios (e.g. no arrivals, transferring admin work, reducing doctor intervention in deliveries).\nHuang et al. (2019): Not met. Set up a notebook to programmatically run the model scenarios. It took alot of work to modify and write code that could run the scenarios, and I often made mistakes in my interpretation for the implementation of scenarios, which could be avoided if code for those scenarios was provided.\nLim et al. (2020): Not met. Several parameters or scenarios were not incorporated in the code, and had to be added (e.g. with conditional logic to skip or change code run, removing hard-coding, adding parameters to existing).\nKim et al. (2021): Not met. Took alot of work to change model from for loop to function, to set all parameters as inputs (some were hard coded), and add conditional logic of scenarios when required.\nAnagnostou et al. (2022): Not applicable. No scenarios.\nJohnson et al. (2021): \nReflections:\n\nCommon issue\nTime consuming and tricky to resolve\n\n\n\n\n\n\n\n\n\n\nAll the required outputs are calculated/provided\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n❌\n❌\n❌\n✅\n\n\n\n\nShoaib and Ramamohan (2021): Not met. Had to add some outputs and calculations (e.g. proportion of childbirth cases referred, standard deviation)\nHuang et al. (2019): Not met. It has a complicated output (standardised density of patient in queue) that I was never certain on whether I correctly calculated. Although it outputs the columns required to calculate it, due its complexity, I feel this was not met, as it feels like a whole new output in its own right (and not just something simple like a mean).\nLim et al. (2020): Not met. The model script provided was only set up to provide results from days 7, 14 and 21. The figures require daily results, so I needed to modify the code to output that.\nKim et al. (2021): Not met. Had to write code to find aorta sizes of people with AAA-related deaths.\nAnagnostou et al. (2022): Fully met. Although worth noting this only had one scenario/version of model and one output to reproduce.\nJohnson et al. (2021): \nReflections:\n\nCalculate and provide all the outputs required\nAppreicate this can be a bit “ambiguous” (e.g. if its just plotting a mean or simple calculation, then didn’t consider that here) (however, combined with other criteria, we do want them to provide code to calculate outputs, so we would want them to provide that anyway)\n\n\n\n\n\n\n\n\n\n\nInclude correct parameters in the script (even if just for one scenario)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n🟡\n❌\n🟡\n✅\n✅\n\n\n\n\nShoaib and Ramamohan (2021): Partially met. Script is set with parameters for base configuration 1, with the exception of number of replications.\nHuang et al. (2019): Not met. The baseline model in the script did not match the baseline model (or any scenario) in the paper, so had to modify parameters.\nLim et al. (2020): Partially met. The included parameters were corrected, but the baseline scenario included varying staff strength to 2, and the provided code only varied 4 and 6. I had to add some code that enabled it to run with staff strength 2 (as there were an error that occured if you tried to set that).\nKim et al. (2021): Fully met.\nAnagnostou et al. (2022): Fully met.\nJohnson et al. (2021): \nReflections:\n\nAt least provide a script that can run the baseline model as in the paper (even if not providing the scenarios)\nThis can introduce difficulties - when some parameters are wrong, you rely on the paper to check which parameters are correct or not, but if the paper doesn’t mention every single parameter (which is reasonably likely, as this includes those not varied by scenarios), then you aren’t able to be sure that the model you are running is correct.\n\n\n\n\n\n\n\n\n\n\nProvide all the required parameters\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n❌\n❌\n✅\n✅\n\n\n\n\nShoaib and Ramamohan (2021): Some parameters that could not be calculated were not provided - ie. what consultation boundaries to use when mean length of doctor consultation was 2.5 minutes\nHuang et al. (2019): Not met. In this case, patient arrivals and resource numbers were listed in the paper, and there were several discprepancies between this and the provided code. However, for many of the model parameters like length of appointment, these were not mentioned in the paper, and so it was not possible to confirm whether or not those were correct. Hence, marked as not met, as the presence of discrepenancies for several other parameters puts these into doubt.\nLim et al. (2020): Not met. For Figure 5, had to guess the value for staff_per_shift.\nKim et al. (2021): Fully met.\nAnagnostou et al. (2022): Fully met.\nJohnson et al. (2021): \nReflections:\n\nProvide all required parameters\n\n\n\n\n\n\n\n\n\n\nIf not provided in the script, then clearly present all parameters in the paper\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n❌\n🟡\nN/A\nN/A\n\n\n\n\nShoaib and Ramamohan (2021): Not met. Although there was a scenario table, this did not include all the parameters I would need to change. It was more challenging to identify parameters that were only described in the body of the article. There were also some discrepancies in parameters between the main text of the article, and the tables and figures. Some scenarios were quite ambiguous/unclear from their description in the text, and I initially misunderstood the required parameters for the scenarios.\nHuang et al. (2019): Not met. As described above, paper didn’t adequately describe all parameters.\nLim et al. (2020): Partially met. Nearly all parameters are in the paper table, and others are described in the article. However, didn’t provide information for the staff_per_shift for Figure 5.\nKim et al. (2021) and Anagnostou et al. (2022): Not applicable. All provided.\nJohnson et al. (2021): \nReflections:\n\nProvide parameters in a table (including for each scenario), as it can be difficult/ambiguous to interpret them from the text, and hard to spot them too.\nBe sure to mention every parameter that gets changed (e.g. for Lim et al. (2020), as there wasn’t a default staff_per_shift across all scenarios, but not stated for the scenario, had to guess it).\n\n\n\n\n\n\n\n\n\n\nIf will need to process parameters, provide required calculations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n✅\nN/A\nN/A\nN/A\n\n\n\n\nShoaib and Ramamohan (2021): Not met. It was unclear how to estimate inter-arrival time.\nHuang et al. (2019): Fully met. The calculations for inter-arrival times were provided in the code, and the inputs to the code were the number of arrivals, as reported in the paper, and so making it easy to compare those parameters and check if numbers were correct or not.\nLim et al. (2020): Not applicable. The parameter not provided is not one that you would calculate.\nKim et al. (2021) and Anagnostou et al. (2022): Not applicable. All provided.\nJohnson et al. (2021): \nReflections:\n\nIf you are going to be mentioning the “pre-processed” values at all, then its important to include the calculation (ideally in the code, as that is the clearest demonstration of exactly what you did)",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reflections from reproductions</span>"
    ]
  },
  {
    "objectID": "pages/reflections.html#output-format",
    "href": "pages/reflections.html#output-format",
    "title": "5  Reflections from reproductions",
    "section": "5.5 Output format",
    "text": "5.5 Output format\n\n\n\n\n\n\nSaves output to a file\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n✅\n❌\n❌\n❌\n✅\n\n\n\n\nShoaib and Ramamohan (2021): Fully met. Outputs to .xlsx files\nHuang et al. (2019), Lim et al. (2020), and Kim et al. (2021): Not met. Outputs to dataframe/s.\nAnagnostou et al. (2022): Outputs to OUT_STATS.csv. Note: Although not needed for the reproduction itself, when I tried to amend the name and location of the csv file output the model for use in tests, this was very tricky to do as it was hard coded into the scripts and I found difficult to amend due to how the model is run and set up.\nJohnson et al. (2021): \nReflections:\n\nCommon issue\nParticularly important if model run time is even slightly long (even just minutes long, but even more so as becomes many minutes / hours), so don’t always have to re-run it each time to get results\nSet up this in such a way that it is easy to change the name and location of the output file.\n\n\n\n\n\n\n\n\n\n\nUnderstandable output tables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n✅\n✅\n❌\n✅\n\n\n\n\nShoaib and Ramamohan (2021): Not met. There were two alternative results spreadsheets with some duplicate metrics but sometimes differing results between them, which made it a bit confusing to work out what to use.\nHuang et al. (2019), Lim et al. (2020), and Anagnostou et al. (2022): Fully met. Didn’t experience issues interpreting the contents of the output table/s.\nKim et al. (2021): Not met. It took me a little while to work out what surgery columns I needed, and to realise I needed to combine two of them. This required looking at what inputs genreated this, and referring to a input data dictionary.\nJohnson et al. (2021): \nReflections:\n\nDon’t provide alternative results for the same metrics\nMake it clear what each colum/category in the results table means, if it might not be immediately clear.",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reflections from reproductions</span>"
    ]
  },
  {
    "objectID": "pages/reflections.html#seeds",
    "href": "pages/reflections.html#seeds",
    "title": "5  Reflections from reproductions",
    "section": "5.6 Seeds",
    "text": "5.6 Seeds\n\n\n\n\n\n\nUse seeds to control stochasticity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n❌\n❌\n✅\n✅\n\n\n\n\nShoaib and Ramamohan (2021): Not met. The lack of seeds wasn’t actually a barrier to the reproduction though due to the replication number. I later add seeds so my results could be reproduced, and found that the ease of setting seeds with salabim was a greater facilitator to the work. I only had to change one or two lines of code to then get consistent results between runs (unlike other simulation software like SimPy where you have to consider the use of seeds by different sampling functions). Moreover, by default, salabim would have set a seed (although overridden by original authors to enable them to run replications).\nHuang et al. (2019): Not met. It would have been beneficial to include seeds, as there was a fair amount of variability, so with seeds I could then I could be sure that my results do not differ from the original simply due to randomness.\nLim et al. (2020): Not met. The results obtained looked very similar to the original article, with minimal differences that I felt to be within the expected variation from the model stochasticity. However, if seeds had been present, we would have been able to say with certainty. I did not feel I needed to add seeds during the reproduction to get the same results.\nKim et al. (2021): Fully met. Included a seed, although I don’t get identical results as I had to reduce number of people in simulation.\nAnagnostou et al. (2022): Fully met. The authors included a random seed so the results I got were identical to the original (so no need for any subjectivity in deciding whether its similar enough, as I could perfectly reproduce).\nJohnson et al. (2021): \nReflections:\n\nDepending on your model and the outputs/type of output you are looking at, the lack of seeds can have varying impacts on the appearance of your results, and can make the subjective judgement of whether results are consistent harder (if discrepancies could be attributed to not having consistent seeds or not).\nIt can be really quite simple to include seeds.",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reflections from reproductions</span>"
    ]
  },
  {
    "objectID": "pages/reflections.html#code-to-produce-article-results",
    "href": "pages/reflections.html#code-to-produce-article-results",
    "title": "5  Reflections from reproductions",
    "section": "5.7 Code to produce article results",
    "text": "5.7 Code to produce article results\n\n\n\n\n\n\nProvide code to process results into tables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\nN/A\n🟡\n❌\nN/A\n\n\n\n\n\nShoaib and Ramamohan (2021): Not met.\nHuang et al. (2019): Not applicable. No tables in scope.\nLim et al. (2020): Partially met. It outputs the results in a similar structure to the paper (like a section of a table). However, it doesn’t have the full code to produce a table outright, for any of the tables, so additional processing still required.\nKim et al. (2021): Not met. Had to write code to generate tables, which included correctly implementing calculation of excess e.g. deaths, scaling to population size, and identify which columns provide the operation outcomes.\nAnagnostou et al. (2022): Not applicable. No tables in scope.\nJohnson et al. (2021): \nReflections:\n\nIt can take a bit of time to do this processing, so very handy for it to be provided.\nCommon issue.\n\n\n\n\n\n\n\n\n\n\nProvide code to process results into figures\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n❌\n❌\n❌\n❌\n\n\n\n\nShoaib and Ramamohan (2021): Not met.\nHuang et al. (2019): Not met. Had to write code from scratch. For one of the figures, it would have been handy if informed that plot was produced by a simmer function (as didn’t initially realise this). It also took a bit of time for me to work out how to transform the figure axes as this was not mentioned in the paper (and no code was provided for these). It was also unclear and a bit tricky to work out how to standardise the density in the figures (since it is only described in the text and no formula/calculations are provided there or in the code). \nLim et al. (2020), Kim et al. (2021) and Anagnostou et al. (2022): Not met. However, the simplicity and repetition of the figures was handy.\nJohnson et al. (2021): \nReflections:\n\nIt can take a bit of time to do this processing, particularly if the figure involves any transformations (and less so if the figure is simple), so very handy for it to be provided.\nCommon issue.\n\n\n\n\n\n\n\n\n\n\nProvide code to calculate in-text results\n\n\n\n\n\nBy “in-text results”, I am referred to results that are mentioned in the text but not included in/cannot be deduced from any of the tables or figures.\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n❌\nN/A\n❌\nN/A\n\n\n\n\nShoaib and Ramamohan (2021), Huang et al. (2019), Kim et al. (2021): Not met.\nLim et al. (2020), Anagnostou et al. (2022): Not applicable (no in-text results).\nJohnson et al. (2021): \nReflections:\n\nProvide code to calculate in-text results\nCommon issue",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reflections from reproductions</span>"
    ]
  },
  {
    "objectID": "pages/reflections.html#documentation",
    "href": "pages/reflections.html#documentation",
    "title": "5  Reflections from reproductions",
    "section": "5.8 Documentation",
    "text": "5.8 Documentation\n\n\n\n\n\n\nInclude instructions on how to run the model/script\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShoaib and Ramamohan (2021)\nHuang et al. (2019)\nLim et al. (2020)\nKim et al. (2021)\nAnagnostou et al. (2022)\nJohnson et al. (2021)\n\n\n\n\n❌\n❌\n❌\n🟡\n✅\n\n\n\n\nShoaib and Ramamohan (2021): Not met. No instructions, although is just a single script that you run.\nHuang et al. (2019): Not met. Not provided in runnable form but, regardless, no instructions for running it as it is provided (as a web application - i.e. no info on how to get that running).\nLim et al. (2020): Not met. No instructions, although is just a single script that you run.\nKim et al. (2021): Partially met. README tells you which folder has the scripts you need, although nothing further. Although all you need to do is run them.\nAnagnostou et al. (2022): Fully met. Clear README with instructions on how to run the model was really helpful.\nReflections:\n\nEven if as simple as running a script, include instructions on how to do so\nCommon issue",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reflections from reproductions</span>"
    ]
  },
  {
    "objectID": "pages/reflections.html#other",
    "href": "pages/reflections.html#other",
    "title": "5  Reflections from reproductions",
    "section": "5.9 Other",
    "text": "5.9 Other\nInclude tick marks/grid lines on figures, so it is easier to read across and judge whether a result is above or below a certain Y value.\nAnagnostou et al. (2022): Included data dictionary for input parameters. Although I didn’t need this, this would have been great if I needed to change the input parameters at all.\nReflections:\n\nInclude grid lines\nInclude data dictionaries",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reflections from reproductions</span>"
    ]
  },
  {
    "objectID": "pages/reflections.html#references",
    "href": "pages/reflections.html#references",
    "title": "5  Reflections from reproductions",
    "section": "5.10 References",
    "text": "5.10 References\n\n\n\n\nAnagnostou, Anastasia, Derek Groen, Simon J. E. Taylor, Diana Suleimenova, Nura Abubakar, Arindam Saha, Kate Mintram, et al. 2022. “FACS-CHARM: A Hybrid Agent-Based and Discrete-Event Simulation Approach for Covid-19 Management at Regional Level.” In 2022 Winter Simulation Conference (WSC), 1223–34. https://doi.org/10.1109/WSC57314.2022.10015462.\n\n\nHuang, Shiwei, Julian Maingard, Hong Kuan Kok, Christen D. Barras, Vincent Thijs, Ronil V. Chandra, Duncan Mark Brooks, and Hamed Asadi. 2019. “Optimizing Resources for Endovascular Clot Retrieval for Acute Ischemic Stroke, a Discrete Event Simulation.” Frontiers in Neurology 10 (June). https://doi.org/10.3389/fneur.2019.00653.\n\n\nJohnson, Kate M., Mohsen Sadatsafavi, Amin Adibi, Larry Lynd, Mark Harrison, Hamid Tavakoli, Don D. Sin, and Stirling Bryan. 2021. “Cost Effectiveness of Case Detection Strategies for the Early Detection of COPD.” Applied Health Economics and Health Policy 19 (2): 203–15. https://doi.org/10.1007/s40258-020-00616-2.\n\n\nKim, Lois G., Michael J. Sweeting, Morag Armer, Jo Jacomelli, Akhtar Nasim, and Seamus C. Harrison. 2021. “Modelling the Impact of Changes to Abdominal Aortic Aneurysm Screening and Treatment Services in England During the COVID-19 Pandemic.” PLOS ONE 16 (6): e0253327. https://doi.org/10.1371/journal.pone.0253327.\n\n\nLim, Chun Yee, Mary Kathryn Bohn, Giuseppe Lippi, Maurizio Ferrari, Tze Ping Loh, Kwok-Yung Yuen, Khosrow Adeli, and Andrea Rita Horvath. 2020. “Staff Rostering, Split Team Arrangement, Social Distancing (Physical Distancing) and Use of Personal Protective Equipment to Minimize Risk of Workplace Transmission During the COVID-19 Pandemic: A Simulation Study.” Clinical Biochemistry 86 (December): 15–22. https://doi.org/10.1016/j.clinbiochem.2020.09.003.\n\n\nShoaib, Mohd, and Varun Ramamohan. 2021. “Simulation Modelling and Analysis of Primary Health Centre Operations.” arXiv, June. https://doi.org/10.48550/arXiv.2104.12492.",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reflections from reproductions</span>"
    ]
  },
  {
    "objectID": "pages/repo_evaluation.html",
    "href": "pages/repo_evaluation.html",
    "title": "6  Evaluation of the repository",
    "section": "",
    "text": "6.1 Summary\nUnique badge criteria:\nBadges:\nEssential components of STARS framework:\nOptional components of STARS framework:",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Evaluation of the repository</span>"
    ]
  },
  {
    "objectID": "pages/repo_evaluation.html#journal-badges",
    "href": "pages/repo_evaluation.html#journal-badges",
    "title": "6  Evaluation of the repository",
    "section": "6.2 Journal badges",
    "text": "6.2 Journal badges\nKey:\n\nS: Shoaib and Ramamohan (2021) - link to evaluation\nH: Huang et al. (2019) - link to evaluation\nL: Lim et al. (2020) - link to evaluation\nK: Kim et al. (2021) - link to evaluation\nA: Anagnostou et al. (2022) - link to evaluation\nJ: Johnson et al. (2021) - link to evaluation\n\n\nIn this section and below, the criteria for each study are marked as either being fully met (✅), partially met (🟡), not met (❌) or not applicable (N/A).\nUnique criteria:\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem\nS\nH\nL\nK\nA\nJ\n\n\n\n\n\nCriteria related to how artefacts are shared\n\n\n\n\n\n\n\n\n\nStored in a permanent archive that is publicly and openly accessible\n❌\n❌\n❌\n❌\n✅\n\n\n\n\nHas a persistent identifier\n❌\n❌\n❌\n❌\n✅\n\n\n\n\nIncludes an open license\n❌\n✅\n❌\n✅\n✅\n\n\n\n\nCriteria related to what artefacts are shared\n\n\n\n\n\n\n\n\n\nArtefacts are relevant to and contribute to the article’s results\n✅\n✅\n✅\n✅\n✅\n\n\n\n\nComplete set of materials shared (as would be needed to fully reproduce article)\n❌\n❌\n❌\n❌\n❌\n\n\n\n\nCriteria related to the structure and documentation of the artefacts\n\n\n\n\n\n\n\n\n\nArtefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n❌\n❌\n❌\n✅\n✅\n\n\n\n\nArtefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n❌\n❌\n❌\n❌\n✅\n\n\n\n\nArtefacts are carefully documented (more than sufficient - i.e. to the extent that reuse and repurposing is facilitated - e.g. changing parameters, reusing for own purpose)\n❌\n❌\n❌\n❌\n✅\n\n\n\n\nArtefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript\n❌\n❌\n❌\n❌\n✅\n\n\n\n\nCriteria related to running and reproducing results\n\n\n\n\n\n\n\n\n\nScripts can be successfully executed\n✅\n✅\n✅\n✅\n✅\n\n\n\n\nIndependent party regenerated results using the authors research artefacts\n✅\n❌\n✅\n✅\n✅\n\n\n\n\nReproduced within approximately one hour (excluding compute time)\n❌\n❌\n❌\n❌\n❌\n❌\n\n\n\n\n \nBadges:\nThe badges are grouped into three categories:\n\n“Open objects” badges: These badges relate to research artefacts being made openly available.\n“Object review” badges: These badges relate to the research artefacts being reviewed against criteria of the badge issuer.\n“Reproduced” badges: These badges relate to an independent party regenerating the reuslts of the article using the author objects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem\nS\nH\nL\nK\nA\nJ\n\n\n\n\n\n“Open objects” badges\n\n\n\n\n\n\n\n\n\nNISO “Open Research Objects (ORO)”• Stored in a permanent archive that is publicly and openly accessible• Has a persistent identifier• Includes an open license\n❌\n❌\n❌\n❌\n✅\n\n\n\n\nNISO “Open Research Objects - All (ORO-A)”• Stored in a permanent archive that is publicly and openly accessible• Has a persistent identifier• Includes an open license• Complete set of materials shared (as would be needed to fully reproduce article)\n❌\n❌\n❌\n❌\n❌\n\n\n\n\nACM “Artifacts Available”• Stored in a permanent archive that is publicly and openly accessible• Has a persistent identifier\n❌\n❌\n❌\n❌\n✅\n\n\n\n\nCOS “Open Code”• Stored in a permanent archive that is publicly and openly accessible• Has a persistent identifier• Includes an open license• Complete set of materials shared (as would be needed to fully reproduce article)• Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n❌\n❌\n❌\n❌\n❌\n\n\n\n\nIEEE “Code Available”• Complete set of materials shared (as would be needed to fully reproduce article)\n❌\n❌\n❌\n❌\n❌\n\n\n\n\n“Object review” badges\n\n\n\n\n\n\n\n\n\nACM “Artifacts Evaluated - Functional”• Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)• Artefacts are relevant to and contribute to the article’s results• Complete set of materials shared (as would be needed to fully reproduce article)• Scripts can be successfully executed\n❌\n❌\n❌\n❌\n❌\n\n\n\n\nACM “Artifacts Evaluated - Reusable”• Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)• Artefacts are carefully documented (more than sufficient - i.e. to the extent that reuse and repurposing is facilitated - e.g. changing parameters, reusing for own purpose)• Artefacts are relevant to and contribute to the article’s results• Complete set of materials shared (as would be needed to fully reproduce article)• Scripts can be successfully executed• Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n❌\n❌\n❌\n❌\n❌\n\n\n\n\nIEEE “Code Reviewed”• Complete set of materials shared (as would be needed to fully reproduce article)• Scripts can be successfully executed\n❌\n❌\n❌\n❌\n❌\n\n\n\n\n“Reproduced” badges\n\n\n\n\n\n\n\n\n\nNISO “Results Reproduced (ROR-R)”• Independent party regenerated results using the authors research artefacts\n✅\n❌\n✅\n✅\n✅\n\n\n\n\nACM “Results Reproduced”• Independent party regenerated results using the authors research artefacts\n✅\n❌\n✅\n✅\n✅\n\n\n\n\nIEEE “Code Reproducible”• Independent party regenerated results using the authors research artefacts\n✅\n❌\n✅\n✅\n✅\n\n\n\n\nPsychological Science “Computational Reproducibility”• Independent party regenerated results using the authors research artefacts• Reproduced within approximately one hour (excluding compute time)• Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)• Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript\n❌\n❌\n❌\n❌\n❌",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Evaluation of the repository</span>"
    ]
  },
  {
    "objectID": "pages/repo_evaluation.html#stars-framework",
    "href": "pages/repo_evaluation.html#stars-framework",
    "title": "6  Evaluation of the repository",
    "section": "6.3 STARS framework",
    "text": "6.3 STARS framework\nKey:\n\nS: Shoaib and Ramamohan (2021) - link to evaluation\nH: Huang et al. (2019) - link to evaluation\nL: Lim et al. (2020) - link to evaluation\nK: Kim et al. (2021) - link to evaluation\nA: Anagnostou et al. (2022) - link to evaluation\nJ: Johnson et al. (2021) - link to evaluation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem\nS\nH\nL\nK\nA\nJ\n\n\n\n\n\nEssential components\n\n\n\n\n\n\n\n\n\nOpen licenseFree and open-source software (FOSS) license (e.g. MIT, GNU Public License (GPL))\n❌\n✅\n❌\n✅\n✅\n\n\n\n\nDependency managementSpecify software libraries, version numbers and sources (e.g. dependency management tools like virtualenv, conda, poetry)\n❌\n❌\n❌\n🟡\n✅\n\n\n\n\nFOSS modelCoded in FOSS language (e.g. R, Julia, Python)\n✅\n✅\n✅\n✅\n✅\n✅\n\n\n\nMinimum documentationMinimal instructions (e.g. in README) that overview (a) what model does, (b) how to install and run model to obtain results, and (c) how to vary parameters to run new experiments\n❌\n❌\n❌\n✅\n✅\n\n\n\n\nORCIDORCID for each study author\n❌\n❌\n❌\n❌\n❌\n\n\n\n\nCitation informationInstructions on how to cite the research artefact (e.g. CITATION.cff file)\n❌\n❌\n❌\n❌\n✅\n\n\n\n\nRemote code repositoryCode available in a remote code repository (e.g. GitHub, GitLab, BitBucket)\n✅\n✅\n✅\n✅\n✅\n\n\n\n\nOpen science archiveCode stored in an open science archive with FORCE11 compliant citation and guaranteed persistance of digital artefacts (e.g. Figshare, Zenodo, the Open Science Framework (OSF), and the Computational Modeling in the Social and Ecological Sciences Network (CoMSES Net))\n❌\n❌\n❌\n❌\n✅\n\n\n\n\nOptional components\n\n\n\n\n\n\n\n\n\nEnhanced documentationOpen and high quality documentation on how the model is implemented and works (e.g. via notebooks and markdown files, brought together using software like Quarto and Jupyter Book). Suggested content includes:• Plain english summary of project and model• Clarifying license• Citation instructions• Contribution instructions• Model installation instructions• Structured code walk through of model• Documentation of modelling cycle using TRACE• Annotated simulation reporting guidelines• Clear description of model validation including its intended purpose\n❌\n❌\n❌\n❌\n❌\n\n\n\n\nDocumentation hostingHost documentation (e.g. with GitHub pages, GitLab pages, BitBucket Cloud, Quarto Pub)\n❌\n❌\n❌\n❌\n❌\n\n\n\n\nOnline coding environmentProvide an online environment where users can run and change code (e.g. BinderHub, Google Colaboratory, Deepnote)\n❌\n❌\n❌\n❌\n❌\n\n\n\n\nModel interfaceProvide web application interface to the model so it is accessible to less technical simulation users\n❌\n✅\n❌\n❌\n✅\n\n\n\n\nWeb app hostingHost web app online (e.g. Streamlit Community Cloud, ShinyApps hosting)\n❌\n✅\n❌\n❌\n🟡",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Evaluation of the repository</span>"
    ]
  },
  {
    "objectID": "pages/repo_evaluation.html#timings",
    "href": "pages/repo_evaluation.html#timings",
    "title": "6  Evaluation of the repository",
    "section": "6.4 Timings",
    "text": "6.4 Timings\n\n\nShoaib and Ramamohan (2021) - 30m\nHuang et al. (2019) - 17m\nLim et al. (2020) - 18m\nKim et al. (2021)\nAnagnostou et al. (2022) - 19m\nJohnson et al. (2021)",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Evaluation of the repository</span>"
    ]
  },
  {
    "objectID": "pages/repo_evaluation.html#badge-sources",
    "href": "pages/repo_evaluation.html#badge-sources",
    "title": "6  Evaluation of the repository",
    "section": "6.5 Badge sources",
    "text": "6.5 Badge sources\nNational Information Standards Organisation (NISO) (NISO Reproducibility Badging and Definitions Working Group (2021))\n\n“Open Research Objects (ORO)”\n“Open Research Objects - All (ORO-A)”\n“Results Reproduced (ROR-R)”\n\nAssociation for Computing Machinery (ACM) (Association for Computing Machinery (ACM) (2020))\n\n“Artifacts Available”\n“Artifacts Evaluated - Functional”\n“Artifacts Evaluated - Resuable”\n“Results Reproduced”\n\nCenter for Open Science (COS) (Blohowiak et al. (2023))\n\n“Open Code”\n\nInstitute of Electrical and Electronics Engineers (IEEE) (Institute of Electrical and Electronics Engineers (IEEE) (n.d.))\n\n“Code Available”\n“Code Reviewed”\n“Code Reproducible”\n\nPsychological Science (Hardwicke and Vazire (2023) and Association for Psychological Science (APS) (2023))\n\n“Computational Reproducibility”",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Evaluation of the repository</span>"
    ]
  },
  {
    "objectID": "pages/repo_evaluation.html#references",
    "href": "pages/repo_evaluation.html#references",
    "title": "6  Evaluation of the repository",
    "section": "6.6 References",
    "text": "6.6 References\n\n\n\n\nAnagnostou, Anastasia, Derek Groen, Simon J. E. Taylor, Diana Suleimenova, Nura Abubakar, Arindam Saha, Kate Mintram, et al. 2022. “FACS-CHARM: A Hybrid Agent-Based and Discrete-Event Simulation Approach for Covid-19 Management at Regional Level.” In 2022 Winter Simulation Conference (WSC), 1223–34. https://doi.org/10.1109/WSC57314.2022.10015462.\n\n\nAssociation for Computing Machinery (ACM). 2020. “Artifact Review and Badging Version 1.1.” ACM. https://www.acm.org/publications/policies/artifact-review-and-badging-current.\n\n\nAssociation for Psychological Science (APS). 2023. “Psychological Science Submission Guidelines.” APS. https://www.psychologicalscience.org/publications/psychological_science/ps-submissions.\n\n\nBlohowiak, Ben B., Johanna Cohoon, Lee de-Wit, Eric Eich, Frank J. Farach, Fred Hasselman, Alex O. Holcombe, Macartan Humphreys, Melissa Lewis, and Brian A. Nosek. 2023. “Badges to Acknowledge Open Practices.” https://osf.io/tvyxz/.\n\n\nHardwicke, Tom E., and Simine Vazire. 2023. “Transparency Is Now the Default at Psychological Science.” Psychological Science 0 (0). https://doi.org/https://doi.org/10.1177/09567976231221573.\n\n\nHuang, Shiwei, Julian Maingard, Hong Kuan Kok, Christen D. Barras, Vincent Thijs, Ronil V. Chandra, Duncan Mark Brooks, and Hamed Asadi. 2019. “Optimizing Resources for Endovascular Clot Retrieval for Acute Ischemic Stroke, a Discrete Event Simulation.” Frontiers in Neurology 10 (June). https://doi.org/10.3389/fneur.2019.00653.\n\n\nInstitute of Electrical and Electronics Engineers (IEEE). n.d. “About Content in IEEE Xplore.” IEEE Explore. Accessed May 20, 2024. https://ieeexplore.ieee.org/Xplorehelp/overview-of-ieee-xplore/about-content.\n\n\nJohnson, Kate M., Mohsen Sadatsafavi, Amin Adibi, Larry Lynd, Mark Harrison, Hamid Tavakoli, Don D. Sin, and Stirling Bryan. 2021. “Cost Effectiveness of Case Detection Strategies for the Early Detection of COPD.” Applied Health Economics and Health Policy 19 (2): 203–15. https://doi.org/10.1007/s40258-020-00616-2.\n\n\nKim, Lois G., Michael J. Sweeting, Morag Armer, Jo Jacomelli, Akhtar Nasim, and Seamus C. Harrison. 2021. “Modelling the Impact of Changes to Abdominal Aortic Aneurysm Screening and Treatment Services in England During the COVID-19 Pandemic.” PLOS ONE 16 (6): e0253327. https://doi.org/10.1371/journal.pone.0253327.\n\n\nLim, Chun Yee, Mary Kathryn Bohn, Giuseppe Lippi, Maurizio Ferrari, Tze Ping Loh, Kwok-Yung Yuen, Khosrow Adeli, and Andrea Rita Horvath. 2020. “Staff Rostering, Split Team Arrangement, Social Distancing (Physical Distancing) and Use of Personal Protective Equipment to Minimize Risk of Workplace Transmission During the COVID-19 Pandemic: A Simulation Study.” Clinical Biochemistry 86 (December): 15–22. https://doi.org/10.1016/j.clinbiochem.2020.09.003.\n\n\nMonks, Thomas, Alison Harper, and Navonil Mustafee. 2024. “Towards Sharing Tools and Artefacts for Reusable Simulations in Healthcare.” Journal of Simulation 0 (0): 1–20. https://doi.org/10.1080/17477778.2024.2347882.\n\n\nNISO Reproducibility Badging and Definitions Working Group. 2021. “Reproducibility Badging and Definitions.” https://doi.org/10.3789/niso-rp-31-2021.\n\n\nShoaib, Mohd, and Varun Ramamohan. 2021. “Simulation Modelling and Analysis of Primary Health Centre Operations.” arXiv, June. https://doi.org/10.48550/arXiv.2104.12492.",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Evaluation of the repository</span>"
    ]
  },
  {
    "objectID": "pages/paper_evaluation.html",
    "href": "pages/paper_evaluation.html",
    "title": "7  Evaluation of the article",
    "section": "",
    "text": "7.1 Summary\nSTRESS-DES:\nDES checklist derived from ISPOR-SDM:",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Evaluation of the article</span>"
    ]
  },
  {
    "objectID": "pages/paper_evaluation.html#stress-des",
    "href": "pages/paper_evaluation.html#stress-des",
    "title": "7  Evaluation of the article",
    "section": "7.2 STRESS-DES",
    "text": "7.2 STRESS-DES\n\nKey:\n\nS: Shoaib and Ramamohan (2021) - link to evaluation\nH: Huang et al. (2019) - link to evaluation\nL: Lim et al. (2020) - link to evaluation\nK: Kim et al. (2021) - link to evaluation\nA: Anagnostou et al. (2022) - link to evaluation\nJ: Johnson et al. (2021) - link to evaluation\n\nIn this section and below, the criteria for each study are marked as either being fully met (✅), partially met (🟡), not met (❌) or not applicable (N/A).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem\nS\nH\nL\nK\nA\nJ\n\n\n\n\n\nObjectives\n\n\n\n\n\n\n\n\n\n1.1 Purpose of the modelExplain the background and objectives for the model\n✅\n✅\n✅\n✅\n✅\n\n\n\n\n1.2 Model outputsDefine all quantitative performance measures that are reported, using equations where necessary. Specify how and when they are calculated during the model run along with how any measures of error such as confidence intervals are calculated.\n🟡\n✅\n✅\n✅\n✅\n\n\n\n\n1.3 Experimentation aimsIf the model has been used for experimentation, state the objectives that it was used to investigate.(A) Scenario based analysis – Provide a name and description for each scenario, providing a rationale for the choice of scenarios and ensure that item 2.3 (below) is completed.(B) Design of experiments – Provide details of the overall design of the experiments with reference to performance measures and their parameters (provide further details in data below).(C) Simulation Optimisation – (if appropriate) Provide full details of what is to be optimised, the parameters that were included and the algorithm(s) that was be used. Where possible provide a citation of the algorithm(s).\n✅\n✅\n✅\n✅\nN/A\n\n\n\n\nLogic\n\n\n\n\n\n\n\n\n\n2.1 Base model overview diagramDescribe the base model using appropriate diagrams and description. This could include one or more process flow, activity cycle or equivalent diagrams sufficient to describe the model to readers. Avoid complicated diagrams in the main text. The goal is to describe the breadth and depth of the model with respect to the system being studied.\n✅\n✅\n✅\ntbc\n✅\n\n\n\n\n2.2 Base model logicGive details of the base model logic. Give additional model logic details sufficient to communicate to the reader how the model works.\n✅\n✅\n✅\ntbc\n✅\n\n\n\n\n2.3 Scenario logicGive details of the logical difference between the base case model and scenarios (if any). This could be incorporated as text or where differences are substantial could be incorporated in the same manner as 2.2.\n✅\n✅\n✅\n✅\nN/A\n\n\n\n\n2.4 AlgorithmsProvide further detail on any algorithms in the model that (for example) mimic complex or manual processes in the real world (i.e. scheduling of arrivals/ appointments/ operations/ maintenance, operation of a conveyor system, machine breakdowns, etc.). Sufficient detail should be included (or referred to in other published work) for the algorithms to be reproducible. Pseudo-code may be used to describe an algorithm.\n✅\n🟡\n✅\ntbc\n✅\n\n\n\n\n2.5.1 Components - entitiesGive details of all entities within the simulation including a description of their role in the model and a description of all their attributes.\n✅\n✅\n✅\n✅\n✅\n\n\n\n\n2.5.2 Components - activitiesDescribe the activities that entities engage in within the model. Provide details of entity routing into and out of the activity.\n✅\n✅\n✅\ntbc\n✅\n\n\n\n\n2.5.3 Components - resourcesList all the resources included within the model and which activities make use of them.\n✅\n✅\nN/A\ntbc\n✅\n\n\n\n\n2.5.4 Components - queuesGive details of the assumed queuing discipline used in the model (e.g. First in First Out, Last in First Out, prioritisation, etc.). Where one or more queues have a different discipline from the rest, provide a list of queues, indicating the queuing discipline used for each. If reneging, balking or jockeying occur, etc., provide details of the rules. Detail any delays or capacity constraints on the queues.\n✅\n✅\nN/A\ntbc\n✅\n\n\n\n\n2.5.5 Components - entry/exit pointsGive details of the model boundaries i.e. all arrival and exit points of entities. Detail the arrival mechanism (e.g. ‘thinning’ to mimic a non-homogenous Poisson process or balking)\n✅\n✅\n✅\n✅\n✅\n\n\n\n\nData\n\n\n\n\n\n\n\n\n\n3.1 Data sourcesList and detail all data sources. Sources may include:• Interviews with stakeholders,• Samples of routinely collected data,• Prospectively collected samples for the purpose of the simulation study,• Public domain data published in either academic or organisational literature. Provide, where possible, the link and DOI to the data or reference to published literature.All data source descriptions should include details of the sample size, sample date ranges and use within the study.\n✅\n✅\n✅\n✅\n✅\n\n\n\n\n3.2 Pre-processingProvide details of any data manipulation that has taken place before its use in the simulation, e.g. interpolation to account for missing data or the removal of outliers.\n✅\nN/A\nN/A\n✅\nN/A\n\n\n\n\n3.3 Input parametersList all input variables in the model. Provide a description of their use and include parameter values. For stochastic inputs provide details of any continuous, discrete or empirical distributions used along with all associated parameters. Give details of all time dependent parameters and correlation.Clearly state:• Base case data• Data use in experimentation, where different from the base case.• Where optimisation or design of experiments has been used, state the range of values that parameters can take.• Where theoretical distributions are used, state how these were selected and prioritised above other candidate distributions.\n🟡\n🟡\n✅\n🟡\n✅\n\n\n\n\n3.4 AssumptionsWhere data or knowledge of the real system is unavailable what assumptions are included in the model? This might include parameter values, distributions or routing logic within the model.\n✅\n❌\n✅\n✅\n❌\n\n\n\n\nExperimentation\n\n\n\n\n\n\n\n\n\n4.1 InitialisationReport if the system modelled is terminating or non-terminating. State if a warm-up period has been used, its length and the analysis method used to select it. For terminating systems state the stopping condition.State what if any initial model conditions have been included, e.g., pre-loaded queues and activities. Report whether initialisation of these variables is deterministic or stochastic.\n🟡\n❌\n❌\ntbc\n❌\n\n\n\n\n4.2 Run lengthDetail the run length of the simulation model and time units.\n✅\n✅\n✅\n✅\n🟡\n\n\n\n\n4.3 Estimation approachState the method used to account for the stochasticity: For example, two common methods are multiple replications or batch means. Where multiple replications have been used, state the number of replications and for batch means, indicate the batch length and whether the batch means procedure is standard, spaced or overlapping. For both procedures provide a justification for the methods used and the number of replications/size of batches.\n🟡\n🟡\n✅\n✅\n✅\n\n\n\n\nImplementation\n\n\n\n\n\n\n\n\n\n5.1 Software or programming languageState the operating system and version and build number.State the name, version and build number of commercial or open source DES software that the model is implemented in.State the name and version of general-purpose programming languages used (e.g. Python 3.5).Where frameworks and libraries have been used provide all details including version numbers.\n🟡\n🟡\n🟡\n🟡\n🟡\n\n\n\n\n5.2 Random samplingState the algorithm used to generate random samples in the software/programming language used e.g. Mersenne Twister.If common random numbers are used, state how seeds (or random number streams) are distributed among sampling processes.\n❌\n🟡\n❌\n❌\n❌\n\n\n\n\n5.3 Model executionState the event processing mechanism used e.g. three phase, event, activity, process interaction.Note that in some commercial software the event processing mechanism may not be published. In these cases authors should adhere to item 5.1 software recommendations.State all priority rules included if entities/activities compete for resources.If the model is parallel, distributed and/or use grid or cloud computing, etc., state and preferably reference the technology used. For parallel and distributed simulations the time management algorithms used. If the HLA is used then state the version of the standard, which run-time infrastructure (and version), and any supporting documents (FOMs, etc.)\n🟡\n❌\n❌\ntbc\n❌\n\n\n\n\n5.4 System specificationState the model run time and specification of hardware used. This is particularly important for large scale models that require substantial computing power. For parallel, distributed and/or use grid or cloud computing, etc. state the details of all systems used in the implementation (processors, network, etc.)\n✅\n❌\n🟡\ntbc\n❌\n\n\n\n\nCode access\n\n\n\n\n\n\n\n\n\n6.1 Computer model sharing statementDescribe how someone could obtain the model described in the paper, the simulation software and any other associated software (or hardware) needed to reproduce the results. Provide, where possible, the link and DOIs to these.\n✅\n✅\n✅\n✅\n✅",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Evaluation of the article</span>"
    ]
  },
  {
    "objectID": "pages/paper_evaluation.html#des-checklist-derived-from-ispor-sdm",
    "href": "pages/paper_evaluation.html#des-checklist-derived-from-ispor-sdm",
    "title": "7  Evaluation of the article",
    "section": "7.3 DES checklist derived from ISPOR-SDM",
    "text": "7.3 DES checklist derived from ISPOR-SDM\nKey:\n\nS: Shoaib and Ramamohan (2021) - link to evaluation\nH: Huang et al. (2019) - link to evaluation\nL: Lim et al. (2020) - link to evaluation\nK: Kim et al. (2021) - link to evaluation\nA: Anagnostou et al. (2022) - link to evaluation\nJ: Johnson et al. (2021) - link to evaluation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem\nS\nH\nL\nK\nA\nJ\n\n\n\n\n\nModel conceptualisation\n\n\n\n\n\n\n\n\n\n1 Is the focused health-related decision problem clarified?…the decision problem under investigation was defined. DES studies included different types of decision problems, eg, those listed in previously developed taxonomies.\n✅\n✅\n✅\n✅\n✅\n\n\n\n\n2 Is the modeled healthcare setting/health condition clarified?…the physical context/scope (eg, a certain healthcare unit or a broader system) or disease spectrum simulated was described.\n✅\n✅\n✅\n✅\n✅\n\n\n\n\n3 Is the model structure described?…the model’s conceptual structure was described in the form of either graphical or text presentation.\n✅\n✅\n✅\ntbc\n✅\n\n\n\n\n4 Is the time horizon given?…the time period covered by the simulation was reported.\n✅\n✅\n✅\n✅\n❌\n\n\n\n\n5 Are all simulated strategies/scenarios specified?…the comparators under test were described in terms of their components, corresponding variations, etc\n✅\n✅\n✅\n✅\nN/A\n\n\n\n\n6 Is the target population described?…the entities simulated and their main attributes were characterized.\n✅\n❌\n✅\n✅\n🟡\n\n\n\n\nParamaterisation and uncertainty assessment\n\n\n\n\n\n\n\n\n\n7 Are data sources informing parameter estimations provided?…the sources of all data used to inform model inputs were reported.\n✅\n✅\n✅\n✅\n✅\n\n\n\n\n8 Are the parameters used to populate model frameworks specified?…all relevant parameters fed into model frameworks were disclosed.\n🟡\n🟡\n✅\n✅\n✅\n\n\n\n\n9 Are model uncertainties discussed?…the uncertainty surrounding parameter estimations and adopted statistical methods (eg, 95% confidence intervals or possibility distributions) were reported.\n🟡\n❌\n❌\n❌\n✅\n\n\n\n\n10 Are sensitivity analyses performed and reported?…the robustness of model outputs to input uncertainties was examined, for example via deterministic (based on parameters’ plausible ranges) or probabilistic (based on a priori-defined probability distributions) sensitivity analyses, or both.\n✅\n❌\n✅\n❌\nN/A\n\n\n\n\nValidation\n\n\n\n\n\n\n\n\n\n11 Is face validity evaluated and reported?…it was reported that the model was subjected to the examination on how well model designs correspond to the reality and intuitions. It was assumed that this type of validation should be conducted by external evaluators with no stake in the study.\n❌\n❌\n❌\n❌\n❌\n\n\n\n\n12 Is cross validation performed and reported…comparison across similar modeling studies which deal with the same decision problem was undertaken.\nN/A\n❌\n❌\n✅\n❌\n\n\n\n\n13 Is external validation performed and reported?…the modeler(s) examined how well the model’s results match the empirical data of an actual event modeled.\nN/A\nN/A\nN/A\n✅\n❌\n\n\n\n\n14 Is predictive validation performed or attempted? …the modeler(s) examined the consistency of a model’s predictions of a future event and the actual outcomes in the future. If this was not undertaken, it was assessed whether the reasons were discussed.\nN/A\nN/A\nN/A\nN/A\nN/A\n\n\n\n\nGeneralisability and stakeholder involvement\n\n\n\n\n\n\n\n\n\n15 Is the model generalizability issue discussed?…the modeler(s) discussed the potential of the resulting model for being applicable to other settings/populations (single/multiple application).\n✅\n✅\n✅\n❌\n🟡\n\n\n\n\n16 Are decision makers or other stakeholders involved in modeling?…the modeler(s) reported in which part throughout the modeling process decision makers and other stakeholders (eg, subject experts) were engaged.\n❌\n❌\n❌\n❌\n✅\n\n\n\n\n17 Is the source of funding stated?…the sponsorship of the study was indicated.\n✅\n❌\n✅\n✅\n✅\n\n\n\n\n18 Are model limitations discussed?…limitations of the assessed model, especially limitations of interest to decision makers, were discussed.\n✅\n🟡\n✅\n✅\n🟡",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Evaluation of the article</span>"
    ]
  },
  {
    "objectID": "pages/paper_evaluation.html#timings",
    "href": "pages/paper_evaluation.html#timings",
    "title": "7  Evaluation of the article",
    "section": "7.4 Timings",
    "text": "7.4 Timings\n\n\nShoaib and Ramamohan (2021) - 1h 56m\nHuang et al. (2019) - 1h 28m\nLim et al. (2020) - 1h 12m\nKim et al. (2021)\nAnagnostou et al. (2022) - 53m\nJohnson et al. (2021)",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Evaluation of the article</span>"
    ]
  },
  {
    "objectID": "pages/paper_evaluation.html#references",
    "href": "pages/paper_evaluation.html#references",
    "title": "7  Evaluation of the article",
    "section": "7.5 References",
    "text": "7.5 References\n\n\n\n\nAnagnostou, Anastasia, Derek Groen, Simon J. E. Taylor, Diana Suleimenova, Nura Abubakar, Arindam Saha, Kate Mintram, et al. 2022. “FACS-CHARM: A Hybrid Agent-Based and Discrete-Event Simulation Approach for Covid-19 Management at Regional Level.” In 2022 Winter Simulation Conference (WSC), 1223–34. https://doi.org/10.1109/WSC57314.2022.10015462.\n\n\nHuang, Shiwei, Julian Maingard, Hong Kuan Kok, Christen D. Barras, Vincent Thijs, Ronil V. Chandra, Duncan Mark Brooks, and Hamed Asadi. 2019. “Optimizing Resources for Endovascular Clot Retrieval for Acute Ischemic Stroke, a Discrete Event Simulation.” Frontiers in Neurology 10 (June). https://doi.org/10.3389/fneur.2019.00653.\n\n\nJohnson, Kate M., Mohsen Sadatsafavi, Amin Adibi, Larry Lynd, Mark Harrison, Hamid Tavakoli, Don D. Sin, and Stirling Bryan. 2021. “Cost Effectiveness of Case Detection Strategies for the Early Detection of COPD.” Applied Health Economics and Health Policy 19 (2): 203–15. https://doi.org/10.1007/s40258-020-00616-2.\n\n\nKim, Lois G., Michael J. Sweeting, Morag Armer, Jo Jacomelli, Akhtar Nasim, and Seamus C. Harrison. 2021. “Modelling the Impact of Changes to Abdominal Aortic Aneurysm Screening and Treatment Services in England During the COVID-19 Pandemic.” PLOS ONE 16 (6): e0253327. https://doi.org/10.1371/journal.pone.0253327.\n\n\nLim, Chun Yee, Mary Kathryn Bohn, Giuseppe Lippi, Maurizio Ferrari, Tze Ping Loh, Kwok-Yung Yuen, Khosrow Adeli, and Andrea Rita Horvath. 2020. “Staff Rostering, Split Team Arrangement, Social Distancing (Physical Distancing) and Use of Personal Protective Equipment to Minimize Risk of Workplace Transmission During the COVID-19 Pandemic: A Simulation Study.” Clinical Biochemistry 86 (December): 15–22. https://doi.org/10.1016/j.clinbiochem.2020.09.003.\n\n\nMonks, Thomas, Christine S. M. Currie, Bhakti Stephan Onggo, Stewart Robinson, Martin Kunc, and Simon J. E. Taylor. 2019. “Strengthening the Reporting of Empirical Simulation Studies: Introducing the STRESS Guidelines.” Journal of Simulation 13 (1): 55–67. https://doi.org/10.1080/17477778.2018.1442155.\n\n\nShoaib, Mohd, and Varun Ramamohan. 2021. “Simulation Modelling and Analysis of Primary Health Centre Operations.” arXiv, June. https://doi.org/10.48550/arXiv.2104.12492.\n\n\nZhang, Xiange, Stefan K. Lhachimi, and Wolf H. Rogowski. 2020. “Reporting Quality of Discrete Event Simulations in Healthcare—Results From a Generic Reporting Checklist.” Value in Health 23 (4): 506–14. https://doi.org/10.1016/j.jval.2020.01.005.",
    "crumbs": [
      "Results",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Evaluation of the article</span>"
    ]
  },
  {
    "objectID": "pages/framework.html",
    "href": "pages/framework.html",
    "title": "8  Modifying the framework",
    "section": "",
    "text": "8.1 Contents of the framework",
    "crumbs": [
      "Discussion",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Modifying the framework</span>"
    ]
  },
  {
    "objectID": "pages/framework.html#contents-of-the-framework",
    "href": "pages/framework.html#contents-of-the-framework",
    "title": "8  Modifying the framework",
    "section": "",
    "text": "Section from reflections\nConsideration for framework\n\n\n\n\nList required packages\nThe difference between listing all packages, and listing some that then have other dependencies. The various options there are for listing packages, and the downside of just assuming its obvious from imports. The options for guiding dependency management (e.g. providing scripts that download packages, and then environment management tools)\n\n\nProvide version for Python/R and for packages\nImportant to do so for both (not just packages). Challenge of implementing in R. Ease of implementing in Python. Importance of listing in repository itself. Options for doing this in R and Python. Suggestions. Need to explore more with R. Is it a matter of providing renv but suggesting someone could try with latest versions in first instance? As not realistic to guarantee maintenance of research projects. But know at least when it worked - as being clear, it won’t always, even in R\n\n\nModel in a “runnable” format\nThis was an unusual case, but I think could merge more under the example of providing code that aligns with the paper, as in that case, it was the code for a web app when the paper wasn’t about that\n\n\nModel designed to run programmatically, and don’t hard code parameters you want to change.\nConsider whether framework will given guidance on model structure. If so, it should be suggesting that (A) parameters are seperate from model and (B) run scenarios by changing elsewhere (and not by directly modifying the model code). Why do this? Because its simpler to run multiple versions of model with same script, and reduces likelihood of missing errors of inputing wrong parameters\n\n\nAvoid large amounts of code duplciation\nThis would also be a code structure thing (does it fit in framework?). Good to do in general - fairly standard coding practice. Here as it makes code more readable, makes it easier when want to change all scenarios, and reduces likelihood of introducing mistakes (which did see)\n\n\nSufficient comments in code\nLikewise, code structure. Standard practice like docstrings (which only one or two had). The standard structures that are available for docstrings (e.g. roxygen in R). And then also just general comments in code itself.\n\n\nQuicker models\nWorth considering for framework, as this was practically one of the big things for me when it came to using the models. Think about the options that are available for reducing model run time. And from the start, principles of keeping it simple and small. Things to avoid that make it slow. Alternatives to those things. The value of a quicker model (e.g. in being able to make an app, to rerun it all easily and spot mistakes, to just be easier to work with).\n\n\nState run time\nCould include in minimum documentation\n\n\nState memory usage and alterantives for lower spec machines\nCould include in enhanced documentation? Or minimum? Need to consider that this can seem a daunting thing if not familiar and wouldn’t know how to find this out or what this means\n\n\nProvide code for all scenarios\n\n\n\nInclude correct parameters in script\nSuggestion of default model parameters matching up to baseline in paper, and explaining that if not, issue becomes that its hard to check if model is all correct without code or paper listing every single parameter\n\n\nProvide all required parameters\n\n\n\nClearly present parameters in paper\nThis would not be relevant for STARS framework, but could feed into STRESS-DES work? How it being in a table was so much easier than it being described in the text, and how it being comprehensive of all parameters that get varied (or clear if those are the only things changed from baseline, and so on)\n\n\nProvide calculations\nAgain, might not quite fit into STARS? But if you are going to be mentioning the “pre-processed” values at all, then its important to include the calculation (ideally in the code, as that is the clearest demonstration of exactly what you did)\n\n\nSaves output to a file\nCode structure type thing. This was really handy, particularly for long run times. In doing this, set up in way that is easy to change name and location of output file, and not hard coded to one thing\n\n\nUnderstandable output tables\nNot sure where/if this might fit. But suggestion is to not provide alternative results for same metrics. And if a table or output might be unclear on what need or how to calculate, then providing some docs or something that supports\n\n\nUsing seeds\nExplain how, how it can be quite simple, and what benefit of this is. Could be in enhanced\n\n\nProvide code to produce (a) tables (b) figures (c) in-text results\nExplaining why this is handy (being able to reproduce gives confidence model is running right and also important in science) (plus useful for self too if need to make changes in review process and so on). Noting importance of not forgetting about “in-text” results\n\n\nInstructions on how to run model\nAlready in minimal documentation, but be aware, even as simple as “run this script and here is an example of how” is helpful\n\n\nGrid lines\nMinor, not sure if fits/to include\n\n\nData dictionaries\nMinor and intersects with good commenting, might not be relevant for all, but also worth considering, if people are uploading data as part of model, what the principles and practices and recommendations are for shairng of data and linking to those (as this is likely part of those, along with other things). If there is overlap, make it clear the synergies (e.g. if talks about archiving data, how could do alongside code, and so on).",
    "crumbs": [
      "Discussion",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Modifying the framework</span>"
    ]
  },
  {
    "objectID": "pages/framework.html#presentation-of-the-framework",
    "href": "pages/framework.html#presentation-of-the-framework",
    "title": "8  Modifying the framework",
    "section": "8.2 Presentation of the framework",
    "text": "8.2 Presentation of the framework\nChecklist table with categories, description and space to complete. But in multiple synced formats (perhaps auto conversion github action between them) - e.g. markdown, latex, docx\nDiagram: Think about any ways could adapt this and if would benefit from that. E.g. gradual reveal with GIF. more icons. alt layout. etc.\nWebsite: Could share like https://joss.readthedocs.io/en/latest/paper.html but would want to make sure we are adding sufficient detail on top of checklist.",
    "crumbs": [
      "Discussion",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Modifying the framework</span>"
    ]
  }
]